<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="ictfox blog">
<meta property="og:url" content="http://www.yangguanjun.com/index.html">
<meta property="og:site_name" content="ictfox blog">
<meta property="og:description" content="学无止境">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ictfox blog">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.yangguanjun.com/"/>





  <title>ictfox blog</title>
  








  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-7472013512056838",
    enable_page_level_ads: true
  });
</script>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ictfox blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">ForTech</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/05/17/ceph-daemonperf-intro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/17/ceph-daemonperf-intro/" itemprop="url">ceph daemonperf tool分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-17T22:41:27+08:00">
                2018-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/17/ceph-daemonperf-intro/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/05/17/ceph-daemonperf-intro/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><p>Ceph有个daemonperf工具，结合Ceph daemon的asok文件，可以检查Ceph各个组件的当前状态。</p>
<p>命令格式：ceph daemonperf <asok> <interval></interval></asok></p>
<p>示例如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph daemonperf /var/run/ceph/ceph-osd.0.asok 2</span></span><br><span class="line">---objecter--- -----------osd-----------</span><br><span class="line">writ <span class="built_in">read</span> actv|recop rd   wr   lat  ops |</span><br><span class="line">  0    0    0 |   0   12k   0    0    1</span><br><span class="line">  0    0    0 |   0  532k   0    0   62</span><br><span class="line">  0    0    0 |   0  106k   0    0   10</span><br><span class="line">  0    0    0 |   0  487k 4.2M   1   71</span><br><span class="line"></span><br><span class="line"><span class="comment"># ceph daemonperf /var/run/ceph/ceph-mds.mds-ceph0.asok 2</span></span><br><span class="line">-----mds------ --mds_server-- ---objecter--- -----mds_cache----- ---mds_log----</span><br><span class="line">rlat inos caps|hsr  hcs  hcr |writ <span class="built_in">read</span> actv|recd recy stry purg|segs evts subm|</span><br><span class="line">  0  137k  22k|  0    0   81 |  4    0  129 |  0    0  108k   4 | 54   40k  43</span><br><span class="line">  0  139k  15k|  0    0  7.5k|941    1  132 |  0    0  111k 918 | 46   34k 4.7k</span><br><span class="line">  0  145k  16k|  0    0   11k|592    0  129 |  0    0  116k 581 | 54   40k 6.3k</span><br><span class="line">  0  123k 7.3k|  0    1  6.9k|231    1  129 |  0    0  119k 214 | 48   33k 3.7k</span><br><span class="line">  0  128k 8.2k|  0    0  9.0k|509    0  130 |  0    0  123k 503 | 54   38k 5.0k</span><br><span class="line">  1  129k 8.3k|  0    0  924 |405    1  128 |  0    0  123k 402 | 55   39k 867</span><br></pre></td></tr></table></figure>
<h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><p>文件：ceph.in</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> parsed_args.admin_socket:</span><br><span class="line">        sockpath = parsed_args.admin_socket</span><br><span class="line">    <span class="keyword">elif</span> len(childargs) &gt; <span class="number">0</span> <span class="keyword">and</span> childargs[<span class="number">0</span>] <span class="keyword">in</span> [<span class="string">"daemon"</span>, <span class="string">"daemonperf"</span>]:</span><br><span class="line">        daemon_perf = (childargs[<span class="number">0</span>] == <span class="string">"daemonperf"</span>)</span><br><span class="line">        <span class="comment"># Treat "daemon &lt;path&gt;" or "daemon &lt;name&gt;" like --admin_daemon &lt;path&gt;</span></span><br><span class="line">        <span class="comment"># Handle "daemonperf &lt;path&gt;" the same but requires no trailing args</span></span><br><span class="line">        require_args = <span class="number">2</span> <span class="keyword">if</span> daemon_perf <span class="keyword">else</span> <span class="number">3</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> sockpath <span class="keyword">and</span> daemon_perf:</span><br><span class="line">        interval = <span class="number">1</span></span><br><span class="line">        count = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> len(childargs) &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                interval = float(childargs[<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">if</span> interval &lt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                print(<span class="string">'daemonperf: interval should be a positive number'</span>, file=sys.stderr)</span><br><span class="line">                <span class="keyword">return</span> errno.EINVAL</span><br><span class="line">        <span class="keyword">if</span> len(childargs) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> childargs[<span class="number">1</span>].isdigit():</span><br><span class="line">                print(<span class="string">'daemonperf: count should be a positive integer'</span>, file=sys.stderr)</span><br><span class="line">                <span class="keyword">return</span> errno.EINVAL</span><br><span class="line">            count = int(childargs[<span class="number">1</span>])</span><br><span class="line">        DaemonWatcher(sockpath).run(interval, count)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">	...</span><br></pre></td></tr></table></figure>
<p>文件：pybind/ceph_daemon.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DaemonWatcher</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Given a Ceph daemon's admin socket path, poll its performance counters</span></span><br><span class="line"><span class="string">    and output a series of output lines showing the momentary values of</span></span><br><span class="line"><span class="string">    counters of interest (those with the 'nick' property in Ceph's schema)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_load_schema</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Populate our instance-local copy of the daemon's performance counter</span></span><br><span class="line"><span class="string">        schema, and work out which stats we will display.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self._schema = json.loads(admin_socket(self.asok_path, [<span class="string">"perf"</span>, <span class="string">"schema"</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Build list of which stats we will display, based on which</span></span><br><span class="line">        <span class="comment"># stats have a nickname</span></span><br><span class="line">        self._stats = defaultdict(dict)</span><br><span class="line">        <span class="keyword">for</span> section_name, section_stats <span class="keyword">in</span> self._schema.items():</span><br><span class="line">            <span class="keyword">for</span> name, schema_data <span class="keyword">in</span> section_stats.items():</span><br><span class="line">                <span class="keyword">if</span> schema_data.get(<span class="string">'nick'</span>):</span><br><span class="line">                    self._stats[section_name][name] = schema_data[<span class="string">'nick'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, interval, count=None, ostr=sys.stdout)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Print output at regular intervals until interrupted.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param ostr: Stream to which to send output</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        self._load_schema()</span><br><span class="line">        self._colored = self.supports_color(ostr)</span><br><span class="line"></span><br><span class="line">        self._print_headers(ostr)</span><br><span class="line"></span><br><span class="line">        last_dump = json.loads(admin_socket(self.asok_path, [<span class="string">"perf"</span>, <span class="string">"dump"</span>]))</span><br><span class="line">        rows_since_header = <span class="number">0</span></span><br><span class="line">        term_height = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">                dump = json.loads(admin_socket(self.asok_path, [<span class="string">"perf"</span>, <span class="string">"dump"</span>]))</span><br><span class="line">                <span class="keyword">if</span> rows_since_header &gt; term_height - <span class="number">2</span>:</span><br><span class="line">                    self._print_headers(ostr)</span><br><span class="line">                    rows_since_header = <span class="number">0</span></span><br><span class="line">                self._print_vals(ostr, dump, last_dump)</span><br><span class="line">                <span class="keyword">if</span> count <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                    count -= <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> count &lt;= <span class="number">0</span>:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                rows_since_header += <span class="number">1</span></span><br><span class="line">                last_dump = dump</span><br><span class="line">                time.sleep(interval)</span><br><span class="line">        <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">            <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>所以<code>ceph daemonperf &lt;asok&gt;</code>命令的输出是根据<code>ceph daemon &lt;asok&gt; perf dump/schema</code>的输出整理的。</p>
<p>实现中存了上一次的<code>perf dump</code>结果，所以这里获取的值是<code>interval</code>里的数据统计。</p>
<p>以ceph mds asok的<code>perf dump/schema</code>输出为例，看看每个项是什么含义：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon &lt;mds-asok&gt; perf schema</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"mds"</span>: &#123;</span><br><span class="line">        <span class="string">"reply_latency"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 5,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Reply latency"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"rlat"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"inodes"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Inodes"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"inos"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"caps"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Capabilities"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"caps"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_cache"</span>: &#123;</span><br><span class="line">        <span class="string">"num_strays"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Stray dentries"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"stry"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"strays_purged"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Stray dentries purged"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"purg"</span></span><br><span class="line">        &#125;,</span><br><span class="line">    	...</span><br><span class="line">        <span class="string">"num_recovering_enqueued"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Files waiting for recovery"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"recy"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"recovery_completed"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"File recoveries completed"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"recd"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_log"</span>: &#123;</span><br><span class="line">        <span class="string">"evadd"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Events submitted"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"subm"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"ev"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Events"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"evts"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"seg"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Segments"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"segs"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_server"</span>: &#123;</span><br><span class="line">        <span class="string">"handle_client_request"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Client requests"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"hcr"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"handle_slave_request"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Slave requests"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"hsr"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"handle_client_session"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Client session messages"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"hcs"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"objecter"</span>: &#123;</span><br><span class="line">        <span class="string">"op_active"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 2,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Operations active"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"actv"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"op_r"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Read operations"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"read"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"op_w"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: 10,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"Write operations"</span>,</span><br><span class="line">            <span class="string">"nick"</span>: <span class="string">"writ"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>schema输出里的含义：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">文件：common/perf_counters.h</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> perfcounter_type_d</span><br><span class="line">&#123;</span><br><span class="line">    PERFCOUNTER_NONE = <span class="number">0</span>,</span><br><span class="line">    PERFCOUNTER_TIME = <span class="number">0x1</span>,</span><br><span class="line">    PERFCOUNTER_U64 = <span class="number">0x2</span>,</span><br><span class="line">    PERFCOUNTER_LONGRUNAVG = <span class="number">0x4</span>,</span><br><span class="line">    PERFCOUNTER_COUNTER = <span class="number">0x8</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PerfCounters</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="comment">/** Represents a PerfCounters data element. */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">perf_counter_data_any_d</span> &#123;</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *name;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *description;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *nick;</span><br><span class="line">        <span class="keyword">enum</span> perfcounter_type_d type;</span><br><span class="line">        <span class="keyword">atomic64_t</span> u64;</span><br><span class="line">        <span class="keyword">atomic64_t</span> avgcount;</span><br><span class="line">        <span class="keyword">atomic64_t</span> avgcount2;</span><br><span class="line">        ...</span><br><span class="line">    &#125;;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>ceph daemon <asok> perf dump中与daemonperf相关的输出项：</asok></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon &lt;mds-asok&gt; perf dump</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"mds"</span>: &#123;</span><br><span class="line">    	...</span><br><span class="line">        <span class="string">"reply_latency"</span>: &#123;</span><br><span class="line">            <span class="string">"avgcount"</span>: 1879241,</span><br><span class="line">            <span class="string">"sum"</span>: 563.417555661</span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"inodes"</span>: 510943,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"caps"</span>: 68002,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_cache"</span>: &#123;</span><br><span class="line">        <span class="string">"num_strays"</span>: 415633,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"strays_purged"</span>: 1192320,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"num_recovering_enqueued"</span>: 0,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"recovery_completed"</span>: 9</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_log"</span>: &#123;</span><br><span class="line">        <span class="string">"evadd"</span>: 2094629,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"ev"</span>: 42664,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"seg"</span>: 57,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mds_server"</span>: &#123;</span><br><span class="line">        <span class="string">"handle_client_request"</span>: 1879915,</span><br><span class="line">        <span class="string">"handle_slave_request"</span>: 0,</span><br><span class="line">        <span class="string">"handle_client_session"</span>: 698,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"objecter"</span>: &#123;</span><br><span class="line">        <span class="string">"op_active"</span>: 64,</span><br><span class="line">        ...</span><br><span class="line">        <span class="string">"op_r"</span>: 832,</span><br><span class="line">        <span class="string">"op_w"</span>: 1219634,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/05/05/ceph-osd-deploy-with-bcache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/ceph-osd-deploy-with-bcache/" itemprop="url">使用Bcache加速Ceph OSD性能</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-05T22:11:17+08:00">
                2018-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/05/ceph-osd-deploy-with-bcache/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/05/05/ceph-osd-deploy-with-bcache/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在Ceph的环境中，我们通常会使用SSD来作为OSD的Journal，而OSD的数据盘是普通的SATA盘，在实践中，经常会发现SATA盘的性能瓶颈影响了OSD的性能，那能不能继续压榨SSD的性能来提升OSD的性能呢？</p>
<p>答案是肯定的，可以使用SSD加速SATA盘的策略来加速作为OSD数据盘的SATA盘，通常的策略有：</p>
<ul>
<li>flashcache</li>
<li>bcache</li>
</ul>
<p>有文章对比测试过这两种cache策略的性能，bcache的性能会好很多，这里介绍如何使用bcache来给OSD加速。</p>
<h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>Ceph版本：Jewel 10.2.9</p>
<p>作为Ceph机器的物理机的磁盘配置如下：</p>
<ol>
<li>SSD - 745 G，三块</li>
<li>SATA - 3.7 T，九块</li>
</ol>
<p>对磁盘规划如下：</p>
<ol>
<li>每个SSD分出3个10G分区，作为三个SATA盘OSD的journal</li>
<li>每个SSD剩余空间分为1个分区，使用bcache来加速三个SATA盘</li>
</ol>
<p>磁盘分区前如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@ceph0:~/yangguanjun<span class="comment"># lsblk</span></span><br><span class="line">NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">sdb      8:16   0 745.2G  0 disk</span><br><span class="line">sdc      8:32   0 745.2G  0 disk</span><br><span class="line">sdd      8:48   0 745.2G  0 disk</span><br></pre></td></tr></table></figure>
<p>磁盘分区后为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@ceph0:~<span class="comment"># lsblk</span></span><br><span class="line">NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">sdb           8:16   0 745.2G  0 disk</span><br><span class="line">├─sdb1        8:17   0    10G  0 part</span><br><span class="line">├─sdb2        8:18   0    10G  0 part</span><br><span class="line">├─sdb3        8:19   0    10G  0 part</span><br><span class="line">└─sdb4        8:20   0 715.2G  0 part</span><br><span class="line">sdc           8:32   0 745.2G  0 disk</span><br><span class="line">├─sdc1        8:33   0    10G  0 part</span><br><span class="line">├─sdc2        8:34   0    10G  0 part</span><br><span class="line">├─sdc3        8:35   0    10G  0 part</span><br><span class="line">└─sdc4        8:36   0 715.2G  0 part</span><br><span class="line">sdd           8:48   0 745.2G  0 disk</span><br><span class="line">├─sdd1        8:49   0    10G  0 part</span><br><span class="line">├─sdd2        8:50   0    10G  0 part</span><br><span class="line">├─sdd1        8:51   0    10G  0 part</span><br><span class="line">└─sdd4        8:52   0 715.2G  0 part</span><br></pre></td></tr></table></figure>
<h2 id="设备性能"><a href="#设备性能" class="headerlink" title="设备性能"></a>设备性能</h2><p>针对当前环境，先要了解下各个硬件的性能，通过fio测试结果如下：</p>
<table>
<thead>
<tr>
<th>磁盘类型</th>
<th>read</th>
<th>write</th>
<th>randread</th>
<th>randwrite</th>
</tr>
</thead>
<tbody>
<tr>
<td>SATA</td>
<td>155MB/s</td>
<td>158MB/s</td>
<td>126</td>
<td>219</td>
</tr>
<tr>
<td>SSD</td>
<td>508MB/s</td>
<td>426MB/s</td>
<td>69.2k</td>
<td>45.5k</td>
</tr>
</tbody>
</table>
<p>参考文章配置SATA盘与SSD盘的bcache策略：<a href="http://www.yangguanjun.com/2018/03/26/lvm-sata-ssd-bcache/">http://www.yangguanjun.com/2018/03/26/lvm-sata-ssd-bcache/</a></p>
<p>配置bcache命令如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -B /dev/sde -C /dev/sdc4</span></span><br></pre></td></tr></table></figure>
<p>配置后的块设备信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">...</span><br><span class="line">sdc           8:32   0 745.2G  0 disk</span><br><span class="line">├─sdc1        8:33   0    10G  0 part</span><br><span class="line">├─sdc2        8:34   0    10G  0 part</span><br><span class="line">├─sdc3        8:35   0    10G  0 part</span><br><span class="line">└─sdc4        8:36   0 715.2G  0 part</span><br><span class="line">  ├─bcache0 253:0    0   3.7T  0 disk</span><br><span class="line">...</span><br><span class="line">sde           8:64   0   3.7T  0 disk</span><br><span class="line">└─bcache0   253:0    0   3.7T  0 disk</span><br></pre></td></tr></table></figure>
<p>之后测试bcache加速设备性能：</p>
<table>
<thead>
<tr>
<th>bcache的不同缓存策略</th>
<th>randwrite</th>
</tr>
</thead>
<tbody>
<tr>
<td>bcache [writethrough]</td>
<td>218</td>
</tr>
<tr>
<td>bcache [writeback]</td>
<td>38.8k</td>
</tr>
</tbody>
</table>
<p>上面结果看出 <code>bcache</code> 配置为<code>writeback</code>模式后，加速设备性能很高，会比SSD盘的性能略差些。但之后数据会回刷到SATA上，通过<code>iostat</code>可以看到SATA盘会繁忙好一阵子。</p>
<h2 id="部署OSD"><a href="#部署OSD" class="headerlink" title="部署OSD"></a>部署OSD</h2><p>默认直接使用<code>ceph-deploy</code>部署<code>bcache</code>设备时会报错，如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd prepare ceph0:/dev/bcache0:/dev/sdd1</span></span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (1.5.37): /usr/bin/ceph-deploy osd prepare ceph0:/dev/bcache0:/dev/sdd1</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  disk                          : [(<span class="string">'ceph0'</span>, <span class="string">'/dev/bcache0'</span>, <span class="string">'/dev/sdd1'</span>)]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  dmcrypt                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  bluestore                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : prepare</span><br><span class="line">[ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f81bab7b200&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  fs_type                       : xfs</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;<span class="keyword">function</span> osd at 0x7f81bab6a938&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  zap_disk                      : False</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph0:/dev/bcache0:/dev/sdd1</span><br><span class="line">[ceph0][DEBUG ] connected to host: ceph0</span><br><span class="line">[ceph0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph0][DEBUG ] detect machine <span class="built_in">type</span></span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.4.1708 Core</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Deploying osd to ceph0</span><br><span class="line">[ceph0][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Preparing host ceph0 disk /dev/bcache0 journal /dev/sdd1 activate False</span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /dev/bcache0 /dev/sdd1</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-osd --check-allows-journal -i 0 --<span class="built_in">log</span>-file <span class="variable">$run_dir</span>/<span class="variable">$cluster</span>-osd-check.log --cluster ceph --setuser ceph --setgroup ceph</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-osd --check-wants-journal -i 0 --<span class="built_in">log</span>-file <span class="variable">$run_dir</span>/<span class="variable">$cluster</span>-osd-check.log --cluster ceph --setuser ceph --setgroup ceph</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-osd --check-needs-journal -i 0 --<span class="built_in">log</span>-file <span class="variable">$run_dir</span>/<span class="variable">$cluster</span>-osd-check.log --cluster ceph --setuser ceph --setgroup ceph</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mkfs_options_xfs</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mount_options_xfs</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/sdd1 uuid path is /sys/dev/block/8:51/dm/uuid</span><br><span class="line">[ceph0][WARNIN] prepare_device: Journal /dev/sdd1 is a partition</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/sdd1 uuid path is /sys/dev/block/8:51/dm/uuid</span><br><span class="line">[ceph0][WARNIN] prepare_device: OSD will not be hot-swappable <span class="keyword">if</span> journal is not the same device as the osd data</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/sbin/blkid -o udev -p /dev/sdd1</span><br><span class="line">[ceph0][WARNIN] prepare_device: Journal /dev/sdd1 was not prepared with ceph-disk. Symlinking directly.</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] set_data_partition: Creating osd partition on /dev/bcache0</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] ptype_tobe_for_name: name = data</span><br><span class="line">[ceph0][WARNIN] get_dm_uuid: get_dm_uuid /dev/bcache0 uuid path is /sys/dev/block/252:8/dm/uuid</span><br><span class="line">[ceph0][WARNIN] create_partition: Creating data partition num 1 size 0 on /dev/bcache0</span><br><span class="line">[ceph0][WARNIN] command_check_call: Running <span class="built_in">command</span>: /usr/sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:cf599e47-c299-46c1-a385-aff4b0d25f1f --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be --mbrtogpt -- /dev/bcache0</span><br><span class="line">[ceph0][WARNIN] Caution: invalid main GPT header, but valid backup; regenerating main header</span><br><span class="line">[ceph0][WARNIN] from backup!</span><br><span class="line">[ceph0][WARNIN]</span><br><span class="line">[ceph0][WARNIN] Invalid partition data!</span><br><span class="line">[ceph0][WARNIN] <span class="string">'/usr/sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:cf599e47-c299-46c1-a385-aff4b0d25f1f --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be --mbrtogpt -- /dev/bcache0'</span> failed with status code 2</span><br><span class="line">[ceph0][ERROR ] RuntimeError: <span class="built_in">command</span> returned non-zero <span class="built_in">exit</span> status: 1</span><br><span class="line">[ceph_deploy.osd][ERROR ] Failed to execute <span class="built_in">command</span>: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /dev/bcache0 /dev/sdd1</span><br><span class="line">[ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs</span><br></pre></td></tr></table></figure>
<p>搜索有如下参考，<code>ceph-deploy</code>还不支持<code>bcache</code>设备，默认<code>ceph-deploy</code>会尝试对<code>bcache</code>设备进行分区，而<code>bcache</code>设备是不支持分区后挂载的，所以会导致命令失败。</p>
<p><a href="http://tracker.ceph.com/issues/13278" target="_blank" rel="noopener">http://tracker.ceph.com/issues/13278</a></p>
<p><a href="https://github.com/ceph/ceph/pull/16327" target="_blank" rel="noopener">https://github.com/ceph/ceph/pull/16327</a></p>
<h3 id="解决办法一"><a href="#解决办法一" class="headerlink" title="解决办法一"></a>解决办法一</h3><p>修改<code>ceph-disk</code>的代码，把上述链接中的patch加上，可惜没搞成功，很奇怪修改后的代码貌似没跑到。。。因时间紧急就没再研究，但这个办法肯定是可行的！</p>
<h3 id="解决办法二"><a href="#解决办法二" class="headerlink" title="解决办法二"></a>解决办法二</h3><p>手动格式化<code>bcache</code>设备，mount上后，通过<code>ceph-deploy</code>指定目录来部署了，步骤如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir /var/lib/ceph/osd/ceph-0</span></span><br><span class="line"><span class="comment"># mkfs.xfs /dev/bcache0</span></span><br><span class="line"><span class="comment"># mount /dev/bcache0 /var/lib/ceph/osd/ceph-0</span></span><br></pre></td></tr></table></figure>
<p>然后再尝试部署，报错如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy --overwrite-conf osd prepare ceph0:/var/lib/ceph/osd/ceph-0:/dev/sdd1</span></span><br><span class="line">...</span><br><span class="line">[ceph0][WARNIN] <span class="built_in">command</span>: Running <span class="built_in">command</span>: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 195 --monmap /var/lib/ceph/osd/ceph-0/activate.monmap --osd-data /var/lib/ceph/osd/ceph-0 --osd-journal /var/lib/ceph/osd/ceph-0/journal --osd-uuid 9ff0983b-74e2-4fc1-8ba8-cfb688024284 --keyring /var/lib/ceph/osd/ceph-0/keyring --setuser ceph --setgroup ceph</span><br><span class="line">[ceph0][WARNIN] Traceback (most recent call last):</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/sbin/ceph-disk"</span>, line 9, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">[ceph0][WARNIN]     load_entry_point(<span class="string">'ceph-disk==1.0.0'</span>, <span class="string">'console_scripts'</span>, <span class="string">'ceph-disk'</span>)()</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 5553, <span class="keyword">in</span> run</span><br><span class="line">[ceph0][WARNIN]     main(sys.argv[1:])</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 5504, <span class="keyword">in</span> main</span><br><span class="line">[ceph0][WARNIN]     args.func(args)</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 3631, <span class="keyword">in</span> main_activate</span><br><span class="line">[ceph0][WARNIN]     init=args.mark_init,</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 3451, <span class="keyword">in</span> activate_dir</span><br><span class="line">[ceph0][WARNIN]     (osd_id, cluster) = activate(path, activate_key_template, init)</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 3556, <span class="keyword">in</span> activate</span><br><span class="line">[ceph0][WARNIN]     keyring=keyring,</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 3010, <span class="keyword">in</span> mkfs</span><br><span class="line">[ceph0][WARNIN]     <span class="string">'--setgroup'</span>, get_ceph_group(),</span><br><span class="line">[ceph0][WARNIN]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_disk/main.py"</span>, line 2957, <span class="keyword">in</span> ceph_osd_mkfs</span><br><span class="line">[ceph0][WARNIN]     raise Error(<span class="string">'%s failed : %s'</span> % (str(arguments), error))</span><br><span class="line">[ceph0][WARNIN] ceph_disk.main.Error: Error: [<span class="string">'ceph-osd'</span>, <span class="string">'--cluster'</span>, <span class="string">'ceph'</span>, <span class="string">'--mkfs'</span>, <span class="string">'--mkkey'</span>, <span class="string">'-i'</span>, u<span class="string">'195'</span>, <span class="string">'--monmap'</span>, <span class="string">'/var/lib/ceph/osd/ceph-0/activate.monmap'</span>, <span class="string">'--osd-data'</span>, <span class="string">'/var/lib/ceph/osd/ceph-0'</span>, <span class="string">'--osd-journal'</span>, <span class="string">'/var/lib/ceph/osd/ceph-0/journal'</span>, <span class="string">'--osd-uuid'</span>, u<span class="string">'9ff0983b-74e2-4fc1-8ba8-cfb688024284'</span>, <span class="string">'--keyring'</span>, <span class="string">'/var/lib/ceph/osd/ceph-0/keyring'</span>, <span class="string">'--setuser'</span>, <span class="string">'ceph'</span>, <span class="string">'--setgroup'</span>, <span class="string">'ceph'</span>] failed : parse error setting <span class="string">'osd_deep_scrub_interval'</span> to <span class="string">'2592000 // every mouth'</span></span><br><span class="line">[ceph0][WARNIN] 2018-04-26 16:02:27.180328 7f3085e23940 -1 filestore(/var/lib/ceph/osd/ceph-0) mkfs: write_version_stamp() failed: (13) Permission denied</span><br><span class="line">[ceph0][WARNIN] 2018-04-26 16:02:27.180346 7f3085e23940 -1 OSD::mkfs: ObjectStore::mkfs failed with error -13</span><br><span class="line">[ceph0][WARNIN] 2018-04-26 16:02:27.180441 7f3085e23940 -1  ** ERROR: error creating empty object store <span class="keyword">in</span> /var/lib/ceph/osd/ceph-0: (13) Permission denied</span><br><span class="line">[ceph0][WARNIN]</span><br><span class="line">[ceph0][ERROR ] RuntimeError: <span class="built_in">command</span> returned non-zero <span class="built_in">exit</span> status: 1</span><br><span class="line">[ceph_deploy][ERROR ] RuntimeError: Failed to execute <span class="built_in">command</span>: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /var/lib/ceph/osd/ceph-0</span><br></pre></td></tr></table></figure>
<p>从输出里看是权限的问题，执行如下两条命令后，部署成功：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ceph0:/var/lib/ceph/osd<span class="comment"># chown -R ceph:ceph /dev/sdd1</span></span><br><span class="line">root@ceph0:/var/lib/ceph/osd<span class="comment"># chown -R ceph:ceph ceph-0</span></span><br></pre></td></tr></table></figure>
<h2 id="Ceph-OSD开机自启动"><a href="#Ceph-OSD开机自启动" class="headerlink" title="Ceph OSD开机自启动"></a>Ceph OSD开机自启动</h2><h3 id="bcache开机启动"><a href="#bcache开机启动" class="headerlink" title="bcache开机启动"></a>bcache开机启动</h3><p>添加bcache开机启动</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/sysconfig/modules/bcache.modules</span></span><br><span class="line"><span class="meta">#! /bin/sh</span></span><br><span class="line"></span><br><span class="line">/sbin/modinfo -F filename bcache &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">    /sbin/modprobe -f bcache</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># chmod 755 /etc/sysconfig/modules/bcache.modules</span></span><br></pre></td></tr></table></figure>
<h3 id="自动挂载OSD目录"><a href="#自动挂载OSD目录" class="headerlink" title="自动挂载OSD目录"></a>自动挂载OSD目录</h3><p>添加磁盘自动挂载，保证重启后Ceph OSD能自动运行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@ceph0:~<span class="comment"># blkid</span></span><br><span class="line">/dev/sdd1: PARTUUID=<span class="string">"81732128-2073-4d93-8582-377f4f9a701f"</span></span><br><span class="line">...</span><br><span class="line">/dev/bcache0: UUID=<span class="string">"88ef6ba6-fd13-478c-8b56-82951183f1d3"</span> TYPE=<span class="string">"xfs"</span></span><br><span class="line"></span><br><span class="line">root@ceph0:~<span class="comment"># cat /etc/fstab</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># /etc/fstab</span></span><br><span class="line"><span class="comment"># Created by anaconda on Wed May 24 15:20:03 2017</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Accessible filesystems, by reference, are maintained under '/dev/disk'</span></span><br><span class="line"><span class="comment"># See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">LABEL=/  /                       ext4    defaults        1 1</span><br><span class="line">UUID=88ef6ba6-fd13-478c-8b56-82951183f1d3 /var/lib/ceph/osd/ceph-0 xfs defaults 0 2</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/04/06/ceph-deploy-latest-luminous/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/06/ceph-deploy-latest-luminous/" itemprop="url">ceph-deploy 2.0.0 部署 Ceph Luminous 12.2.4</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-06T23:11:17+08:00">
                2018-04-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/06/ceph-deploy-latest-luminous/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/06/ceph-deploy-latest-luminous/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>Ceph Luminous已经发布到12.2.4版本，经历了前几个版本的磨炼，Luminous版本也越来越稳定，它的Bluestore属性和CephFS提供的多主MDS一直是我们关注的重点。</p>
<p>参考ceph和ceph-deploy官方文档，本文介绍下使用ceph-deploy部署最新版Ceph Luminous 12.2.4，以及部署中遇到的问题。</p>
<h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><h3 id="ceph-deploy版本"><a href="#ceph-deploy版本" class="headerlink" title="ceph-deploy版本"></a>ceph-deploy版本</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy --version</span></span><br><span class="line">2.0.0</span><br></pre></td></tr></table></figure>
<p>ceph-deploy 2.0.0的changelog：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2.0.0</span><br><span class="line">16-Jan-2018</span><br><span class="line"></span><br><span class="line">- Backward incompatible API changes <span class="keyword">for</span> OSD creation - will use ceph-volume and no longer consume ceph-disk.</span><br><span class="line">- Remove python-distribute dependency</span><br><span class="line">- Use /etc/os-release as a fallback when linux_distribution() doesn’t work</span><br><span class="line">- Drop dmcrypt support (unsupported by ceph-volume <span class="keyword">for</span> now)</span><br><span class="line">- Allow debug modes <span class="keyword">for</span> ceph-volume</span><br></pre></td></tr></table></figure>
<p>参考：<a href="http://docs.ceph.com/ceph-deploy/docs/changelog.html#id1" target="_blank" rel="noopener">http://docs.ceph.com/ceph-deploy/docs/changelog.html#id1</a></p>
<h3 id="系统版本"><a href="#系统版本" class="headerlink" title="系统版本"></a>系统版本</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line">LSB Version:	:core-4.1-amd64:core-4.1-noarch</span><br><span class="line">Distributor ID:	CentOS</span><br><span class="line">Description:	CentOS Linux release 7.3.1611 (Core)</span><br><span class="line">Release:	7.3.1611</span><br><span class="line">Codename:	Core</span><br></pre></td></tr></table></figure>
<h3 id="Ceph版本"><a href="#Ceph版本" class="headerlink" title="Ceph版本"></a>Ceph版本</h3><p>yum源配置，选择最新的Luminous版本：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/yum.repos.d/ceph.repo</span></span><br><span class="line">[ceph]</span><br><span class="line">name=Ceph packages <span class="keyword">for</span> <span class="variable">$basearch</span></span><br><span class="line">baseurl=http://mirrors.163.com/ceph/rpm-luminous/el7/<span class="variable">$basearch</span></span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://mirrors.163.com/ceph/rpm-luminous/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph <span class="built_in">source</span> packages</span><br><span class="line">baseurl=http://mirrors.163.com/ceph/rpm-luminous/el7/SRPMS</span><br><span class="line">enabled=0</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br></pre></td></tr></table></figure>
<p>ceph安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y ceph ceph-radosgw</span></span><br><span class="line">or</span><br><span class="line"><span class="comment"># ceph-deploy install [hosts]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ceph -v</span></span><br><span class="line">ceph version 12.2.4 (52085d5249a80c5f5121a76d6288429f35e4e77b) luminous (stable)</span><br></pre></td></tr></table></figure>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>使用ceph-deploy开始部署前，有如下几点要提前做好</p>
<ol>
<li><p>部署节点安装 ceph-deploy</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y ceph-deploy</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>部署节点与ceph nodes之间ssh无密码访问</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-keygen</span></span><br><span class="line"><span class="comment"># cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ceph nodes的hostname配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/hostname</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>部署节点/etc/hosts配置 ceph nodes的hostname与ip的对应</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/hosts</span></span><br><span class="line">100.60.0.20 ceph0</span><br><span class="line">100.60.0.21 ceph1</span><br><span class="line">100.60.0.22 ceph2</span><br></pre></td></tr></table></figure>
</li>
<li><p>ceph nodes配置ntp server</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y ntp ntpdate ntp-doc</span></span><br><span class="line"><span class="comment"># systemctl start ntpd</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ceph nodes安装ssh server</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y openssh-server</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ceph nodes关闭或配置防火墙</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl stop firewalld</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
<h2 id="Ceph-Monitor部署"><a href="#Ceph-Monitor部署" class="headerlink" title="Ceph Monitor部署"></a>Ceph Monitor部署</h2><p>开始部署Ceph Cluster，创建三个monitors：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy new ceph0 ceph1 ceph2</span></span><br><span class="line"><span class="comment"># ceph-deploy mon create ceph0 ceph1 ceph2</span></span><br></pre></td></tr></table></figure>
<p>创建ceph keys：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy gatherkeys ceph0 ceph1 ceph2</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>一定要开启ceph 认证，不然该命令执行失败</p>
<p>与<code>ceph-deploy mon create</code>命令执行完要有一定时间间隔，等到monitor集群正常了才能执行</p>
</blockquote>
<p>分发ceph配置和admin key到ceph集群节点：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy admin ceph0 ceph1 ceph2</span></span><br></pre></td></tr></table></figure>
<p>检查当前ceph集群状态：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph -s</span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     5b2192ff-299c-4024-9f10-93af008e66d3</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph0,ceph2,ceph1</span><br><span class="line">    mgr: no daemons active</span><br><span class="line">    osd: 0 osds: 0 up, 0 <span class="keyword">in</span></span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   0 pools, 0 pgs</span><br><span class="line">    objects: 0 objects, 0 bytes</span><br><span class="line">    usage:   0 kB used, 0 kB / 0 kB avail</span><br><span class="line">    pgs:</span><br></pre></td></tr></table></figure>
<p>参考：<a href="http://docs.ceph.com/ceph-deploy/docs/index.html#creating-a-new-configuration" target="_blank" rel="noopener">http://docs.ceph.com/ceph-deploy/docs/index.html#creating-a-new-configuration</a></p>
<h2 id="Ceph-manager部署"><a href="#Ceph-manager部署" class="headerlink" title="Ceph manager部署"></a>Ceph manager部署</h2><p>部署<code>ceph-mgr</code>组件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy mgr create ceph0 ceph1 ceph2</span></span><br><span class="line"><span class="comment"># ceph -s</span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     5b2192ff-299c-4024-9f10-93af008e66d3</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph0,ceph2,ceph1</span><br><span class="line">    mgr: ceph0(active), standbys: ceph2, ceph1</span><br><span class="line">    osd: 0 osds: 0 up, 0 <span class="keyword">in</span></span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   0 pools, 0 pgs</span><br><span class="line">    objects: 0 objects, 0 bytes</span><br><span class="line">    usage:   0 kB used, 0 kB / 0 kB avail</span><br><span class="line">    pgs:</span><br></pre></td></tr></table></figure>
<p>参考：<a href="http://docs.ceph.com/docs/master/mgr/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/mgr/</a></p>
<blockquote>
<p>Ceph Luminous主推的用于Ceph集群管理的组件，默认在所有部署ceph-mon的节点都启动一个ceph-mgr</p>
</blockquote>
<h2 id="Ceph-OSD部署"><a href="#Ceph-OSD部署" class="headerlink" title="Ceph OSD部署"></a>Ceph OSD部署</h2><p>使用<code>ceph-deploy</code>工具来部署ceph osd：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create -h</span></span><br><span class="line">usage: ceph-deploy osd create [-h] [--data DATA] [--journal JOURNAL]</span><br><span class="line">                              [--zap-disk] [--fs-type FS_TYPE] [--dmcrypt]</span><br><span class="line">                              [--dmcrypt-key-dir KEYDIR] [--filestore]</span><br><span class="line">                              [--bluestore] [--block-db BLOCK_DB]</span><br><span class="line">                              [--block-wal BLOCK_WAL] [--debug]</span><br><span class="line">                              [HOST]</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  HOST                  Remote host to connect</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --<span class="built_in">help</span>            show this <span class="built_in">help</span> message and <span class="built_in">exit</span></span><br><span class="line">  --data DATA           The OSD data logical volume (vg/lv) or absolute path</span><br><span class="line">                        to device</span><br><span class="line">  --journal JOURNAL     Logical Volume (vg/lv) or path to GPT partition</span><br><span class="line">  --zap-disk            DEPRECATED - cannot zap when creating an OSD</span><br><span class="line">  --fs-type FS_TYPE     filesystem to use to format DEVICE (xfs, btrfs)</span><br><span class="line">  --dmcrypt             use dm-crypt on DEVICE</span><br><span class="line">  --dmcrypt-key-dir KEYDIR</span><br><span class="line">                        directory <span class="built_in">where</span> dm-crypt keys are stored</span><br><span class="line">  --filestore           filestore objectstore</span><br><span class="line">  --bluestore           bluestore objectstore</span><br><span class="line">  --block-db BLOCK_DB   bluestore block.db path</span><br><span class="line">  --block-wal BLOCK_WAL</span><br><span class="line">                        bluestore block.wal path</span><br><span class="line">  --debug               Enable debug mode on remote ceph-volume calls</span><br></pre></td></tr></table></figure>
<p>注：从Ceph Luminous 12.2.2开始， <code>ceph-disk</code> 就被弃用了，开始使用新的工具<code>ceph-volume</code>。</p>
<p>参考：<a href="http://docs.ceph.com/docs/master/ceph-volume/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/ceph-volume/</a></p>
<p>创建一个bluestore的osd，有以下几种设备选择：</p>
<ul>
<li>A block device, a block.wal, and a block.db device</li>
<li>A block device and a block.wal device</li>
<li>A block device and a block.db device</li>
<li>A single block device</li>
</ul>
<p>参考：<a href="http://docs.ceph.com/docs/master/ceph-volume/lvm/prepare/#bluestore" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/ceph-volume/lvm/prepare/#bluestore</a></p>
<p>block device也有如下三种选项：</p>
<ul>
<li>整块磁盘</li>
<li>磁盘分区</li>
<li>逻辑卷（a logical volume of LVM）</li>
</ul>
<blockquote>
<p>配置使用整块磁盘时，ceph-volume会自动创建一个logical volume使用</p>
</blockquote>
<h3 id="单独块设备创建OSD"><a href="#单独块设备创建OSD" class="headerlink" title="单独块设备创建OSD"></a>单独块设备创建OSD</h3><h4 id="整块磁盘"><a href="#整块磁盘" class="headerlink" title="整块磁盘"></a>整块磁盘</h4><p>命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create [host] --data [/path/to/device]</span></span><br></pre></td></tr></table></figure>
<p>首先销毁磁盘的分区信息：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ceph-deploy]<span class="comment"># ceph-deploy disk zap ceph0 /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[ceph_deploy][ERROR ] Traceback (most recent call last):</span><br><span class="line">[ceph_deploy][ERROR ]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_deploy/util/decorators.py"</span>, line 69, <span class="keyword">in</span> newfunc</span><br><span class="line">[ceph_deploy][ERROR ]     <span class="built_in">return</span> f(*a, **kw)</span><br><span class="line">[ceph_deploy][ERROR ]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_deploy/cli.py"</span>, line 164, <span class="keyword">in</span> _main</span><br><span class="line">[ceph_deploy][ERROR ]     <span class="built_in">return</span> args.func(args)</span><br><span class="line">[ceph_deploy][ERROR ]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_deploy/osd.py"</span>, line 438, <span class="keyword">in</span> disk</span><br><span class="line">[ceph_deploy][ERROR ]     disk_zap(args)</span><br><span class="line">[ceph_deploy][ERROR ]   File <span class="string">"/usr/lib/python2.7/site-packages/ceph_deploy/osd.py"</span>, line 336, <span class="keyword">in</span> disk_zap</span><br><span class="line">[ceph_deploy][ERROR ]     <span class="keyword">if</span> args.debug:</span><br><span class="line">[ceph_deploy][ERROR ] AttributeError: <span class="string">'Namespace'</span> object has no attribute <span class="string">'debug'</span></span><br><span class="line">[ceph_deploy][ERROR ]</span><br></pre></td></tr></table></figure>
<p>修改osd.py如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ceph-deploy]<span class="comment"># vim /usr/lib/python2.7/site-packages/ceph_deploy/osd.py</span></span><br><span class="line">        <span class="comment">#if args.debug:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">False</span>:</span><br></pre></td></tr></table></figure>
<p>再尝试<code>disk zap</code>成功：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ceph-deploy]<span class="comment"># ceph-deploy disk zap ceph0 /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume lvm zap /dev/sdb</span><br><span class="line">[ceph0][DEBUG ] --&gt; Zapping: /dev/sdb</span><br><span class="line">[ceph0][DEBUG ] Running <span class="built_in">command</span>: cryptsetup status /dev/mapper/</span><br><span class="line">[ceph0][DEBUG ]  stdout: /dev/mapper/ is inactive.</span><br><span class="line">[ceph0][DEBUG ] Running <span class="built_in">command</span>: wipefs --all /dev/sdb</span><br><span class="line">[ceph0][DEBUG ] Running <span class="built_in">command</span>: dd <span class="keyword">if</span>=/dev/zero of=/dev/sdb bs=1M count=10</span><br><span class="line">[ceph0][DEBUG ]  stderr: 10+0 records <span class="keyword">in</span></span><br><span class="line">[ceph0][DEBUG ] 10+0 records out</span><br><span class="line">[ceph0][DEBUG ] 10485760 bytes (10 MB) copied</span><br><span class="line">[ceph0][DEBUG ]  stderr: , 0.0110867 s, 946 MB/s</span><br><span class="line">[ceph0][DEBUG ] --&gt; Zapping successful <span class="keyword">for</span>: /dev/sdb</span><br></pre></td></tr></table></figure>
<blockquote>
<p>从输出看，ceph-deploy调用ceph-volume lvm zap，最后是执行dd命令往disk前10M写入全0数据</p>
</blockquote>
<p>创建OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create ceph0 --data /dev/sdb</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdb</span><br><span class="line">...</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph0 is now ready <span class="keyword">for</span> osd use.</span><br></pre></td></tr></table></figure>
<p>检查OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df -h</span></span><br><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">...</span><br><span class="line">tmpfs                 16G   48K   16G   1% /var/lib/ceph/osd/ceph-0</span><br><span class="line"></span><br><span class="line"><span class="comment"># ll /var/lib/ceph/osd/ceph-0/</span></span><br><span class="line">total 48</span><br><span class="line">-rw-r--r-- 1 ceph ceph 393 Apr  2 18:11 activate.monmap</span><br><span class="line">lrwxrwxrwx 1 ceph ceph  93 Apr  2 18:11 block -&gt; /dev/ceph-5b2192ff-299c-4024-9f10-93af008e66d3/osd-block-fe7cd3b1-8513-4be5-b9a8-88fd47dca679</span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:11 bluefs</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:11 ceph_fsid</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:11 fsid</span><br><span class="line">-rw------- 1 ceph ceph  55 Apr  2 18:11 keyring</span><br><span class="line">-rw-r--r-- 1 ceph ceph   8 Apr  2 18:11 kv_backend</span><br><span class="line">-rw-r--r-- 1 ceph ceph  21 Apr  2 18:11 magic</span><br><span class="line">-rw-r--r-- 1 ceph ceph   4 Apr  2 18:11 mkfs_done</span><br><span class="line">-rw-r--r-- 1 ceph ceph  41 Apr  2 18:11 osd_key</span><br><span class="line">-rw-r--r-- 1 ceph ceph   6 Apr  2 18:11 ready</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  2 18:11 <span class="built_in">type</span></span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:11 whoami</span><br></pre></td></tr></table></figure>
<p>查看OSD block对应设备：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsblk /dev/sdb</span></span><br><span class="line">NAME                                                                                                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sdb                                                                                                     8:16   0  3.7T  0 disk</span><br><span class="line">└─ceph--5b2192ff--299c--4024--9f10--93af008e66d3-osd--block--fe7cd3b1--8513--4be5--b9a8--88fd47dca679 253:3    0  3.7T  0 lvm</span><br><span class="line"></span><br><span class="line"><span class="comment"># pvs /dev/sdb</span></span><br><span class="line">  PV         VG                                        Fmt  Attr PSize PFree</span><br><span class="line">  /dev/sdb   ceph-5b2192ff-299c-4024-9f10-93af008e66d3 lvm2 a--  3.64t    0</span><br><span class="line"></span><br><span class="line"><span class="comment"># lvs ceph-5b2192ff-299c-4024-9f10-93af008e66d3</span></span><br><span class="line">  LV                                             VG                                        Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  osd-block-fe7cd3b1-8513-4be5-b9a8-88fd47dca679 ceph-5b2192ff-299c-4024-9f10-93af008e66d3 -wi-ao---- 3.64t</span><br></pre></td></tr></table></figure>
<p><strong>结论：</strong></p>
<ul>
<li>Ceph OSD的mount路径对应的是tmpfs，Linux基于内存的文件系统，而并没有单独的块设备与之对应</li>
<li>整块磁盘创建一个PV，然后创建VG和一个LV给OSD的<code>block</code>使用</li>
</ul>
<p>没有单独的块设备与tmpfs对应，那上面的数据存在哪里了？ </p>
<p><strong>答：</strong>存在OSD的metadata里了！</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">文件：osd/OSD.cc</span><br><span class="line"><span class="keyword">int</span> OSD::write_meta(CephContext *cct, ObjectStore *store, uuid_d&amp; cluster_fsid, uuid_d&amp; osd_fsid, <span class="keyword">int</span> whoami)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="built_in">snprintf</span>(val, <span class="keyword">sizeof</span>(val), <span class="string">"%s"</span>, CEPH_OSD_ONDISK_MAGIC);</span><br><span class="line">    r = store-&gt;write_meta(<span class="string">"magic"</span>, val);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> r;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">snprintf</span>(val, <span class="keyword">sizeof</span>(val), <span class="string">"%d"</span>, whoami);</span><br><span class="line">    r = store-&gt;write_meta(<span class="string">"whoami"</span>, val);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> r;</span><br><span class="line"></span><br><span class="line">    cluster_fsid.print(val);</span><br><span class="line">    r = store-&gt;write_meta(<span class="string">"ceph_fsid"</span>, val);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> r;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">string</span> key = cct-&gt;_conf-&gt;get_val&lt;<span class="built_in">string</span>&gt;(<span class="string">"key"</span>);</span><br><span class="line">    <span class="keyword">if</span> (key.size()) &#123;</span><br><span class="line">        r = store-&gt;write_meta(<span class="string">"osd_key"</span>, key);</span><br><span class="line">        <span class="keyword">if</span> (r &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> r;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    r = store-&gt;write_meta(<span class="string">"ready"</span>, <span class="string">"ready"</span>);</span><br><span class="line">    ...    </span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">文件：os/bluestore/BlueStore.cc</span><br><span class="line"><span class="keyword">int</span> BlueStore::write_meta(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; key, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; value)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">bluestore_bdev_label_t</span> label;</span><br><span class="line">    <span class="built_in">string</span> p = path + <span class="string">"/block"</span>;</span><br><span class="line">    <span class="keyword">int</span> r = _read_bdev_label(cct, p, &amp;label);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> ObjectStore::write_meta(key, value);</span><br><span class="line">    &#125;</span><br><span class="line">    label.meta[key] = value;</span><br><span class="line">    r = _write_bdev_label(cct, p, label);</span><br><span class="line">    assert(r == <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> ObjectStore::write_meta(key, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="磁盘分区"><a href="#磁盘分区" class="headerlink" title="磁盘分区"></a>磁盘分区</h4><p>命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create [host] --data [/path/to/device-partition]</span></span><br></pre></td></tr></table></figure>
<p>首先创建磁盘分区：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fdisk -l /dev/sdc</span></span><br><span class="line">...</span><br><span class="line">Disk /dev/sdc: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: gpt</span><br><span class="line">Disk identifier: 84B34A2B-5F0D-4C4F-ADCD-1974B8FD5851</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#         Start          End    Size  Type            Name</span></span><br><span class="line"> 1         2048   7814037134    3.7T  Linux filesyste</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk /dev/sdc</span></span><br><span class="line">NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sdc      8:32   0  3.7T  0 disk</span><br><span class="line">└─sdc1   8:33   0  3.7T  0 part</span><br></pre></td></tr></table></figure>
<blockquote>
<p>请使用gpt分区格式，其他的会报错</p>
</blockquote>
<p>创建OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create ceph0 --data /dev/sdc1</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdc1</span><br><span class="line">...</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: 1</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: None</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm create successful <span class="keyword">for</span>: /dev/sdc1</span><br><span class="line">[ceph0][INFO  ] checking OSD status...</span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /bin/ceph --cluster=ceph osd <span class="built_in">stat</span> --format=json</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph0 is now ready <span class="keyword">for</span> osd use.</span><br></pre></td></tr></table></figure>
<p>检查OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ll /var/lib/ceph/osd/ceph-1/</span></span><br><span class="line">total 48</span><br><span class="line">-rw-r--r-- 1 ceph ceph 393 Apr  2 18:48 activate.monmap</span><br><span class="line">lrwxrwxrwx 1 ceph ceph  93 Apr  2 18:48 block -&gt; /dev/ceph-589101eb-51c3-42b9-adad-915bfccfc4f2/osd-block-8553492d-cb56-4b69-ab9f-d0cfcf0d0970</span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:48 bluefs</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:48 ceph_fsid</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:48 fsid</span><br><span class="line">-rw------- 1 ceph ceph  55 Apr  2 18:48 keyring</span><br><span class="line">-rw-r--r-- 1 ceph ceph   8 Apr  2 18:48 kv_backend</span><br><span class="line">-rw-r--r-- 1 ceph ceph  21 Apr  2 18:48 magic</span><br><span class="line">-rw-r--r-- 1 ceph ceph   4 Apr  2 18:48 mkfs_done</span><br><span class="line">-rw-r--r-- 1 ceph ceph  41 Apr  2 18:48 osd_key</span><br><span class="line">-rw-r--r-- 1 ceph ceph   6 Apr  2 18:48 ready</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  2 18:48 <span class="built_in">type</span></span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:48 whoam</span><br><span class="line"></span><br><span class="line"><span class="comment"># pvs /dev/sdc1</span></span><br><span class="line">  PV         VG                                        Fmt  Attr PSize PFree</span><br><span class="line">  /dev/sdc1  ceph-589101eb-51c3-42b9-adad-915bfccfc4f2 lvm2 a--  3.64t    0</span><br><span class="line"></span><br><span class="line"><span class="comment"># lvs ceph-589101eb-51c3-42b9-adad-915bfccfc4f2</span></span><br><span class="line">  LV                                             VG                                        Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  osd-block-8553492d-cb56-4b69-ab9f-d0cfcf0d0970 ceph-589101eb-51c3-42b9-adad-915bfccfc4f2 -wi-ao---- 3.64t</span><br></pre></td></tr></table></figure>
<p><strong>结论：</strong></p>
<ul>
<li>与使用整块磁盘基本一样，不同的只是用磁盘分区创建一个PV</li>
</ul>
<h4 id="逻辑卷"><a href="#逻辑卷" class="headerlink" title="逻辑卷"></a>逻辑卷</h4><p>命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create [host] --data [vg/lv]</span></span><br></pre></td></tr></table></figure>
<p>首先创建一个逻辑卷：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pvcreate /dev/sdd</span></span><br><span class="line">  Physical volume <span class="string">"/dev/sdd"</span> successfully created.</span><br><span class="line"></span><br><span class="line"><span class="comment"># vgcreate sddvg /dev/sdd</span></span><br><span class="line">  Volume group <span class="string">"sddvg"</span> successfully created</span><br><span class="line"></span><br><span class="line"><span class="comment"># lvcreate -n sddlv -l 100%FREE sddvg</span></span><br><span class="line">  Logical volume <span class="string">"sddlv"</span> created.</span><br></pre></td></tr></table></figure>
<p>创建OSD：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create ceph0 --data sddvg/sddlv</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data sddvg/sddlv</span><br><span class="line">...</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: 2</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: None</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm create successful <span class="keyword">for</span>: sddvg/sddlv</span><br><span class="line">[ceph0][INFO  ] checking OSD status...</span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /bin/ceph --cluster=ceph osd <span class="built_in">stat</span> --format=json</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph0 is now ready <span class="keyword">for</span> osd use.</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>若指定<code>--data /dev/sddvg/sddlv</code>，命令会报错，会被认为是block device</p>
</blockquote>
<p>检查OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ll /var/lib/ceph/osd/ceph-2/</span></span><br><span class="line">total 48</span><br><span class="line">-rw-r--r-- 1 ceph ceph 393 Apr  2 18:55 activate.monmap</span><br><span class="line">lrwxrwxrwx 1 ceph ceph  16 Apr  2 18:55 block -&gt; /dev/sddvg/sddlv</span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:55 bluefs</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:55 ceph_fsid</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  2 18:55 fsid</span><br><span class="line">-rw------- 1 ceph ceph  55 Apr  2 18:55 keyring</span><br><span class="line">-rw-r--r-- 1 ceph ceph   8 Apr  2 18:55 kv_backend</span><br><span class="line">-rw-r--r-- 1 ceph ceph  21 Apr  2 18:55 magic</span><br><span class="line">-rw-r--r-- 1 ceph ceph   4 Apr  2 18:55 mkfs_done</span><br><span class="line">-rw-r--r-- 1 ceph ceph  41 Apr  2 18:55 osd_key</span><br><span class="line">-rw-r--r-- 1 ceph ceph   6 Apr  2 18:55 ready</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  2 18:55 <span class="built_in">type</span></span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  2 18:55 whoami</span><br></pre></td></tr></table></figure>
<p><strong>结论：</strong></p>
<ul>
<li>与前两个一致，区别只是自己收到创建了PV，VG，LV</li>
</ul>
<h3 id="指定block-wal和block-db设备创建OSD"><a href="#指定block-wal和block-db设备创建OSD" class="headerlink" title="指定block.wal和block.db设备创建OSD"></a>指定block.wal和block.db设备创建OSD</h3><p>当指定<code>block.wal</code>或<code>block.db</code>时，对应的设备可以为两种：</p>
<ol>
<li>物理磁盘，但必须是一个磁盘分区</li>
<li>逻辑卷（a logical volume of LVM）</li>
</ol>
<p>这里只区分指定的<code>block.wal</code>或<code>block.db</code>设备，data设备选择整块磁盘。</p>
<p><strong>bluestore的<code>block.db</code>和<code>block.wal</code>大小</strong></p>
<p>默认值如下，db size = 0，wal size = 100663296，都比较小。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-conf --show-config | grep bluestore_block</span></span><br><span class="line">bluestore_block_create = <span class="literal">true</span></span><br><span class="line">bluestore_block_db_create = <span class="literal">false</span></span><br><span class="line">bluestore_block_db_path =</span><br><span class="line">bluestore_block_db_size = 0</span><br><span class="line">bluestore_block_path =</span><br><span class="line">bluestore_block_preallocate_file = <span class="literal">false</span></span><br><span class="line">bluestore_block_size = 10737418240</span><br><span class="line">bluestore_block_wal_create = <span class="literal">false</span></span><br><span class="line">bluestore_block_wal_path =</span><br><span class="line">bluestore_block_wal_size = 100663296</span><br></pre></td></tr></table></figure>
<p>参考：<a href="https://marc.info/?l=ceph-devel&amp;m=149978799900866&amp;w=2" target="_blank" rel="noopener">https://marc.info/?l=ceph-devel&amp;m=149978799900866&amp;w=2</a></p>
<p>对<code>block.db</code>和<code>block.wal</code>的大小要求也都比较小，后续测试我们选择<code>block.db</code>和<code>block.wal</code>为10G。</p>
<h4 id="磁盘分区-1"><a href="#磁盘分区-1" class="headerlink" title="磁盘分区"></a>磁盘分区</h4><p>命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create [host] --data [/path/to/device] --block-db [/path/to/device-partition] --block-wal [/path/to/device-partition]</span></span><br></pre></td></tr></table></figure>
<p>首先创建两个磁盘分区给block.wal和block.db使用：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parted -s /dev/sdf print</span></span><br><span class="line">Model: ATA INTEL SSDSC2BB48 (scsi)</span><br><span class="line">Disk /dev/sdf: 480GB</span><br><span class="line">Sector size (logical/physical): 512B/4096B</span><br><span class="line">Partition Table: gpt</span><br><span class="line">Disk Flags:</span><br><span class="line"></span><br><span class="line">Number  Start   End     Size    File system  Name  Flags</span><br><span class="line"> 1      1049kB  10.7GB  10.7GB</span><br><span class="line"> 2      10.7GB  21.5GB  10.7GB</span><br></pre></td></tr></table></figure>
<p>创建OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy disk zap ceph0 /dev/sde</span></span><br><span class="line"><span class="comment"># ceph-deploy osd create ceph0 --data /dev/sde --block-db /dev/sdf1 --block-wal /dev/sdf2</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sde --block.wal /dev/sdf2 --block.db /dev/sdf1</span><br><span class="line">...</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: 3</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: None</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm create successful <span class="keyword">for</span>: /dev/sde</span><br><span class="line">[ceph0][INFO  ] checking OSD status...</span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /bin/ceph --cluster=ceph osd <span class="built_in">stat</span> --format=json</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph0 is now ready <span class="keyword">for</span> osd use.</span><br></pre></td></tr></table></figure>
<p>检查OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df -h</span></span><br><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">...</span><br><span class="line">tmpfs                 16G   56K   16G   1% /var/lib/ceph/osd/ceph-3</span><br><span class="line"></span><br><span class="line"><span class="comment"># ll /var/lib/ceph/osd/ceph-3</span></span><br><span class="line">total 56</span><br><span class="line">-rw-r--r-- 1 ceph ceph 393 Apr  3 09:20 activate.monmap</span><br><span class="line">lrwxrwxrwx 1 ceph ceph  93 Apr  3 09:20 block -&gt; /dev/ceph-7777d5e4-9b81-4c17-916d-7a1e48f6268e/osd-block-3ed97688-03b4-4ca6-a497-bbd30e865852</span><br><span class="line">lrwxrwxrwx 1 root root   9 Apr  3 09:20 block.db -&gt; /dev/sdf1</span><br><span class="line">lrwxrwxrwx 1 root root   9 Apr  3 09:20 block.wal -&gt; /dev/sdf2</span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  3 09:20 bluefs</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  3 09:20 ceph_fsid</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  3 09:20 fsid</span><br><span class="line">-rw------- 1 ceph ceph  55 Apr  3 09:20 keyring</span><br><span class="line">-rw-r--r-- 1 ceph ceph   8 Apr  3 09:20 kv_backend</span><br><span class="line">-rw-r--r-- 1 ceph ceph  21 Apr  3 09:20 magic</span><br><span class="line">-rw-r--r-- 1 ceph ceph   4 Apr  3 09:20 mkfs_done</span><br><span class="line">-rw-r--r-- 1 ceph ceph  41 Apr  3 09:20 osd_key</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  3 09:20 path_block.db</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  3 09:20 path_block.wal</span><br><span class="line">-rw-r--r-- 1 ceph ceph   6 Apr  3 09:20 ready</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  3 09:20 <span class="built_in">type</span></span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  3 09:20 whoami</span><br></pre></td></tr></table></figure>
<p><strong>结论：</strong></p>
<ul>
<li>与使用单块盘基本一样，不同的只是指定了<code>block.db -&gt; /dev/sdf1</code>和<code>block.wal -&gt; /dev/sdf2</code></li>
</ul>
<h4 id="逻辑卷-1"><a href="#逻辑卷-1" class="headerlink" title="逻辑卷"></a>逻辑卷</h4><p>命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy osd create [host] --data [/path/to/device] --block-db [vg/lv]  --block-wal [vg/lv]</span></span><br></pre></td></tr></table></figure>
<p>首先创建两个逻辑卷给block.wal和block.db使用：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pvcreate /dev/sdm</span></span><br><span class="line"><span class="comment"># vgcreate ssdvg /dev/sdm</span></span><br><span class="line"><span class="comment"># lvcreate -n db-lv-0 -L 4G ssdvg</span></span><br><span class="line"><span class="comment"># lvcreate -n wal-lv-0 -L 8G ssdvg</span></span><br></pre></td></tr></table></figure>
<p>创建OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy disk zap ceph0 /dev/sdg</span></span><br><span class="line"><span class="comment"># ceph-deploy osd create ceph0 --data /dev/sdg --block-db ssdvg/db-lv-0 --block-wal ssdvg/wal-lv-0</span></span><br><span class="line">...</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdg --block.wal ssdvg/wal-lv-0 --block.db ssdvg/db-lv-0</span><br><span class="line">...</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: 4</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm activate successful <span class="keyword">for</span> osd ID: None</span><br><span class="line">[ceph0][DEBUG ] --&gt; ceph-volume lvm create successful <span class="keyword">for</span>: /dev/sdg</span><br><span class="line">[ceph0][INFO  ] checking OSD status...</span><br><span class="line">[ceph0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph0][INFO  ] Running <span class="built_in">command</span>: /bin/ceph --cluster=ceph osd <span class="built_in">stat</span> --format=json</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph0 is now ready <span class="keyword">for</span> osd use.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>若指定<code>--block-db /dev/ssdvg/db-lv-0 --block-wal /dev/ssdvg/wal-lv-0</code>，命令会报错</p>
</blockquote>
<p>检查OSD：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df -h</span></span><br><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">...</span><br><span class="line">tmpfs                 16G   56K   16G   1% /var/lib/ceph/osd/ceph-4</span><br><span class="line"></span><br><span class="line"><span class="comment"># ll /var/lib/ceph/osd/ceph-4</span></span><br><span class="line">total 56</span><br><span class="line">-rw-r--r-- 1 ceph ceph 393 Apr  3 09:30 activate.monmap</span><br><span class="line">lrwxrwxrwx 1 ceph ceph  93 Apr  3 09:30 block -&gt; /dev/ceph-017b646a-0332-4677-967b-95033a3a33ab/osd-block-24228535-1fb3-4bcd-bb87-f6d5f49ed24d</span><br><span class="line">lrwxrwxrwx 1 root root  18 Apr  3 09:30 block.db -&gt; /dev/ssdvg/db-lv-0</span><br><span class="line">lrwxrwxrwx 1 root root  19 Apr  3 09:30 block.wal -&gt; /dev/ssdvg/wal-lv-0</span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  3 09:30 bluefs</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  3 09:30 ceph_fsid</span><br><span class="line">-rw-r--r-- 1 ceph ceph  37 Apr  3 09:30 fsid</span><br><span class="line">-rw------- 1 ceph ceph  55 Apr  3 09:30 keyring</span><br><span class="line">-rw-r--r-- 1 ceph ceph   8 Apr  3 09:30 kv_backend</span><br><span class="line">-rw-r--r-- 1 ceph ceph  21 Apr  3 09:30 magic</span><br><span class="line">-rw-r--r-- 1 ceph ceph   4 Apr  3 09:30 mkfs_done</span><br><span class="line">-rw-r--r-- 1 ceph ceph  41 Apr  3 09:30 osd_key</span><br><span class="line">-rw-r--r-- 1 ceph ceph  19 Apr  3 09:30 path_block.db</span><br><span class="line">-rw-r--r-- 1 ceph ceph  20 Apr  3 09:30 path_block.wal</span><br><span class="line">-rw-r--r-- 1 ceph ceph   6 Apr  3 09:30 ready</span><br><span class="line">-rw-r--r-- 1 ceph ceph  10 Apr  3 09:30 <span class="built_in">type</span></span><br><span class="line">-rw-r--r-- 1 ceph ceph   2 Apr  3 09:30 whoami</span><br></pre></td></tr></table></figure>
<p><strong>结论：</strong></p>
<ul>
<li>与使用单块盘基本一样，不同的只是指定了<code>block.db -&gt; /dev/ssdvg/db-lv-0</code>和<code>block.wal -&gt; /dev/ssdvg/wal-lv-0</code></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/03/26/lvm-sata-ssd-bcache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/26/lvm-sata-ssd-bcache/" itemprop="url">SSD加速SATA盘之bcache策略</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-26T22:18:27+08:00">
                2018-03-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/storage/" itemprop="url" rel="index">
                    <span itemprop="name">storage</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/26/lvm-sata-ssd-bcache/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/03/26/lvm-sata-ssd-bcache/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在前面的文章中介绍了<a href="http://www.yangguanjun.com/2018/03/08/ssd-enhance-sata-with-flashcache/"> SSD加速SATA盘之flashcache策略</a>。<br>一般我们也推荐选择稳定的flashcache策略来做SSD加速SATA盘，但在实践中，发现其在CentOS上编译安装还是很麻烦的，这里就抓紧研究实践了下bcache策略。</p>
<p>另外bcache使用可以用一块SSD来缓存多块SATA盘，对于使用中随时变动磁盘的应用场景来说，操作非常便捷。</p>
<p>并且官网说bcache的性能完全优于flashcache，参考：</p>
<p><a href="http://www.accelcloud.com/2012/04/18/linux-flashcache-and-bcache-performance-testing/" target="_blank" rel="noopener">http://www.accelcloud.com/2012/04/18/linux-flashcache-and-bcache-performance-testing/</a></p>
<h2 id="Bcache"><a href="#Bcache" class="headerlink" title="Bcache"></a>Bcache</h2><p>介绍：</p>
<p><a href="https://wiki.archlinux.org/index.php/Bcache" target="_blank" rel="noopener">https://wiki.archlinux.org/index.php/Bcache</a></p>
<p><a href="https://bcache.evilpiepirate.org/" target="_blank" rel="noopener">https://bcache.evilpiepirate.org/</a></p>
<p>Bcache在Linux kernel 3.10版本加入了mainline，使用它只需要主机的kernel版本大于3.10即可。</p>
<p>bcache-tools 源码：<a href="https://evilpiepirate.org/git/bcache-tools.git" target="_blank" rel="noopener">https://evilpiepirate.org/git/bcache-tools.git</a></p>
<h3 id="Ubuntu上安装"><a href="#Ubuntu上安装" class="headerlink" title="Ubuntu上安装"></a>Ubuntu上安装</h3><h4 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:    Ubuntu</span><br><span class="line">Description:    Ubuntu 16.04.2 LTS</span><br><span class="line">Release:    16.04</span><br><span class="line">Codename:    xenial</span><br><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.4.0-72-generic</span><br></pre></td></tr></table></figure>
<h4 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h4><p>加载系统的bcache module：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsmod | grep bcache</span></span><br><span class="line"><span class="comment"># modprobe bcache</span></span><br><span class="line"><span class="comment"># lsmod | grep bcache</span></span><br></pre></td></tr></table></figure>
<p>编译安装bcace-tools：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt-get install -y pkg-config libblkid-dev</span></span><br><span class="line"><span class="comment"># git clone https://evilpiepirate.org/git/bcache-tools.git</span></span><br><span class="line"><span class="comment"># cd bcache-tools</span></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`   -c -o bcache.o bcache.c</span><br><span class="line">bcache.c:125:9: warning: ‘crc_table’ is static but used <span class="keyword">in</span> inline <span class="keyword">function</span> ‘crc64’ <span class="built_in">which</span> is not static</span><br><span class="line">   crc = crc_table[i] ^ (crc &lt;&lt; 8);</span><br><span class="line">         ^</span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`    make-bcache.c bcache.o  `pkg-config --libs uuid blkid` -o make-bcache</span><br><span class="line">/tmp/ccW6rXtD.o: In <span class="keyword">function</span> `write_sb<span class="string">':</span></span><br><span class="line"><span class="string">/root/yangguanjun/bcache-tools/make-bcache.c:277: undefined reference to `crc64'</span></span><br><span class="line">collect2: error: ld returned 1 <span class="built_in">exit</span> status</span><br><span class="line">&lt;<span class="built_in">builtin</span>&gt;: recipe <span class="keyword">for</span> target <span class="string">'make-bcache'</span> failed</span><br><span class="line">make: *** [make-bcache] Error 1</span><br></pre></td></tr></table></figure>
<p>网上搜索有这个bug的fix，如下：</p>
<p><a href="https://www.spinics.net/lists/linux-bcache/msg02847.html" target="_blank" rel="noopener">https://www.spinics.net/lists/linux-bcache/msg02847.html</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--- a/bcache.c</span><br><span class="line">+++ b/bcache.c</span><br><span class="line"></span><br><span class="line">@@ -115,7 +115,7 @@ static const uint64_t crc_table[256] = &#123;</span><br><span class="line">       0x9AFCE626CE85B507ULL</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">-inline uint64_t crc64(const void *_data, size_t len)</span><br><span class="line">+uint64_t crc64(const void *_data, size_t len)</span><br><span class="line">&#123;</span><br><span class="line">       uint64_t crc = 0xFFFFFFFFFFFFFFFFULL;</span><br><span class="line">       const unsigned char *data = _data;</span><br></pre></td></tr></table></figure>
<p>按上面patch修改bcache.c后，编译安装正常。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make</span></span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`   -c -o bcache.o bcache.c</span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`    make-bcache.c bcache.o  `pkg-config --libs uuid blkid` -o make-bcache</span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`    probe-bcache.c  `pkg-config --libs uuid blkid` -o probe-bcache</span><br><span class="line">cc -O2 -Wall -g -std=gnu99    bcache-super-show.c bcache.o  `pkg-config --libs uuid` -o bcache-super-show</span><br><span class="line">cc -O2 -Wall -g   -c -o bcache-register.o bcache-register.c</span><br><span class="line">cc   bcache-register.o   -o bcache-register</span><br><span class="line"><span class="comment"># make install</span></span><br><span class="line">install -m0755 make-bcache bcache-super-show    /usr/sbin/</span><br><span class="line">install -m0755 probe-bcache bcache-register        /lib/udev/</span><br><span class="line">install -m0644 69-bcache.rules    /lib/udev/rules.d/</span><br><span class="line">install -m0644 -- *.8 /usr/share/man/man8/</span><br><span class="line">install -D -m0755 initramfs/hook    /usr/share/initramfs-tools/hooks/bcache</span><br><span class="line">install -D -m0755 initcpio/install    /usr/lib/initcpio/install/bcache</span><br><span class="line">install -D -m0755 dracut/module-setup.sh /lib/dracut/modules.d/90bcache/module-setup.sh</span><br></pre></td></tr></table></figure>
<h3 id="CentOS上安装"><a href="#CentOS上安装" class="headerlink" title="CentOS上安装"></a>CentOS上安装</h3><p>因为bcache在kernel 3.10版本才进入主线，所以我们要保证CentOS的内核版本大于3.10，所以CenOS 6就不要尝试了，直接用新的CentOS 7吧。</p>
<h4 id="系统信息-1"><a href="#系统信息-1" class="headerlink" title="系统信息"></a>系统信息</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line">LSB Version:    :core-4.1-amd64:core-4.1-noarch</span><br><span class="line">Distributor ID:    CentOS</span><br><span class="line">Description:    CentOS Linux release 7.3.1611 (Core)</span><br><span class="line">Release:    7.3.1611</span><br><span class="line">Codename:    Core</span><br><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">3.10.0-693.17.1.el7.x86_64</span><br></pre></td></tr></table></figure>
<h4 id="编译安装-1"><a href="#编译安装-1" class="headerlink" title="编译安装"></a>编译安装</h4><p>加载系统的bcache模块：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsmod | grep bcache</span></span><br><span class="line"><span class="comment"># modprobe bcache</span></span><br><span class="line">modprobe: FATAL: Module bcache not found.</span><br></pre></td></tr></table></figure>
<p>查看发现在kernel 3.10.0-693 版本里，默认是不编译bcache模块的，参考：</p>
<p><a href="https://lakelight.net/2017/12/20/bcache-centos-7.html" target="_blank" rel="noopener">https://lakelight.net/2017/12/20/bcache-centos-7.html</a></p>
<p>这里就需要下载当前内核版本的源码，重新编译内核bcache模块，然后再加载bcache模块。</p>
<p>鉴于之前CentOS上安装flashcache时探索了内核版本的升级，所以这里在已经升级内核版本的机器上尝试，发现kernel 4.4版本默认已经编译好了bcache模块，所以在CentOS上使用cache时，还是建议升级到4.4版本内核。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.4.115-1.el7.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsmod | grep bcache</span></span><br><span class="line"><span class="comment"># modprobe bcache</span></span><br><span class="line"><span class="comment"># lsmod | grep bcache</span></span><br><span class="line">bcache                233472  0</span><br></pre></td></tr></table></figure>
<p>编译安装bcace-tools：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y git pkgconfig libblkid-devel</span></span><br><span class="line"><span class="comment"># git clone https://evilpiepirate.org/git/bcache-tools.git</span></span><br><span class="line"><span class="comment"># cd bcache-tools/</span></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`   -c -o bcache.o bcache.c</span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`    make-bcache.c bcache.o  `pkg-config --libs uuid blkid` -o make-bcache</span><br><span class="line">cc -O2 -Wall -g `pkg-config --cflags uuid blkid`    probe-bcache.c  `pkg-config --libs uuid blkid` -o probe-bcache</span><br><span class="line">cc -O2 -Wall -g -std=gnu99    bcache-super-show.c bcache.o  `pkg-config --libs uuid` -o bcache-super-show</span><br><span class="line">cc -O2 -Wall -g   -c -o bcache-register.o bcache-register.c</span><br><span class="line">cc   bcache-register.o   -o bcache-register</span><br><span class="line"><span class="comment"># make install</span></span><br><span class="line">install -m0755 make-bcache bcache-super-show    /usr/sbin/</span><br><span class="line">install -m0755 probe-bcache bcache-register        /lib/udev/</span><br><span class="line">install -m0644 69-bcache.rules    /lib/udev/rules.d/</span><br><span class="line">install -m0644 -- *.8 /usr/share/man/man8/</span><br><span class="line">install -D -m0755 initramfs/hook    /usr/share/initramfs-tools/hooks/bcache</span><br><span class="line">install -D -m0755 initcpio/install    /usr/lib/initcpio/install/bcache</span><br><span class="line">install -D -m0755 dracut/module-setup.sh /lib/dracut/modules.d/90bcache/module-setup.sh</span><br></pre></td></tr></table></figure>
<h2 id="Bcache使用"><a href="#Bcache使用" class="headerlink" title="Bcache使用"></a>Bcache使用</h2><p>下面在CentOS机器上，介绍如何使用bcache。</p>
<h3 id="硬盘信息"><a href="#硬盘信息" class="headerlink" title="硬盘信息"></a>硬盘信息</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fdisk -l | grep dev</span></span><br><span class="line">...</span><br><span class="line">Disk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Disk /dev/vdc: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Disk /dev/vdd: 53.7 GB, 53687091200 bytes, 104857600 sectors</span><br></pre></td></tr></table></figure>
<p>这里使用三块盘：vdb、vdc、vdd。</p>
<p>其中vdb、vdc是容量型磁盘，vdd是性能型磁盘，实验用vdd通过bcache加速vdb和vdc。</p>
<h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p>与bcache相关的命令有：<code>make-bcache</code>和<code>bcache-super-show</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache</span></span><br><span class="line">Please supply a device</span><br><span class="line">Usage: make-bcache [options] device</span><br><span class="line">	-C, --cache		Format a cache device</span><br><span class="line">	-B, --bdev		Format a backing device</span><br><span class="line">	-b, --bucket		bucket size</span><br><span class="line">	-w, --block		block size (hard sector size of SSD, often 2k)</span><br><span class="line">	-o, --data-offset	data offset <span class="keyword">in</span> sectors</span><br><span class="line">	    --cset-uuid		UUID <span class="keyword">for</span> the cache <span class="built_in">set</span></span><br><span class="line">	    --writeback		<span class="built_in">enable</span> writeback</span><br><span class="line">	    --discard		<span class="built_in">enable</span> discards</span><br><span class="line">	    --cache_replacement_policy=(lru|fifo)</span><br><span class="line">	-h, --<span class="built_in">help</span>		display this <span class="built_in">help</span> and <span class="built_in">exit</span></span><br><span class="line">	</span><br><span class="line"><span class="comment"># bcache-super-show</span></span><br><span class="line">Usage: bcache-super-show [-f] &lt;device&gt;</span><br></pre></td></tr></table></figure>
<h4 id="创建backing-device"><a href="#创建backing-device" class="headerlink" title="创建backing device"></a>创建backing device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -B /dev/vdb</span></span><br><span class="line">UUID:            c602abab-bf5a-4b51-b7f6-1492d34239f4</span><br><span class="line">Set UUID:        423e1910-f61a-45fa-8cdf-a23aca3b5eb8</span><br><span class="line">version:        1</span><br><span class="line">block_size:        1</span><br><span class="line">data_offset:        16</span><br><span class="line"></span><br><span class="line"><span class="comment"># bcache-super-show /dev/vdb</span></span><br><span class="line">sb.magic		ok</span><br><span class="line">sb.first_sector		8 [match]</span><br><span class="line">sb.csum			1376BA45B5F924B [match]</span><br><span class="line">sb.version		1 [backing device]</span><br><span class="line"></span><br><span class="line">dev.label		(empty)</span><br><span class="line">dev.uuid		c602abab-bf5a-4b51-b7f6-1492d34239f4</span><br><span class="line">dev.sectors_per_block	1</span><br><span class="line">dev.sectors_per_bucket	1024</span><br><span class="line">dev.data.first_sector	16</span><br><span class="line">dev.data.cache_mode	0 [writethrough]</span><br><span class="line">dev.data.cache_state	1 [clean]</span><br><span class="line"></span><br><span class="line">cset.uuid		4b60c663-7720-4dea-a17a-e9316078e796</span><br></pre></td></tr></table></figure>
<h4 id="创建cache-device"><a href="#创建cache-device" class="headerlink" title="创建cache device"></a>创建cache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -C /dev/vdd</span></span><br><span class="line">UUID:            050998ce-403c-45d7-a89b-492379644c1b</span><br><span class="line">Set UUID:        4b60c663-7720-4dea-a17a-e9316078e796</span><br><span class="line">version:        0</span><br><span class="line">nbuckets:        102400</span><br><span class="line">block_size:        1</span><br><span class="line">bucket_size:        1024</span><br><span class="line">nr_in_set:        1</span><br><span class="line">nr_this_dev:        0</span><br><span class="line">first_bucket:        1</span><br><span class="line"></span><br><span class="line"><span class="comment"># bcache-super-show /dev/vdd</span></span><br><span class="line">sb.magic        ok</span><br><span class="line">sb.first_sector        8 [match]</span><br><span class="line">sb.csum            68CDDDC337A2E296 [match]</span><br><span class="line">sb.version        3 [cache device]</span><br><span class="line"></span><br><span class="line">dev.label        (empty)</span><br><span class="line">dev.uuid        050998ce-403c-45d7-a89b-492379644c1b</span><br><span class="line">dev.sectors_per_block    1</span><br><span class="line">dev.sectors_per_bucket    1024</span><br><span class="line">dev.cache.first_sector    1024</span><br><span class="line">dev.cache.cache_sectors    104856576</span><br><span class="line">dev.cache.total_sectors    104857600</span><br><span class="line">dev.cache.ordered    yes</span><br><span class="line">dev.cache.discard    no</span><br><span class="line">dev.cache.pos        0</span><br><span class="line">dev.cache.replacement    0 [lru]</span><br><span class="line"></span><br><span class="line">cset.uuid        4b60c663-7720-4dea-a17a-e9316078e796</span><br></pre></td></tr></table></figure>
<h4 id="绑定backing-device到cache-device"><a href="#绑定backing-device到cache-device" class="headerlink" title="绑定backing device到cache device"></a>绑定backing device到cache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo "4b60c663-7720-4dea-a17a-e9316078e796" &gt; /sys/block/bcache0/bcache/attach</span></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br></pre></td></tr></table></figure>
<h4 id="查看bcache相关信息"><a href="#查看bcache相关信息" class="headerlink" title="查看bcache相关信息"></a>查看bcache相关信息</h4><p>1、state</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /sys/block/bcache0/bcache/state</span></span><br><span class="line">clean</span><br></pre></td></tr></table></figure>
<p>state的几个状态：</p>
<ul>
<li>no cache：该backing device没有attach任何caching device</li>
<li>clean：一切正常，缓存是干净的</li>
<li>dirty：一切正常，已启用回写，缓存是脏的</li>
<li>inconsistent：遇到问题，后台设备与缓存设备不同步</li>
</ul>
<p>2、缓存数据量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /sys/block/bcache0/bcache/dirty_data</span></span><br><span class="line">0.0k</span><br></pre></td></tr></table></figure>
<p>3、缓存模式</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /sys/block/bcache0/bcache/cache_mode</span></span><br><span class="line">[writethrough] writeback writearound none</span><br><span class="line"><span class="comment"># echo writearound &gt; /sys/block/bcache0/bcache/cache_mode</span></span><br><span class="line"><span class="comment"># cat /sys/block/bcache0/bcache/cache_mode</span></span><br><span class="line">writethrough writeback [writearound] none</span><br></pre></td></tr></table></figure>
<p>4、writeback信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /sys/block/bcache0/bcache/writeback_</span></span><br><span class="line">writeback_delay                writeback_percent              writeback_rate_debug           writeback_rate_p_term_inverse  writeback_running</span><br><span class="line">writeback_metadata             writeback_rate                 writeback_rate_d_term          writeback_rate_update_seconds</span><br></pre></td></tr></table></figure>
<h4 id="解绑backing-device的cache-device"><a href="#解绑backing-device的cache-device" class="headerlink" title="解绑backing device的cache device"></a>解绑backing device的cache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo "697b764f-b3ef-4675-8761-d9518a12089c" &gt; /sys/block/bcache0/bcache/detach</span></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /sys/block/vdb/bcache/state</span></span><br><span class="line">no cache</span><br></pre></td></tr></table></figure>
<blockquote>
<p>解绑后设备可以继续使用，只是没有cache device的加速</p>
</blockquote>
<h4 id="添加新backing-device"><a href="#添加新backing-device" class="headerlink" title="添加新backing device"></a>添加新backing device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -B /dev/vdc</span></span><br><span class="line">UUID:            cc790e62-b3eb-4237-8265-dd1b619e15c0</span><br><span class="line">Set UUID:        edb2b1d0-9eeb-4a8a-b811-3dafd676fac0</span><br><span class="line">version:        1</span><br><span class="line">block_size:        1</span><br><span class="line">data_offset:        16</span><br><span class="line"></span><br><span class="line"><span class="comment"># echo "4b60c663-7720-4dea-a17a-e9316078e796" &gt; /sys/block/bcache1/bcache/attach</span></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">└─bcache1 251:1    0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line">└─bcache1 251:1    0  100G  0 disk</span><br></pre></td></tr></table></figure>
<h4 id="使用bcache-device"><a href="#使用bcache-device" class="headerlink" title="使用bcache device"></a>使用bcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkfs.ext4 /dev/bcache1</span></span><br><span class="line"><span class="comment"># mount /dev/bcache1 /mnt/</span></span><br><span class="line"><span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">...</span><br><span class="line">/dev/bcache1     99G   61M   94G   1% /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># umount /mnt/</span></span><br></pre></td></tr></table></figure>
<h4 id="注销bcache-device"><a href="#注销bcache-device" class="headerlink" title="注销bcache device"></a>注销bcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo 1 &gt; /sys/block/vdc/bcache/stop</span></span><br><span class="line"><span class="comment"># echo 1 &gt; /sys/block/vdb/bcache/stop</span></span><br><span class="line"><span class="comment"># echo 1 &gt; /sys/fs/bcache/10057a1c-15a2-4631-a6d2-f4652d37645d/unregister</span></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb    253:16   0  100G  0 disk</span><br><span class="line">vdc    253:32   0  100G  0 disk</span><br><span class="line">vdd    253:48   0   50G  0 disk</span><br></pre></td></tr></table></figure>
<blockquote>
<p>echo的数字不重要，可为任何值 ;)</p>
</blockquote>
<h4 id="快捷创建bcache-device"><a href="#快捷创建bcache-device" class="headerlink" title="快捷创建bcache device"></a>快捷创建bcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -B /dev/vdb /dev/vdc -C /dev/vdd</span></span><br><span class="line">UUID:			09f971eb-6063-4f94-bdac-d7d7117c0e0f</span><br><span class="line">Set UUID:		697b764f-b3ef-4675-8761-d9518a12089c</span><br><span class="line">version:		0</span><br><span class="line">nbuckets:		102400</span><br><span class="line">block_size:		1</span><br><span class="line">bucket_size:		1024</span><br><span class="line">nr_in_set:		1</span><br><span class="line">nr_this_dev:		0</span><br><span class="line">first_bucket:		1</span><br><span class="line">UUID:			b45301fa-8932-4194-9518-ab681f37d9c9</span><br><span class="line">Set UUID:		697b764f-b3ef-4675-8761-d9518a12089c</span><br><span class="line">version:		1</span><br><span class="line">block_size:		1</span><br><span class="line">data_offset:		16</span><br><span class="line">UUID:			2c0452f7-76de-4319-bd3c-2a73b4fa4b68</span><br><span class="line">Set UUID:		697b764f-b3ef-4675-8761-d9518a12089c</span><br><span class="line">version:		1</span><br><span class="line">block_size:		1</span><br><span class="line">data_offset:		16</span><br><span class="line">[root@lvm-centos-tst ~]<span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">└─bcache1 251:1    0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line">├─bcache0 251:0    0  100G  0 disk</span><br><span class="line">└─bcache1 251:1    0  100G  0 disk</span><br></pre></td></tr></table></figure>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="make-bcache命令有提示"><a href="#make-bcache命令有提示" class="headerlink" title="make-bcache命令有提示"></a>make-bcache命令有提示</h4><p>之前做过bcache的device，重做bcache有提示</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make-bcache -B /dev/vdb</span></span><br><span class="line">Already a bcache device on /dev/vdb, overwrite with --wipe-bcache</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk</span><br></pre></td></tr></table></figure>
<blockquote>
<p>虽说有提示，但实际bcache device已经创建成果</p>
</blockquote>
<p>针对上述情况，可以通过写device前一部分数据的方法解决</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">可以通过dd命令来清理device的前部分数据：</span><br><span class="line"><span class="comment"># dd if=/dev/zero of=/dev/vdb bs=1M count=100 oflag=direct</span></span><br><span class="line"><span class="comment"># dd if=/dev/zero of=/dev/vdd bs=1M count=100 oflag=direct</span></span><br><span class="line"></span><br><span class="line">再创建bcache device，就不会报错了：</span><br><span class="line"><span class="comment"># make-bcache -B /dev/vdb</span></span><br><span class="line">UUID:            c602abab-bf5a-4b51-b7f6-1492d34239f4</span><br><span class="line">Set UUID:        423e1910-f61a-45fa-8cdf-a23aca3b5eb8</span><br><span class="line">version:        1</span><br><span class="line">block_size:        1</span><br><span class="line">data_offset:        16</span><br><span class="line"></span><br><span class="line"><span class="comment"># make-bcache -C /dev/vdd</span></span><br><span class="line">UUID:            050998ce-403c-45d7-a89b-492379644c1b</span><br><span class="line">Set UUID:        4b60c663-7720-4dea-a17a-e9316078e796</span><br><span class="line">version:        0</span><br><span class="line">nbuckets:        102400</span><br><span class="line">block_size:        1</span><br><span class="line">bucket_size:        1024</span><br><span class="line">nr_in_set:        1</span><br><span class="line">nr_this_dev:        0</span><br><span class="line">first_bucket:        1</span><br></pre></td></tr></table></figure>
<h4 id="设备没umount就直接注销"><a href="#设备没umount就直接注销" class="headerlink" title="设备没umount就直接注销"></a>设备没umount就直接注销</h4><p>没有umount，注销bcache device后，设备依旧可以使用，umount后设备消失</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk /mnt</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># mount | grep bcache</span></span><br><span class="line">/dev/bcache0 on /mnt <span class="built_in">type</span> ext4 (rw,relatime,seclabel,data=ordered)</span><br><span class="line"></span><br><span class="line"><span class="comment"># echo 1 &gt; /sys/fs/bcache/4b60c663-7720-4dea-a17a-e9316078e796/unregister</span></span><br><span class="line"><span class="comment"># echo 0 &gt; /sys/block/vdb/bcache/stop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb       253:16   0  100G  0 disk</span><br><span class="line">└─bcache0 251:0    0  100G  0 disk /mnt</span><br><span class="line">vdc       253:32   0  100G  0 disk</span><br><span class="line">vdd       253:48   0   50G  0 disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># ls /sys/block/vdb/bcache</span></span><br><span class="line">ls: cannot access /sys/block/vdb/bcache: No such file or directory</span><br><span class="line"></span><br><span class="line"><span class="comment"># cd /mnt/</span></span><br><span class="line"><span class="comment"># touch tstfile</span></span><br><span class="line"><span class="comment"># umount  /mnt/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb    253:16   0  100G  0 disk</span><br><span class="line">vdc    253:32   0  100G  0 disk</span><br><span class="line">vdd    253:48   0   50G  0 disk</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/03/08/ssd-enhance-sata-with-flashcache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/08/ssd-enhance-sata-with-flashcache/" itemprop="url">SSD加速SATA盘之flashcache策略</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-08T22:08:27+08:00">
                2018-03-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/storage/" itemprop="url" rel="index">
                    <span itemprop="name">storage</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/08/ssd-enhance-sata-with-flashcache/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/03/08/ssd-enhance-sata-with-flashcache/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>通常SATA盘的性能比较低，对于大多数应用来说性能不够，但纯SSD的盘又比较昂贵，结合这两种盘的使用策略是业内讨论的一个热点，也有很多成熟的方案来使用。</p>
<p>之前有文章讨论过cache策略，我们这里选择通用的flashcache方案来用SSD盘加速SATA盘。</p>
<h2 id="flashcache"><a href="#flashcache" class="headerlink" title="flashcache"></a>flashcache</h2><p>源码：<a href="https://github.com/facebookarchive/flashcache" target="_blank" rel="noopener">https://github.com/facebookarchive/flashcache</a><br>参考：<a href="http://www.yangguanjun.com/2018/01/30/lvm-with-cache/">http://www.yangguanjun.com/2018/01/30/lvm-with-cache/</a></p>
<h3 id="Ubuntu上安装"><a href="#Ubuntu上安装" class="headerlink" title="Ubuntu上安装"></a>Ubuntu上安装</h3><p>测试使用的是”Ubuntu 16.04.2 LTS”，它的内核比较新，所以这里编译安装flashcache很方便。</p>
<h4 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	Ubuntu</span><br><span class="line">Description:	Ubuntu 16.04.2 LTS</span><br><span class="line">Release:	16.04</span><br><span class="line">Codename:	xenial</span><br><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.4.0-62-generic</span><br></pre></td></tr></table></figure>
<h4 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt install -y git make gcc</span></span><br><span class="line"><span class="comment"># git clone git@github.com:facebookarchive/flashcache.git</span></span><br><span class="line"><span class="comment"># cd flashcache/</span></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line"><span class="comment"># make install</span></span><br><span class="line"><span class="comment"># modprobe flashcache</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /proc/flashcache/flashcache_version</span></span><br><span class="line">Flashcache Version : flashcache-3.1.1</span><br><span class="line">git commit: 1.0-248-g437afbfe233e</span><br><span class="line"></span><br><span class="line"><span class="comment"># flashcache_</span></span><br><span class="line">flashcache_create    flashcache_destroy   flashcache_load      flashcache_setioctl</span><br></pre></td></tr></table></figure>
<h3 id="CentOS上安装"><a href="#CentOS上安装" class="headerlink" title="CentOS上安装"></a>CentOS上安装</h3><p>测试使用的是”CentOS Linux release 7.3.1611”，它的内核比较旧，在安装flashcache时遇到很多问题。</p>
<h4 id="系统信息-1"><a href="#系统信息-1" class="headerlink" title="系统信息"></a>系统信息</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line">...</span><br><span class="line">Distributor ID:    CentOS</span><br><span class="line">Description:    CentOS Linux release 7.3.1611 (Core)</span><br><span class="line">Release:    7.3.1611</span><br><span class="line">Codename:    Core</span><br><span class="line"></span><br><span class="line"><span class="comment"># uname -a</span></span><br><span class="line">Linux xs732 3.10.0-514.el7.x86_64 <span class="comment">#1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>
<h4 id="编译安装-1"><a href="#编译安装-1" class="headerlink" title="编译安装"></a>编译安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y git make gcc </span></span><br><span class="line"><span class="comment"># git clone git@github.com:facebookarchive/flashcache.git</span></span><br><span class="line"><span class="comment"># cd flashcache</span></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line">...</span><br><span class="line">/root/yangguanjun/flashcache/src/flashcache_conf.c:1230:11: error: too many arguments to <span class="keyword">function</span> ‘wait_on_bit_lock’</span><br><span class="line">           flashcache_wait_schedule, TASK_UNINTERRUPTIBLE);</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>网上可搜索到该问题：<a href="https://github.com/facebookarchive/flashcache/issues/191" target="_blank" rel="noopener">https://github.com/facebookarchive/flashcache/issues/191</a></p>
<h4 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h4><p>尝试升级CentOS的内核版本，但是编译flashcache还是一样的错误。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum update</span></span><br><span class="line"><span class="comment"># uname -a</span></span><br><span class="line">Linux server0 3.10.0-693.17.1.el7.x86_64 <span class="comment">#1 SMP Thu Jan 25 20:13:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>
<p>无奈，选择升级CentOS内核到最新版本4.15。</p>
<p>参考：<a href="http://www.jiagoumi.com/work/1167.html" target="_blank" rel="noopener">http://www.jiagoumi.com/work/1167.html</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">先导入elrepo的key，然后安装elrepo的yum源：</span><br><span class="line"><span class="comment"># rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br><span class="line"><span class="comment"># rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</span></span><br><span class="line"></span><br><span class="line">列出可用的内核相关包：</span><br><span class="line"><span class="comment"># yum --disablerepo="*" --enablerepo="elrepo-kernel" list available</span></span><br><span class="line">…</span><br><span class="line">kernel-lt.x86_64               4.4.115-1.el7.elrepo                  elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-devel.x86_64         4.4.115-1.el7.elrepo                  elrepo-kernel</span><br><span class="line">...</span><br><span class="line">kernel-ml.x86_64               4.15.1-1.el7.elrepo                   elrepo-kernel</span><br><span class="line">kernel-ml-devel.x86_64         4.15.1-1.el7.elrepo                   elrepo-kernel</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">安装最新的主线稳定内核：</span><br><span class="line"><span class="comment"># yum -y --enablerepo=elrepo-kernel install kernel-ml.x86_64 kernel-ml-devel.x86_64</span></span><br><span class="line"></span><br><span class="line">查看系统kernel默认启动顺序：</span><br><span class="line"><span class="comment"># awk -F\' '$1=="menuentry " &#123;print $2&#125;' /etc/grub2.cfg</span></span><br><span class="line">CentOS Linux (4.15.1-1.el7.elrepo.x86_64) 7 (Core)</span><br><span class="line">CentOS Linux (3.10.0-514.el7.x86_64) 7 (Core)</span><br><span class="line">CentOS Linux (0-rescue-836c8e52784b401db086b015b56e2fba) 7 (Core)</span><br><span class="line"></span><br><span class="line">修改系统kernel默认启动内核：</span><br><span class="line"><span class="comment"># vim /etc/default/grub</span></span><br><span class="line">...</span><br><span class="line">GRUB_DEFAULT=saved     修改为 0</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">重新创建内核配置：</span><br><span class="line"><span class="comment"># grub2-mkconfig -o /boot/grub2/grub.cfg</span></span><br><span class="line"></span><br><span class="line">重启机器：</span><br><span class="line"><span class="comment"># reboot -nf</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.15.1-1.el7.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line">make -C src KERNEL_TREE=/usr/src/kernels/4.15.1-1.el7.elrepo.x86_64 PWD=/root/flashcache/src all</span><br><span class="line">...</span><br><span class="line">/root/flashcache/src/flashcache_main.c: In <span class="keyword">function</span> ‘dm_io_async_bvec_pl’:</span><br><span class="line">/root/flashcache/src/flashcache_main.c:119:6: error: ‘struct dm_io_request’ has no member named ‘bi_rw’</span><br><span class="line">  iorq.bi_rw = rw;</span><br><span class="line">      ^</span><br><span class="line">/root/flashcache/src/flashcache_main.c: In <span class="keyword">function</span> ‘dm_io_async_bvec’:</span><br><span class="line">/root/flashcache/src/flashcache_main.c:143:6: error: ‘struct dm_io_request’ has no member named ‘bi_rw’</span><br><span class="line">  iorq.bi_rw = rw;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>很无语，最新kernel的4.15版本竟然也编译不过flashcache。</p>
<p>查看之前编译安装flashcache成功的Ubuntu平台上的内核版本为：4.4.0-62-generic，最后决定尝试 4.4的kernel版本，步骤与上面的步骤类似，差别如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">重新升级系统内核，选择kernel<span class="_">-lt</span>*</span><br><span class="line"><span class="comment"># yum -y --enablerepo=elrepo-kernel install kernel-lt.x86_64 kernel-lt-devel.x86_64</span></span><br><span class="line"></span><br><span class="line">之后重启机器</span><br><span class="line"></span><br><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.4.115-1.el7.elrepo.x86_64</span><br></pre></td></tr></table></figure>
<p>再尝试编译安装flashcache，一切正常O(∩_∩)O哈哈~</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd flashcache</span></span><br><span class="line"><span class="comment"># make</span></span><br><span class="line"><span class="comment"># make install</span></span><br><span class="line"><span class="comment"># flashcache_</span></span><br><span class="line">flashcache_create    flashcache_destroy   flashcache_load      flashcache_setioctl</span><br></pre></td></tr></table></figure>
<h2 id="flashcache使用"><a href="#flashcache使用" class="headerlink" title="flashcache使用"></a>flashcache使用</h2><h3 id="硬盘信息"><a href="#硬盘信息" class="headerlink" title="硬盘信息"></a>硬盘信息</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fdisk -l | grep dev</span></span><br><span class="line">...</span><br><span class="line">Disk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Disk /dev/vdc: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Disk /dev/vdd: 53.7 GB, 53687091200 bytes, 104857600 sectors</span><br></pre></td></tr></table></figure>
<p>这里使用三块盘：vdb、vdc、vdd。</p>
<p>其中vdb、vdc是容量型磁盘，vdd是性能型磁盘，实验用vdd通过bcache加速vdb和vdc。</p>
<h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p>与flashcache相关的命令好几个，如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flashcache_create</span></span><br><span class="line">Usage: flashcache_create [-v] [-p back|thru|around] [-w] [-b block size] [-m md block size] [-s cache size] [-a associativity] cachedev ssd_devname disk_devname</span><br><span class="line">Usage : flashcache_create Cache Mode back|thru|around is required argument</span><br><span class="line">Usage : flashcache_create Default units <span class="keyword">for</span> -b, -m, -s are sectors, or specify <span class="keyword">in</span> k/M/G. Default associativity is 512.</span><br><span class="line"></span><br><span class="line"><span class="comment"># flashcache_destroy</span></span><br><span class="line">Usage: flashcache_destroy ssd_devname</span><br><span class="line"></span><br><span class="line"><span class="comment"># flashcache_load</span></span><br><span class="line">Usage: flashcache_load ssd_devname [cachedev]</span><br><span class="line"></span><br><span class="line"><span class="comment"># flashcache_setioctl</span></span><br><span class="line">Usage: flashcache_setioctl (-c | -a | -r) (-b pid |-w pid) ssd_devname</span><br></pre></td></tr></table></figure>
<p>另外flashcache是通过device mapper来做的设备映射和缓存，所以对flashcache device的操作命令也有<code>dmsetup</code>，使用如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmsetup</span></span><br><span class="line">Usage:</span><br><span class="line"></span><br><span class="line">dmsetup</span><br><span class="line">        [--version] [-h|--<span class="built_in">help</span> [-c|-C|--columns]]</span><br><span class="line">        [-v|--verbose [-v|--verbose ...]] [-f|--force]</span><br><span class="line">        [--checks] [--manglename &#123;none|hex|auto&#125;]</span><br><span class="line">        [-r|--<span class="built_in">readonly</span>] [--noopencount] [--noflush] [--nolockfs] [--inactive]</span><br><span class="line">        [--udevcookie &lt;cookie&gt;] [--noudevrules] [--noudevsync] [--verifyudev]</span><br><span class="line">        [-y|--yes] [--readahead &#123;[+]&lt;sectors&gt;|auto|none&#125;] [--retry]</span><br><span class="line">        [-c|-C|--columns] [-o &lt;fields&gt;] [-O|--sort &lt;sort_fields&gt;]</span><br><span class="line">        [-S|--select &lt;selection&gt;] [--nameprefixes] [--noheadings]</span><br><span class="line">        [--separator &lt;separator&gt;]</span><br><span class="line"></span><br><span class="line">	<span class="built_in">help</span> [-c|-C|--columns]</span><br><span class="line">	create &lt;dev_name&gt;</span><br><span class="line">	    [-j|--major &lt;major&gt; -m|--minor &lt;minor&gt;]</span><br><span class="line">	    [-U|--uid &lt;uid&gt;] [-G|--gid &lt;gid&gt;] [-M|--mode &lt;octal_mode&gt;]</span><br><span class="line">	    [-u|uuid &lt;uuid&gt;] [--addnodeonresume|--addnodeoncreate]</span><br><span class="line">	    [--readahead &#123;[+]&lt;sectors&gt;|auto|none&#125;]</span><br><span class="line">	    [-n|--notable|--table &#123;&lt;table&gt;|&lt;table_file&gt;&#125;]</span><br><span class="line">	remove [--deferred] [-f|--force] [--retry] &lt;device&gt;</span><br><span class="line">	remove_all [-f|--force]</span><br><span class="line">	<span class="built_in">suspend</span> [--noflush] [--nolockfs] &lt;device&gt;</span><br><span class="line">	resume [--noflush] [--nolockfs] &lt;device&gt;</span><br><span class="line">	       [--addnodeonresume|--addnodeoncreate]</span><br><span class="line">	       [--readahead &#123;[+]&lt;sectors&gt;|auto|none&#125;]</span><br><span class="line">	load &lt;device&gt; [&lt;table&gt;|&lt;table_file&gt;]</span><br><span class="line">	clear &lt;device&gt;</span><br><span class="line">	reload &lt;device&gt; [&lt;table&gt;|&lt;table_file&gt;]</span><br><span class="line">	wipe_table [-f|--force] [--noflush] [--nolockfs] &lt;device&gt;</span><br><span class="line">	rename &lt;device&gt; [--setuuid] &lt;new_name_or_uuid&gt;</span><br><span class="line">	message &lt;device&gt; &lt;sector&gt; &lt;message&gt;</span><br><span class="line">	ls [--target &lt;target_type&gt;] [--<span class="built_in">exec</span> &lt;<span class="built_in">command</span>&gt;] [-o &lt;options&gt;] [--tree]</span><br><span class="line">	info [&lt;device&gt;]</span><br><span class="line">	deps [-o &lt;options&gt;] [&lt;device&gt;]</span><br><span class="line">	stats &lt;<span class="built_in">command</span>&gt; [&lt;options&gt;] [&lt;devices&gt;]</span><br><span class="line">	status [&lt;device&gt;] [--noflush] [--target &lt;target_type&gt;]</span><br><span class="line">	table [&lt;device&gt;] [--target &lt;target_type&gt;] [--showkeys]</span><br><span class="line">	<span class="built_in">wait</span> &lt;device&gt; [&lt;event_nr&gt;] [--noflush]</span><br><span class="line">	mknodes [&lt;device&gt;]</span><br><span class="line">	mangle [&lt;device&gt;]</span><br><span class="line">	udevcreatecookie</span><br><span class="line">	udevreleasecookie [&lt;cookie&gt;]</span><br><span class="line">	udevflags &lt;cookie&gt;</span><br><span class="line">	udevcomplete &lt;cookie&gt;</span><br><span class="line">	udevcomplete_all [&lt;age_in_minutes&gt;]</span><br><span class="line">	udevcookies</span><br><span class="line">	targets</span><br><span class="line">	version</span><br><span class="line">	setgeometry &lt;device&gt; &lt;cyl&gt; &lt;head&gt; &lt;sect&gt; &lt;start&gt;</span><br><span class="line">	splitname &lt;device&gt; [&lt;subsystem&gt;]</span><br><span class="line"></span><br><span class="line">&lt;device&gt; may be device name or -u &lt;uuid&gt; or -j &lt;major&gt; -m &lt;minor&gt;</span><br><span class="line">&lt;mangling_mode&gt; is one of <span class="string">'none'</span>, <span class="string">'auto'</span> and <span class="string">'hex'</span>.</span><br><span class="line">&lt;fields&gt; are comma-separated.  Use <span class="string">'help -c'</span> <span class="keyword">for</span> list.</span><br><span class="line">Table_file contents may be supplied on stdin.</span><br><span class="line">Options are: devno, devname, blkdevname.</span><br><span class="line">Tree specific options are: ascii, utf, vt100; compact, inverted, notrunc;</span><br><span class="line">                           blkdevname, [no]device, active, open, rw and uuid.</span><br></pre></td></tr></table></figure>
<h4 id="磁盘规划"><a href="#磁盘规划" class="headerlink" title="磁盘规划"></a>磁盘规划</h4><p>因为flashcache要求一个ssd_device对应一个sata_device，所以在使用之前，我们要规划好哪些SSD盘做缓存？哪些SATA盘需要做flashcache？以便给出合理规划。</p>
<p>这里我们有一个SSD盘，两个SATA盘，所以把SSD盘分为两个分区。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fdisk /dev/vdd</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># fdisk -l /dev/vdd</span></span><br><span class="line">Disk /dev/vdd: 53.7 GB, 53687091200 bytes, 104857600 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0xa8f11a03</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/vdd1            2048    52430847    26214400   83  Linux</span><br><span class="line">/dev/vdd2        52430848   104857599    26213376   83  Linux</span><br></pre></td></tr></table></figure>
<h4 id="缓存模式"><a href="#缓存模式" class="headerlink" title="缓存模式"></a>缓存模式</h4><p>flashcache支持三种缓存模式：</p>
<ul>
<li>Writeback : 对于写入，首先会写入到Cache中，同时将对于block的元数据dirty bit，但是并不会立即写入后备的device</li>
<li>Writethrough : 对于写入，写入到Cache中，同时也会将数据写入backing device，知道写完backing device，才算写完</li>
<li>Writearound : 写入的时候，绕过Cache，直接写入backing device，即SSD只当读缓存</li>
</ul>
<p>三种缓存模式的区别如下图：</p>
<p><img src="/images/flashcache-cachemodes.png" alt="flashcache-cachemodes"></p>
<h4 id="创建flashcache-device"><a href="#创建flashcache-device" class="headerlink" title="创建flashcache device"></a>创建flashcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">后端设备为一分区：</span><br><span class="line"><span class="comment"># flashcache_create -p back fcache-dev1 /dev/vdd1 /dev/vdb1</span></span><br><span class="line">cachedev fcache-dev1, ssd_devname /dev/vdd1, disk_devname /dev/vdb1 cache mode WRITE_BACK</span><br><span class="line">block_size 8, md_block_size 8, cache_size 0</span><br><span class="line">Flashcache metadata will use 137MB of your 3951MB main memory</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb             253:16   0  100G  0 disk</span><br><span class="line">└─vdb1          253:17   0  100G  0 part</span><br><span class="line">  └─fcache-dev1 252:0    0  100G  0 dm</span><br><span class="line">vdd             253:48   0   50G  0 disk</span><br><span class="line">├─vdd1          253:49   0   25G  0 part</span><br><span class="line">│ └─fcache-dev1 252:0    0  100G  0 dm</span><br><span class="line">└─vdd2          253:50   0   25G  0 part</span><br><span class="line"></span><br><span class="line">后端设备为整块磁盘：</span><br><span class="line"><span class="comment"># flashcache_create -p back fcache-dev2 /dev/vdd2 /dev/vdc</span></span><br><span class="line">cachedev fcache-dev2, ssd_devname /dev/vdd2, disk_devname /dev/vdc cache mode WRITE_BACK</span><br><span class="line">block_size 8, md_block_size 8, cache_size 0</span><br><span class="line">Flashcache metadata will use 137MB of your 3951MB main memory</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb             253:16   0  100G  0 disk</span><br><span class="line">└─vdb1          253:17   0  100G  0 part</span><br><span class="line">  └─fcache-dev1 252:0    0  100G  0 dm</span><br><span class="line">vdc             253:32   0  100G  0 disk</span><br><span class="line">└─fcache-dev2   252:1    0  100G  0 dm</span><br><span class="line">vdd             253:48   0   50G  0 disk</span><br><span class="line">├─vdd1          253:49   0   25G  0 part</span><br><span class="line">│ └─fcache-dev1 252:0    0  100G  0 dm</span><br><span class="line">└─vdd2          253:50   0   25G  0 part</span><br><span class="line">  └─fcache-dev2 252:1    0  100G  0 dm</span><br></pre></td></tr></table></figure>
<h4 id="查看flashcache-device"><a href="#查看flashcache-device" class="headerlink" title="查看flashcache device"></a>查看flashcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ll /dev/mapper/fcache-dev*</span></span><br><span class="line">lrwxrwxrwx. 1 root root 7 Feb 11 11:14 /dev/mapper/fcache-dev1 -&gt; ../dm-0</span><br><span class="line">lrwxrwxrwx. 1 root root 7 Feb 11 11:15 /dev/mapper/fcache-dev2 -&gt; ../dm-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># dmsetup table</span></span><br><span class="line">fcache-dev2: 0 209715200 flashcache conf:</span><br><span class="line">	ssd dev (/dev/vdd2), disk dev (/dev/vdc) cache mode(WRITE_BACK)</span><br><span class="line">	capacity(25498M), associativity(512), data block size(4K) metadata block size(4096b)</span><br><span class="line">	disk assoc(0K)</span><br><span class="line">	skip sequential thresh(0K)</span><br><span class="line">	total blocks(6527488), cached blocks(259), cache percent(0)</span><br><span class="line">	dirty blocks(0), dirty percent(0)</span><br><span class="line">	nr_queued(0)</span><br><span class="line">Size Hist: 4096:1497</span><br><span class="line">fcache-dev1: 0 209713152 flashcache conf:</span><br><span class="line">	ssd dev (/dev/vdd1), disk dev (/dev/vdb1) cache mode(WRITE_BACK)</span><br><span class="line">	capacity(25498M), associativity(512), data block size(4K) metadata block size(4096b)</span><br><span class="line">	disk assoc(0K)</span><br><span class="line">	skip sequential thresh(0K)</span><br><span class="line">	total blocks(6527488), cached blocks(259), cache percent(0)</span><br><span class="line">	dirty blocks(0), dirty percent(0)</span><br><span class="line">	nr_queued(0)</span><br><span class="line">Size Hist: 4096:1497</span><br></pre></td></tr></table></figure>
<h4 id="使用flashcache-device"><a href="#使用flashcache-device" class="headerlink" title="使用flashcache device"></a>使用flashcache device</h4><p>创建后的flashcache device可以像普通device一样使用，如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkfs.ext4 /dev/mapper/fcache-dev1</span></span><br><span class="line"><span class="comment"># mount /dev/mapper/fcache-dev1 /mnt/</span></span><br><span class="line"><span class="comment"># mount | grep mnt</span></span><br><span class="line">/dev/mapper/fcache-dev1 on /mnt <span class="built_in">type</span> ext4 (rw,relatime,seclabel,data=ordered)</span><br><span class="line"><span class="comment"># umount /mnt/</span></span><br></pre></td></tr></table></figure>
<h4 id="查看flashcache-device的flashcache状态"><a href="#查看flashcache-device的flashcache状态" class="headerlink" title="查看flashcache device的flashcache状态"></a>查看flashcache device的flashcache状态</h4><p>在使用一段时间后，我们可以看flashcache的缓存状态如下，可以以此为依据来调整flashcache的策略。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmsetup status fcache-dev1</span></span><br><span class="line">0 209713152 flashcache stats:</span><br><span class="line">	reads(1063), writes(422824)</span><br><span class="line">	<span class="built_in">read</span> hits(786), <span class="built_in">read</span> hit percent(73)</span><br><span class="line">	write hits(291) write hit percent(0)</span><br><span class="line">	dirty write hits(44) dirty write hit percent(0)</span><br><span class="line">	replacement(0), write replacement(7392)</span><br><span class="line">	write invalidates(0), <span class="built_in">read</span> invalidates(2)</span><br><span class="line">	pending enqueues(2), pending inval(2)</span><br><span class="line">	metadata dirties(422499), metadata cleans(112914)</span><br><span class="line">	metadata batch(531237) metadata ssd writes(4432)</span><br><span class="line">	cleanings(112914) fallow cleanings(0)</span><br><span class="line">	no room(31) front merge(3042) back merge(109407)</span><br><span class="line">	force_clean_block(0)</span><br><span class="line">	disk reads(277), disk writes(112945) ssd reads(113700) ssd writes(427505)</span><br><span class="line">	uncached reads(2), uncached writes(31), uncached IO requeue(0)</span><br><span class="line">	disk <span class="built_in">read</span> errors(0), disk write errors(0) ssd <span class="built_in">read</span> errors(0) ssd write errors(0)</span><br><span class="line">	uncached sequential reads(0), uncached sequential writes(0)</span><br><span class="line">	pid_adds(0), pid_dels(0), pid_drops(0) pid_expiry(0)</span><br><span class="line">	lru hot blocks(3263744), lru warm blocks(3263744)</span><br><span class="line">	lru promotions(0), lru demotions(0)</span><br></pre></td></tr></table></figure>
<h4 id="查看flashcache-device相关信息"><a href="#查看flashcache-device相关信息" class="headerlink" title="查看flashcache device相关信息"></a>查看flashcache device相关信息</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls /proc/flashcache/vdd1+vdb1/</span></span><br><span class="line">flashcache_errors  flashcache_iosize_hist  flashcache_pidlists  flashcache_stats</span><br><span class="line"><span class="comment"># cat /proc/flashcache/vdd1+vdb1/flashcache_errors</span></span><br><span class="line">disk_read_errors=0 disk_write_errors=0 ssd_read_errors=0 ssd_write_errors=0 memory_alloc_errors=0</span><br><span class="line"><span class="comment"># cat /proc/flashcache/vdd1+vdb1/flashcache_pidlists</span></span><br><span class="line">Blacklist:</span><br><span class="line">Whitelist:</span><br></pre></td></tr></table></figure>
<p>sysctl查看flashcache的信息：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sysctl -a | grep flashcache</span></span><br><span class="line">dev.flashcache.vdd1+vdb1.cache_all = 1</span><br><span class="line">dev.flashcache.vdd1+vdb1.clean_on_read_miss = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.clean_on_write_miss = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.dirty_thresh_pct = 20</span><br><span class="line">dev.flashcache.vdd1+vdb1.do_pid_expiry = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.do_sync = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.fallow_clean_speed = 2</span><br><span class="line">dev.flashcache.vdd1+vdb1.fallow_delay = 900</span><br><span class="line">dev.flashcache.vdd1+vdb1.fast_remove = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.io_latency_hist = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.lru_hot_pct = 75</span><br><span class="line">dev.flashcache.vdd1+vdb1.lru_promote_thresh = 2</span><br><span class="line">dev.flashcache.vdd1+vdb1.max_clean_ios_set = 2</span><br><span class="line">dev.flashcache.vdd1+vdb1.max_clean_ios_total = 4</span><br><span class="line">dev.flashcache.vdd1+vdb1.max_pids = 100</span><br><span class="line">dev.flashcache.vdd1+vdb1.new_style_write_merge = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.pid_expiry_secs = 60</span><br><span class="line">dev.flashcache.vdd1+vdb1.reclaim_policy = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.skip_seq_thresh_kb = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.stop_sync = 0</span><br><span class="line">dev.flashcache.vdd1+vdb1.zero_stats = 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># cd /proc/sys/dev/flashcache/vdd1+vdb1/</span></span><br><span class="line"><span class="comment"># ls</span></span><br><span class="line">cache_all            dirty_thresh_pct  fallow_clean_speed  io_latency_hist     max_clean_ios_set    new_style_write_merge  skip_seq_thresh_kb</span><br><span class="line">clean_on_read_miss   do_pid_expiry     fallow_delay        lru_hot_pct         max_clean_ios_total  pid_expiry_secs        stop_sync</span><br><span class="line">clean_on_write_miss  do_sync           fast_remove         lru_promote_thresh  max_pids             reclaim_policy         zero_stats</span><br></pre></td></tr></table></figure>
<blockquote>
<p>不明确上述参数是否可以动态调整？</p>
</blockquote>
<h4 id="删除flashcache-device"><a href="#删除flashcache-device" class="headerlink" title="删除flashcache device"></a>删除flashcache device</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmsetup info /dev/dm-0</span></span><br><span class="line">Name:              fcache-dev1</span><br><span class="line">State:             ACTIVE</span><br><span class="line">Read Ahead:        8192</span><br><span class="line">Tables present:    LIVE</span><br><span class="line">Open count:        0</span><br><span class="line">Event number:      0</span><br><span class="line">Major, minor:      252, 0</span><br><span class="line">Number of targets: 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># dmsetup remove /dev/dm-0</span></span><br><span class="line"><span class="comment"># flashcache_destroy /dev/vdd1</span></span><br><span class="line">flashcache_destroy: Destroying Flashcache found on /dev/vdd1. Any data will be lost !!</span><br></pre></td></tr></table></figure>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="删除设备出错"><a href="#删除设备出错" class="headerlink" title="删除设备出错"></a>删除设备出错</h4><p>测试中在remove一个device mapper设备时，报“Device or resource busy”。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmsetup remove /dev/dm-1</span></span><br><span class="line">device-mapper: remove ioctl on fcache-dev2 failed: Device or resource busy</span><br><span class="line">Command failed</span><br><span class="line"></span><br><span class="line"><span class="comment"># dmsetup info /dev/dm-1</span></span><br><span class="line">Name:              fcache-dev2</span><br><span class="line">State:             ACTIVE</span><br><span class="line">Read Ahead:        256</span><br><span class="line">Tables present:    LIVE</span><br><span class="line">Open count:        1</span><br><span class="line">Event number:      0</span><br><span class="line">Major, minor:      252, 1</span><br><span class="line">Number of targets: 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># dmsetup table</span></span><br><span class="line">fcache-dev2: 0 209715200 flashcache conf:</span><br><span class="line">    ssd dev (/dev/vdd2), disk dev (/dev/vdc) cache mode(WRITE_BACK)</span><br><span class="line">    capacity(25498M), associativity(512), data block size(4K) metadata block size(4096b)</span><br><span class="line">    disk assoc(0K)</span><br><span class="line">    skip sequential thresh(0K)</span><br><span class="line">    total blocks(6527488), cached blocks(259), cache percent(0)</span><br><span class="line">    dirty blocks(0), dirty percent(0)</span><br><span class="line">    nr_queued(0)</span><br><span class="line">Size Hist: 1024:2 4096:471740</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsof /dev/vdd2</span></span><br><span class="line"><span class="comment"># lsof /dev/vdc</span></span><br><span class="line"><span class="comment"># lsof /dev/dm-1</span></span><br></pre></td></tr></table></figure>
<p>尝试<code>remove --force</code>参数：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmsetup remove /dev/dm-1 --force</span></span><br><span class="line">device-mapper: remove ioctl on fcache-dev2 failed: Device or resource busy</span><br><span class="line">Command failed</span><br><span class="line"><span class="comment"># dmsetup table</span></span><br><span class="line">fcache-dev2: 0 209715200 error</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">vdb         253:16   0  100G  0 disk</span><br><span class="line">└─vdb1      253:17   0  100G  0 part</span><br><span class="line">vdc         253:32   0  100G  0 disk</span><br><span class="line">vdd         253:48   0   50G  0 disk</span><br><span class="line">├─vdd1      253:49   0   25G  0 part</span><br><span class="line">└─vdd2      253:50   0   25G  0 part</span><br><span class="line">fcache-dev2 252:1    0  100G  0 dm			<span class="comment">## 出些在这里了???</span></span><br></pre></td></tr></table></figure>
<p>之后尝试很多命令，没法完全把该设备移除，只能重启，重启后一切正常。</p>
<h4 id="创建设备出错1"><a href="#创建设备出错1" class="headerlink" title="创建设备出错1"></a>创建设备出错1</h4><p>创建flashcache device时报错：“Valid Flashcache already exists on…”。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flashcache_create -p back fcache-dev1 /dev/vdd1 /dev/vdb1</span></span><br><span class="line">cachedev fcache-dev1, ssd_devname /dev/vdd1, disk_devname /dev/vdb1 cache mode WRITE_BACK</span><br><span class="line">block_size 8, md_block_size 8, cache_size 0</span><br><span class="line">flashcache_create: Valid Flashcache already exists on /dev/vdd1</span><br><span class="line">flashcache_create: Use flashcache_destroy first and <span class="keyword">then</span> create again /dev/vdd1</span><br></pre></td></tr></table></figure>
<p>这个出错比较明确，按照提示先销毁cache设备中的flashcache数据即可。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flashcache_destroy /dev/vdd1</span></span><br><span class="line">flashcache_destroy: Destroying Flashcache found on /dev/vdd1. Any data will be lost !!</span><br><span class="line"></span><br><span class="line"><span class="comment"># flashcache_create -p back fcache-dev1 /dev/vdd1 /dev/vdb1</span></span><br><span class="line">cachedev fcache-dev1, ssd_devname /dev/vdd1, disk_devname /dev/vdb1 cache mode WRITE_BACK</span><br><span class="line">block_size 8, md_block_size 8, cache_size 0</span><br><span class="line">Flashcache metadata will use 137MB of your 3951MB main memory</span><br></pre></td></tr></table></figure>
<h4 id="创建设备出错2"><a href="#创建设备出错2" class="headerlink" title="创建设备出错2"></a>创建设备出错2</h4><p>测试中反复操作，创建flashcache device时报错：“Device or resource busy”。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flashcache_create -p back fcache-dev2 /dev/vdd2 /dev/vdc</span></span><br><span class="line">cachedev fcache-dev2, ssd_devname /dev/vdd2, disk_devname /dev/vdc cache mode WRITE_BACK</span><br><span class="line">block_size 8, md_block_size 8, cache_size 0</span><br><span class="line">Flashcache metadata will use 137MB of your 3951MB main memory</span><br><span class="line">device-mapper: reload ioctl on fcache-dev2 failed: Device or resource busy</span><br><span class="line">Command failed</span><br><span class="line"><span class="built_in">echo</span> 0 209715200 flashcache /dev/vdc /dev/vdd2 fcache-dev2 1 2 8 0 512 0 0 8 | dmsetup create fcache-dev2 failed</span><br></pre></td></tr></table></figure>
<p>尝试销毁flashcache设备上的相关数据，之后创建还是报错：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flashcache_destroy /dev/vdd2</span></span><br><span class="line">flashcache_destroy: No valid Flashcache found on /dev/vdd2</span><br></pre></td></tr></table></figure>
<p>再重启机器后，创建flashcache就正常了，比较奇怪 ;(</p>
<h4 id="重启机器后设备消失"><a href="#重启机器后设备消失" class="headerlink" title="重启机器后设备消失"></a>重启机器后设备消失</h4><p>重启机器后，看不到之前创建的flashcache device。</p>
<p>这是因为flashcache重启后不会自动加载设备，需要手动执行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># modprobe flashcache</span></span><br><span class="line"><span class="comment"># flashcache_load</span></span><br><span class="line">Usage: flashcache_load ssd_devname [cachedev]</span><br><span class="line">git commit:</span><br><span class="line"><span class="comment"># flashcache_load /dev/vdd1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dmsetup info</span></span><br><span class="line">Name:              fcache-dev1</span><br><span class="line">State:             ACTIVE</span><br><span class="line">Read Ahead:        8192</span><br><span class="line">Tables present:    LIVE</span><br><span class="line">Open count:        0</span><br><span class="line">Event number:      0</span><br><span class="line">Major, minor:      252, 0</span><br><span class="line">Number of targets: 1</span><br></pre></td></tr></table></figure>
<p>若想flashcache和设备在机器重启后自动加载，可以把相关命令加入“/etc/rc.d/rc.local”。</p>
<blockquote>
<p>/etc/rc.d/init.d/里也添加服务也是一个好方法 ;)</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/02/28/lvm-cmd-usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/28/lvm-cmd-usage/" itemprop="url">LVM Usage</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-28T08:42:52+08:00">
                2018-02-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/storage/" itemprop="url" rel="index">
                    <span itemprop="name">storage</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/02/28/lvm-cmd-usage/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/02/28/lvm-cmd-usage/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>之前文章大致做了LVM简介，推荐在使用本地存储时，使用LVM，那如何使用LVM呢？</p>
<p>这里从LVM相关组件分析其常用命令，最后给出创建一个LVM volume的步骤。</p>
<h2 id="物理卷相关"><a href="#物理卷相关" class="headerlink" title="物理卷相关"></a>物理卷相关</h2><p>物理卷 - PhysicalVolume</p>
<p>LVM管理的最底层就是一个个物理卷，与之相关的命令基本都以pv开始，大致有如下这些：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># pv</span></span><br><span class="line">pvchange   pvck       pvcreate   pvdisplay  pvmove     pvremove   pvresize   pvs        pvscan</span><br></pre></td></tr></table></figure>
<h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p><strong>pvcreate</strong> - initialize a disk or partition for use by LVM</p>
<p>从物理盘或者一个分区初始化一个PV，这个PV之后会被LVM用来创建VG；</p>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p><strong>pvremove</strong> - remove a physical volume</p>
<p>删除一个PV，之后LVM将不认为该设备为PV；</p>
<h3 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h3><p><strong>pvs</strong> - report information about physical volumes</p>
<p>展示系统PVS的信息，可以指定输出格式等；</p>
<p><strong>pvdisplay</strong> - display attributes of a physical volume</p>
<p>展示一个/多个PVS的属性信息，可以指定输出格式等；</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><strong>pvscan</strong> - scan all disks for physical volumes</p>
<p>扫描整个系统中支持LVM块设备的PVS；</p>
<p><strong>pvresize</strong> - resize a disk or partition in use by LVM2</p>
<p>调整LVM使用的一个PV的大小，前提是它对应的物理设备大小可以resize；</p>
<p><strong>pvchange</strong> - change attributes of a physical volume</p>
<p>修改一个PV的属性；</p>
<h2 id="卷组相关"><a href="#卷组相关" class="headerlink" title="卷组相关"></a>卷组相关</h2><p>卷组 - VolumeGroup</p>
<p>卷组是LVM基于PVS创建的一个块设备集合，类似于有的存储中说的Volume Pool，它综合了底层所有PVS的存储，做了统一的配置，比如：分配块大小等；</p>
<p>与卷组相关的命令都是以vg开始，大致如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># vg</span></span><br><span class="line">vgcfgbackup    vgchange       vgconvert      vgdisplay      vgextend       vgimportclone  vgmknodes      vgremove       vgs            vgsplit</span><br><span class="line">vgcfgrestore   vgck           vgcreate       vgexport       vgimport       vgmerge        vgreduce       vgrename       vgscan</span><br></pre></td></tr></table></figure>
<h3 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h3><p><strong>vgcreate</strong> - create a volume group</p>
<p>基于之前创建的PVS创建一个VG，这里原则上选择同质物理盘创建的PVS；</p>
<p>可以指定每次在PV上申请空间的Extent size（-s, –physicalextentsize PhysicalExtentSize[bBsSkKmMgGtTpPeE]）</p>
<h3 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h3><p><strong>vgremove</strong> - remove a volume group</p>
<p>删除一个VG；若VG上有LV，则会有相关提示；</p>
<h3 id="显示-1"><a href="#显示-1" class="headerlink" title="显示"></a>显示</h3><p><strong>vgs</strong> - report information about volume groups</p>
<p>显示系统中有的VGS信息；</p>
<p><strong>vgdisplay</strong> - display attributes of volume groups</p>
<p>显示VGS的详细属性信息；</p>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><p><strong>vgextend</strong> - add physical volumes to a volume group</p>
<p>添加PVS到VG中，扩容VG；</p>
<p><strong>vgreduce</strong> - reduce a volume group</p>
<p>从VG中删除没有使用的PVS，若PV已经分配了PE，则命令失败；</p>
<p><strong>vgchange</strong> - change attributes of a volume group</p>
<p>修改一个VG的属性；</p>
<h2 id="逻辑卷相关"><a href="#逻辑卷相关" class="headerlink" title="逻辑卷相关"></a>逻辑卷相关</h2><p>逻辑卷 - LogicalVolume</p>
<p>逻辑卷是最终面向用户使用的块设备，用户可以像使用普通磁盘/分区一样的使用它；同时逻辑卷支持很多普通磁盘没有的特性，比如：mirror，stripe，raid，thin等；</p>
<p>与逻辑卷相关的命令都是以lv开始，大致如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># lv</span></span><br><span class="line">lvchange     lvcreate     lvextend     lvmchange    lvmconfig    lvmdump      lvmpolld     lvmsar       lvremove     lvresize     lvscan</span><br><span class="line">lvconvert    lvdisplay    lvm          lvmconf      lvmdiskscan  lvmetad      lvmsadc      lvreduce     lvrename     lvs</span><br></pre></td></tr></table></figure>
<h3 id="创建-2"><a href="#创建-2" class="headerlink" title="创建"></a>创建</h3><p><strong>lvcreate</strong> - create a logical volume in an existing volume group</p>
<p>从一个创建好的VG里创建一个LV，可以指定LV的很多属性，比如：size，stripe，raid，thin等；</p>
<h3 id="删除-2"><a href="#删除-2" class="headerlink" title="删除"></a>删除</h3><p><strong>lvremove</strong> - remove a logical volume</p>
<p>删除一个LV；若该LV系统正在使用，则删除失败；</p>
<h3 id="显示-2"><a href="#显示-2" class="headerlink" title="显示"></a>显示</h3><p><strong>lvs</strong> - report information about logical volumes</p>
<p>显示系统LVS的基本信息；</p>
<p><strong>lvdisplay</strong> - display attributes of a logical volume</p>
<p>显示一个LV的详细属性信息；</p>
<h3 id="其他-2"><a href="#其他-2" class="headerlink" title="其他"></a>其他</h3><p><strong>lvextend</strong> - extend the size of a logical volume</p>
<p>扩容一个LV的size；</p>
<p><strong>lvresize</strong> - resize a logical volume</p>
<p>调整一个LV的size；可以扩容，可以缩容，但缩容需谨慎，可能导致数据丢失；</p>
<p><strong>lvchange</strong> - change attributes of a logical volume</p>
<p>修改一个LV的属性；</p>
<p><strong>lvscan</strong> - scan (all disks) for Logical Volumes</p>
<p>扫描系统获取所有LV的 active，snapshot/origin，size等信息；</p>
<h2 id="创建LVM-Volume步骤"><a href="#创建LVM-Volume步骤" class="headerlink" title="创建LVM Volume步骤"></a>创建LVM Volume步骤</h2><h3 id="创建PV"><a href="#创建PV" class="headerlink" title="创建PV"></a>创建PV</h3><p>使用fdisk创建LVM Type的磁盘分区</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ~]<span class="comment"># fdisk /dev/sdj</span></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Partition number (1-128, default 1):</span><br><span class="line">First sector (34-7814037134, default 2048):</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (2048-7814037134, default 7814037134):</span><br><span class="line">Created partition 1</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): t</span><br><span class="line">Selected partition 1</span><br><span class="line">Partition <span class="built_in">type</span> (<span class="built_in">type</span> L to list all types): 15</span><br><span class="line">Changed <span class="built_in">type</span> of partition <span class="string">'Linux filesystem'</span> to <span class="string">'Linux LVM'</span></span><br><span class="line"> </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): p</span><br><span class="line"> </span><br><span class="line">Disk /dev/sdj: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: gpt</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">#         Start          End    Size  Type            Name</span></span><br><span class="line"> 1         2048   7814037134    3.7T  Linux LVM</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line">The partition table has been altered!</span><br><span class="line"> </span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ~]<span class="comment"># pvs</span></span><br><span class="line">  PV         VG Fmt  Attr PSize   PFree</span><br><span class="line">  /dev/sdi1     lvm2 ---    3.64t 3.64t</span><br><span class="line">  /dev/sdj1     lvm2 ---    3.64t 3.64t</span><br><span class="line">  /dev/sdk1     lvm2 ---    3.64t 3.64t</span><br><span class="line">  /dev/sdl1     lvm2 ---    3.64t 3.64t</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[root@ceph0 ~]<span class="comment"># pvdisplay /dev/sdi1</span></span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdi1</span><br><span class="line">  VG Name               volgroup-sata</span><br><span class="line">  PV Size               3.64 TiB / not usable 2.82 MiB</span><br><span class="line">  Allocatable           yes</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              953861</span><br><span class="line">  Free PE               953605</span><br><span class="line">  Allocated PE          256</span><br><span class="line">  PV UUID               rGiKHq-yem2-DUSH-F5AM-4jxE-eZvv-cF1YlG</span><br></pre></td></tr></table></figure>
<h3 id="创建VG"><a href="#创建VG" class="headerlink" title="创建VG"></a>创建VG</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ~]<span class="comment"># vgcreate volgroup-sata /dev/sdi1 /dev/sdj1 /dev/sdk1</span></span><br><span class="line">  Volume group <span class="string">"volgroup-sata"</span> successfully created</span><br><span class="line">[root@ceph0 ~]<span class="comment">#</span></span><br><span class="line">[root@ceph0 ~]<span class="comment"># vgs</span></span><br><span class="line">  VG            <span class="comment">#PV #LV #SN Attr   VSize   VFree</span></span><br><span class="line">  volgroup-sata   3   0   0 wz--n-  10.92t 10.92t</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[root@ceph0 ~]<span class="comment"># vgdisplay volgroup-sata</span></span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               volgroup-sata</span><br><span class="line">  System ID</span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        3</span><br><span class="line">  Metadata Sequence No  9</span><br><span class="line">  VG Access             <span class="built_in">read</span>/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                1</span><br><span class="line">  Open LV               0</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                3</span><br><span class="line">  Act PV                3</span><br><span class="line">  VG Size               10.92 TiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              2861583</span><br><span class="line">  Alloc PE / Size       256 / 1.00 GiB</span><br><span class="line">  Free  PE / Size       2861327 / 10.92 TiB</span><br><span class="line">  VG UUID               7rEMc5-pkzR-ckFM-8Yve-cATM-uy9B-buMcR6</span><br></pre></td></tr></table></figure>
<h3 id="创建LV"><a href="#创建LV" class="headerlink" title="创建LV"></a>创建LV</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ~]<span class="comment"># lvcreate -n lv1 -L 1G volgroup-sata</span></span><br><span class="line">  Logical volume <span class="string">"lv1"</span> created.</span><br><span class="line">[root@ceph0 ~]<span class="comment"># lvs</span></span><br><span class="line">  LV   VG            Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  lv1  volgroup-sata -wi<span class="_">-a</span>-----   1.00g</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[root@ceph0 ~]<span class="comment"># lvdisplay volgroup-sata/lv1</span></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/volgroup-sata/lv1</span><br><span class="line">  LV Name                lv1</span><br><span class="line">  VG Name                volgroup-sata</span><br><span class="line">  LV UUID                SWp2Lr-kGLC-8USu-3jqu-Bwpd-yN3D-wMGFGn</span><br><span class="line">  LV Write Access        <span class="built_in">read</span>/write</span><br><span class="line">  LV Creation host, time ceph0, 2018-01-26 16:19:17 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  <span class="comment"># open                 0</span></span><br><span class="line">  LV Size                1.00 GiB</span><br><span class="line">  Current LE             256</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently <span class="built_in">set</span> to     256</span><br><span class="line">  Block device           253:3</span><br></pre></td></tr></table></figure>
<h3 id="使用LV"><a href="#使用LV" class="headerlink" title="使用LV"></a>使用LV</h3><p>可以像使用系统物理device一样，使用LogicalVolume；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph0 ~]<span class="comment"># mkfs.ext4 /dev/volgroup-sata/lv1</span></span><br><span class="line">[root@ceph0 ~]<span class="comment"># mount /dev/volgroup-sata/lv1 /mnt/</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/02/06/lvm-intro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/06/lvm-intro/" itemprop="url">LVM简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-06T21:41:27+08:00">
                2018-02-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/storage/" itemprop="url" rel="index">
                    <span itemprop="name">storage</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/02/06/lvm-intro/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/02/06/lvm-intro/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="LVM基本组成"><a href="#LVM基本组成" class="headerlink" title="LVM基本组成"></a>LVM基本组成</h2><p>LVM利用Linux内核的<a href="http://sources.redhat.com/dm/" target="_blank" rel="noopener">device-mapper</a>来实现存储系统的虚拟化（系统分区独立于底层硬件）。 通过LVM，你可以实现存储空间的抽象化并在上面建立虚拟分区（virtual partitions），可以更简便地扩大和缩小分区，可以增删分区时无需担心某个硬盘上没有足够的连续空间， LVM是用来方便管理的，不会提供额外的安全保证。</p>
<p>LVM的基本组成块（building blocks）如下：</p>
<ul>
<li><strong>物理卷Physical volume (PV)</strong>：可以在上面建立卷组的媒介，可以是硬盘分区，也可以是硬盘本身或者回环文件（loopback file）。物理卷包括一个特殊的header，其余部分被切割为一块块物理区域（physical extents）。</li>
<li><strong>卷组Volume group (VG)</strong>：将一组物理卷收集为一个管理单元。</li>
<li><strong>逻辑卷Logical volume (LV)</strong>：虚拟分区，由物理区域（physical extents）组成。</li>
<li><strong>物理区域Physical extent (PE)</strong>：硬盘可供指派给逻辑卷的最小单位（通常为4MB）。</li>
</ul>
<p>示例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">两块物理硬盘</span><br><span class="line">                </span><br><span class="line">  硬盘1 (/dev/sda):</span><br><span class="line">     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ </span><br><span class="line">    |分区1 50GB (物理卷)            |分区2 80GB (物理卷)            |</span><br><span class="line">    |/dev/sda1                    |/dev/sda2                     |</span><br><span class="line">    |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _|_ _ _ _ _ _ _ _ _ _ _ _ _ _ __|</span><br><span class="line">                                  </span><br><span class="line">  硬盘2 (/dev/sdb):</span><br><span class="line">     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</span><br><span class="line">    |分区1 120GB (物理卷)                          |</span><br><span class="line">    |/dev/sdb1                                   |</span><br><span class="line">    | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LVM方式</span><br><span class="line"></span><br><span class="line">  卷组VG1 (/dev/storage1/ = /dev/sda1):</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">卷组VG2 (/dev/storage2/ = /dev/sda2 + /dev/sdb1):</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> _ _ _ _ _ _ _  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ </span><br><span class="line">|逻辑卷1 15GB             |逻辑卷2 35GB               |逻辑卷3 200GB               |</span><br><span class="line">|/dev/storage1/rootvol   |/dev/storage2/homevol     |/dev/storage2/mediavol     |</span><br><span class="line">|_ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _|</span><br></pre></td></tr></table></figure>
<p><strong>图解如下</strong></p>
<p><img src="/images/lvm-arch.jpg" alt="lvm-arch"></p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>比起正常的硬盘分区管理，LVM更富于弹性：</p>
<ul>
<li>使用卷组(VG)，使众多硬盘空间看起来像一个大硬盘。</li>
<li>使用逻辑卷（LV），可以创建跨越众多硬盘空间的分区。</li>
<li>可以创建小的逻辑卷（LV），在空间不足时再动态调整它的大小。</li>
<li>在调整逻辑卷（LV）大小时可以不用考虑逻辑卷在硬盘上的位置，不用担心没有可用的连续空间。It does not depend on the position of the LV within VG, there is no need to ensure surrounding available space.</li>
<li>可以在线（online）对逻辑卷（LV）和卷组（VG）进行创建、删除、调整大小等操作。LVM上的文件系统也需要重新调整大小，某些文件系统也支持这样的在线操作。</li>
<li>无需重新启动服务，就可以将服务中用到的逻辑卷（LV）在线（online）/动态（live）迁移至别的硬盘上。</li>
<li>允许创建快照，可以保存文件系统的备份，同时使服务的下线时间（downtime）降低到最小。</li>
</ul>
<p>这些优点使得LVM对服务器的管理非常有用，对于桌面系统管理的帮助则没有那么显著，你需要根据实际情况进行取舍。</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>在系统设置时需要更复杂的额外步骤。</li>
</ul>
<h2 id="系统支持"><a href="#系统支持" class="headerlink" title="系统支持"></a>系统支持</h2><p>当前Linux系统都支持LVM，我们常用的Ubuntu和Centos上都可以方便安装，具体如下：</p>
<p>Ubuntu：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># lsb_release -a</span></span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID: Ubuntu</span><br><span class="line">Description:    Ubuntu 16.04.2 LTS</span><br><span class="line">Release:    16.04</span><br><span class="line">Codename:   xenial</span><br><span class="line"> </span><br><span class="line">root@ubuntu:~<span class="comment"># apt-get install -y lvm2</span></span><br><span class="line">...</span><br><span class="line">root@ubuntu:~<span class="comment"># lvm version</span></span><br><span class="line">  LVM version:     2.02.133(2) (2015-10-30)</span><br><span class="line">  Library version: 1.02.110 (2015-10-30)</span><br><span class="line">  Driver version:  4.34.0</span><br></pre></td></tr></table></figure>
<p>Centos：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@centos:~<span class="comment"># lsb_release -a</span></span><br><span class="line">LSB Version:    :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch</span><br><span class="line">Distributor ID: CentOS</span><br><span class="line">Description:    CentOS Linux release 7.3.1611 (Core)</span><br><span class="line">Release:    7.3.1611</span><br><span class="line">Codename:   Core</span><br><span class="line"> </span><br><span class="line">root@centos:~<span class="comment"># yum install -y lvm2</span></span><br><span class="line">...</span><br><span class="line">root@centos:~<span class="comment"># lvm version</span></span><br><span class="line">  LVM version:     2.02.171(2)-RHEL7 (2017-05-03)</span><br><span class="line">  Library version: 1.02.140-RHEL7 (2017-05-03)</span><br><span class="line">  Driver version:  4.34.0</span><br></pre></td></tr></table></figure>
<h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><p>使用本地存储时，LVM是对比物理盘有明显的优点，建议除非特别简单使用物理盘的场景，都可以使用LVM来提供存储服务。</p>
<p>使用时候的一些建议如下：</p>
<ol>
<li>一个物理盘对应一个PV</li>
<li>多个PV构成一个VG</li>
<li>同一VG内最好使用相同性能的物理盘</li>
<li>不同性能的物理盘，创建不同的VG</li>
<li>创建适当大小的LV，容量不够时再扩容</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2018/01/30/lvm-with-cache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/30/lvm-with-cache/" itemprop="url">LVM之Cache加速</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-30T22:41:27+08:00">
                2018-01-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/storage/" itemprop="url" rel="index">
                    <span itemprop="name">storage</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/30/lvm-with-cache/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/01/30/lvm-with-cache/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>我们知道LVM是管理本地磁盘，更好的提供块设备服务的机制；</p>
<p>在现实环境中，我们的机器通常都有几种不同类型的磁盘存在，高性能的磁盘容量低，容量大的磁盘性能差，那如何利用Linux系统的各种cache机制来提升LVM卷的性能呢？</p>
<h2 id="存储磁盘分类"><a href="#存储磁盘分类" class="headerlink" title="存储磁盘分类"></a>存储磁盘分类</h2><p>通常我们使用的存储磁盘有三种，分别对应不同的容量、性能、价格，有：SATA盘，SSD盘和PCIE-SSD；</p>
<p>他们三个的大致性能容量和价格如下表所示：</p>
<table>
<thead>
<tr>
<th>设备</th>
<th>容量</th>
<th>性能</th>
<th>BandWidth</th>
<th>IOPS</th>
<th>价格</th>
<th>厂商</th>
<th>应用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>SATA</td>
<td>容量大，常见为4-8TB</td>
<td>低</td>
<td>约100MB/s</td>
<td>100</td>
<td>低</td>
<td>希捷，西数等</td>
<td>大容量</td>
</tr>
<tr>
<td>SSD</td>
<td>容量小，常见为几百GB</td>
<td>高</td>
<td>约500MB/s</td>
<td>读：30, 000+写：5, 000+</td>
<td>高</td>
<td>Intel，Samsung等</td>
<td>高性能，加速应用</td>
</tr>
<tr>
<td>PCIE-SSD</td>
<td>容量较大，常见为1-4T</td>
<td>超高</td>
<td>约2GB/s</td>
<td>读：500, 000+写：100, 000+</td>
<td>较高</td>
<td>Intel，Samsung，Memblaze，宝存等</td>
<td>超高性能，加速应用</td>
</tr>
</tbody>
</table>
<p>从上面可以看出，可以作为普通磁盘加速的磁盘有：SSD盘和PCIE-SSD，其中SSD盘是最常见和用的最多的，PCIE卡在超高性能需求场所有使用。</p>
<blockquote>
<p>注：其实现在SSD/PCIE-SSD的每GB价格相差不大了，若对超高性能有需求，PCIE-SSD是个很好的选择；</p>
</blockquote>
<h2 id="Cache算法"><a href="#Cache算法" class="headerlink" title="Cache算法"></a>Cache算法</h2><p>通常我们使用高性能磁盘来加速低性能磁盘时，都会选择一种Linux内核支持的Cache算法，现在Linux内核支持的常用Cache算法有如下几种；</p>
<h3 id="flashcache"><a href="#flashcache" class="headerlink" title="flashcache"></a>flashcache</h3><p>flashcache 是 facebook 开源的 ssd 存储产品，它基于内核的 devicemapper 机制，允许将 ssd 设备映射为机械存储设备的缓存，堆叠成为一个虚拟设备供用户读写，从而在一定程度上兼顾 ssd 的高速与机械存储设备的高容量，更加经济高效地支撑线上业务。</p>
<p>flashcache 支持三种缓存策略：</p>
<ul>
<li>回写(Write Back)：修改内容之后，并不立即写入后端设备</li>
<li>写透(Write Through): 修改内容时写入后端设备，同时也更新前端设备中的缓存块</li>
<li>环写(Write Around): 修改内容时，先写入后端设备，同时使前端设备中对应的缓存块失效</li>
</ul>
<p><strong>参考：</strong></p>
<p><a href="https://github.com/facebookarchive/flashcache" target="_blank" rel="noopener">https://github.com/facebookarchive/flashcache</a></p>
<p><a href="https://en.wikipedia.org/wiki/Flashcache" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Flashcache</a></p>
<h3 id="bcache"><a href="#bcache" class="headerlink" title="bcache"></a>bcache</h3><p>bcache是linux内核块设备层cache，类似于flashcache使用ssd作为hdd的缓存方案，相比于flashcache，bcache更加灵活，支持ssd作为多块hdd的共享缓存，并且还支持多块ssd（还未完善），能够在运行中动态增加，删除缓存设备和后端设备。</p>
<p>从3.10开始，bcache进入内核主线。bcache支持writeback、writethrough、writearoud三种策略，默认是wriththrough，可以动态修改，缓存替换方式支持lru、fifo和random三种。</p>
<p><strong>参考：</strong></p>
<p><a href="https://bcache.evilpiepirate.org/" target="_blank" rel="noopener">https://bcache.evilpiepirate.org/</a></p>
<p><a href="http://www.sysnote.org/2014/06/20/bcache-analysis/" target="_blank" rel="noopener">http://www.sysnote.org/2014/06/20/bcache-analysis/</a></p>
<h3 id="dm-cache"><a href="#dm-cache" class="headerlink" title="dm-cache"></a>dm-cache</h3><p>作为linux内核的一部分，dm-cache采用device mapper机制允许用户建立混合卷。dm-cache可以采用一个或多个快速设备为后端慢速存储系统扮演缓存的角色。</p>
<p>dm-cache设计成由3个物理存储设备来混合成一个逻辑卷的形式。操作模式和缓存策略决定了缓存数据的性能。这三个物理设备分别为：</p>
<ul>
<li>原始设备：提供主要的慢速存储（通常是一个硬盘或者SAN）</li>
<li>缓存设备：提供高速原始设备数据的缓存（通常是一个SSD）</li>
<li>元数据设备：记录硬盘块在缓存中的位置，脏标志以及执行缓存策略所需的内部数据</li>
</ul>
<p>dm-cache支持写回，写通和旁路三种模式。</p>
<p><strong>参考：</strong></p>
<p><a href="https://en.wikipedia.org/wiki/Dm-cache" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Dm-cache</a></p>
<h2 id="LVM加速策略"><a href="#LVM加速策略" class="headerlink" title="LVM加速策略"></a>LVM加速策略</h2><h3 id="flashcache-1"><a href="#flashcache-1" class="headerlink" title="flashcache"></a>flashcache</h3><p>基于flashcache的使用策略（SSD-SATA 1对1），我们有如下策略：</p>
<p><img src="/images/lvm-cache-flashcache.jpg" alt="lvm-cahce-flashcache"></p>
<h3 id="bcache-1"><a href="#bcache-1" class="headerlink" title="bcache"></a>bcache</h3><p>bcache可以用一块SSD盘做多个SATA盘的缓存，有如下策略：</p>
<p><img src="/images/lvm-cache-bcache.jpg" alt="lvm-cahce-bcache"></p>
<h3 id="LVM自带Cache策略"><a href="#LVM自带Cache策略" class="headerlink" title="LVM自带Cache策略"></a>LVM自带Cache策略</h3><p>LVM自带Cache策略可以配置两个LV之间做缓存，有如下策略：</p>
<p><img src="/images/lvm-cache-self.jpg" alt="lvm-cahce-self"></p>
<h2 id="LVM-Cache策略选择"><a href="#LVM-Cache策略选择" class="headerlink" title="LVM Cache策略选择"></a>LVM Cache策略选择</h2><p>现实中，考虑稳定性和可靠性，使用flashcache作为Cache策略的比较多。</p>
<p>但最近bcache也越来越得到大范围的使用，在某些测试报告中，其性能多数场景优于flashcache。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2017/12/29/valgrind-intro-usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/29/valgrind-intro-usage/" itemprop="url">valgrind简介和使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-29T08:40:17+08:00">
                2017-12-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index">
                    <span itemprop="name">tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/29/valgrind-intro-usage/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/12/29/valgrind-intro-usage/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最近有需求要分析定位下开发的文件存储网关的内存泄露问题，对比了几款后选择了<code>valgrind</code>这款工具，功能很是强大，这里我还只使用了一些基本的功能，记录如下。</p>
<p><code>Valgrind</code>支持很多工具: <code>Memcheck</code>，<code>Addrcheck</code>，<code>Cachegrind</code>，<code>Massif</code>，<code>Helgrind</code>和<code>Callgrind</code>等。</p>
<p>官网：<a href="http://valgrind.org/" target="_blank" rel="noopener">http://valgrind.org/</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ wget ftp://sourceware.org/pub/valgrind/valgrind-3.13.0.tar.bz2</span><br><span class="line">$ bzip2 -d valgrind-3.13.0.tar.bz2</span><br><span class="line">$ tar -xf valgrind-3.13.0.tar</span><br><span class="line">$ <span class="built_in">cd</span> valgrind-3.13.0/</span><br><span class="line">$ ./configure</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>
<h2 id="使用与分析"><a href="#使用与分析" class="headerlink" title="使用与分析"></a>使用与分析</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ valgrind --<span class="built_in">help</span></span><br><span class="line">usage: valgrind [options] prog-and-args</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">常用的一些options有：</span><br><span class="line">--trace-children=no|yes   Valgrind-ise child processes (follow execve)? [no]</span><br><span class="line">--<span class="built_in">log</span>-file=&lt;file&gt;         <span class="built_in">log</span> messages to &lt;file&gt;</span><br><span class="line">--leak-check=no|summary|full     search <span class="keyword">for</span> memory leaks at <span class="built_in">exit</span>?  [summary]</span><br><span class="line"></span><br><span class="line">--show-reachable=yes             same as --show-leak-kinds=all</span><br><span class="line">    --show-reachable=no --show-possibly-lost=yes</span><br><span class="line">                                     same as --show-leak-kinds=definite,possible</span><br><span class="line">    --show-reachable=no --show-possibly-lost=no</span><br><span class="line">                                     same as --show-leak-kinds=definite</span><br></pre></td></tr></table></figure>
<p>常用命令格式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/bin/valgrind --<span class="built_in">log</span>-file=mylog ./file-gateway</span><br></pre></td></tr></table></figure>
<p><code>valgrind</code>的<code>memcheck</code>组件支持的内存泄露检查大概有：</p>
<ol>
<li>读写非法的内存</li>
<li>访问未初始化的内存</li>
<li>访问已经释放了的内存</li>
<li>申请的内存没有释放</li>
<li>重复释放内存</li>
<li>释放非法内存</li>
<li><code>source</code>和<code>destination</code>内存的重叠</li>
</ol>
<h3 id="uninitialised-byte-s"><a href="#uninitialised-byte-s" class="headerlink" title="uninitialised byte(s)"></a>uninitialised byte(s)</h3><p>检查出程序中未初始化而访问的变量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">==1350634== Thread 14:</span><br><span class="line">==1350634== Syscall param setxattr(value) points to uninitialised byte(s)</span><br><span class="line">==1350634==    at 0x6D9EB8A: setxattr (<span class="keyword">in</span> /usr/lib64/libc-2.17.so)</span><br><span class="line">==1350634==    by 0x487268: VFS::file_setxattr(std::string, std::string, void*, int) (vfs.cc:64)</span><br><span class="line">==1350634==    by 0x488066: FileGwVFS::file_setxattr(std::string, std::string, void*, int) (vfs.cc:175)</span><br><span class="line">==1350634==    by 0x459583: FileGateway::set_file_xattr(std::string, sgwd_xattr*) (file_gateway.cc:742)</span><br><span class="line">==1350634==    by 0x463706: FileGwRedisWorkItem::update_file_xattr_status(gateway_file_status) (redis_work_item.cc:703)</span><br><span class="line">==1350634==    by 0x4641B1: FileGwRedisWorkItem::file_upload() (redis_work_item.cc:793)</span><br><span class="line">==1350634==    by 0x45F89E: FileGwRedisWorkItem::process() (redis_work_item.cc:190)</span><br><span class="line">==1350634==    by 0x486532: WorkThread::process_work_item() (work_thread.cc:49)</span><br><span class="line">==1350634==    by 0x486850: ShardedWorkThread::entry() (work_thread.cc:112)</span><br><span class="line">==1350634==    by 0x481B58: Thread::_entry_func(void*) (thread.cc:74)</span><br><span class="line">==1350634==    by 0x4E3DDC4: start_thread (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1350634==    by 0x6D9FCEC: <span class="built_in">clone</span> (<span class="keyword">in</span> /usr/lib64/libc-2.17.so)</span><br><span class="line">==1350634==  Address 0x115d95a4 is on thread 14<span class="string">'s stack</span></span><br><span class="line"><span class="string">==1350634==  in frame #4, created by FileGwRedisWorkItem::update_file_xattr_status(gateway_file_status) (redis_work_item.cc:697)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">==1350634== Thread 19:</span><br><span class="line">==1350634== Conditional jump or move depends on uninitialised value(s)</span><br><span class="line">==1350634==    at 0x465155: FileGwRedisWorkItem::callback(void*) (redis_work_item.cc:946)</span><br><span class="line">==1350634==    by 0x481021: FileGwS3WorkItem::postProcess() (s3_work_item.cc:244)</span><br><span class="line">==1350634==    by 0x486551: WorkThread::process_work_item() (work_thread.cc:50)</span><br><span class="line">==1350634==    by 0x48666E: WorkThread::entry() (work_thread.cc:78)</span><br><span class="line">==1350634==    by 0x481B58: Thread::_entry_func(void*) (thread.cc:74)</span><br><span class="line">==1350634==    by 0x4E3DDC4: start_thread (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1350634==    by 0x6D9FCEC: <span class="built_in">clone</span> (<span class="keyword">in</span> /usr/lib64/libc-2.17.so)</span><br></pre></td></tr></table></figure>
<h3 id="Invalid-read-write"><a href="#Invalid-read-write" class="headerlink" title="Invalid read/write"></a>Invalid read/write</h3><p>读取非法地址，通常是继续访问释放后的内存空间</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">==1346085== Thread 14:</span><br><span class="line">==1346085== Invalid <span class="built_in">read</span> of size 4</span><br><span class="line">==1346085==    at 0x4E40BB0: pthread_mutex_unlock (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1346085==    by 0x4559FC: __gthread_mutex_unlock(pthread_mutex_t*) (gthr-default.h:778)</span><br><span class="line">==1346085==    by 0x45B6C1: std::mutex::unlock() (mutex:152)</span><br><span class="line">==1346085==    by 0x489CA8: std::lock_guard&lt;std::mutex&gt;::~lock_guard() (mutex:420)</span><br><span class="line">==1346085==    by 0x4895BB: WorkItemCompletion::finish() (thread_work_item.cc:47)</span><br><span class="line">==1346085==    by 0x48971E: ThreadWorkItem::postProcess() (thread_work_item.cc:70)</span><br><span class="line">==1346085==    by 0x45F721: RedisWorkItem::postProcess() (redis_work_item.cc:139)</span><br><span class="line">==1346085==    by 0x45FFED: FileGwRedisWorkItem::postProcess() (redis_work_item.cc:234)</span><br><span class="line">==1346085==    by 0x486761: WorkThread::process_work_item() (work_thread.cc:50)</span><br><span class="line">==1346085==    by 0x486A60: ShardedWorkThread::entry() (work_thread.cc:112)</span><br><span class="line">==1346085==    by 0x481D68: Thread::_entry_func(void*) (thread.cc:74)</span><br><span class="line">==1346085==    by 0x4E3DDC4: start_thread (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1346085==  Address 0xabd3788 is 24 bytes inside a block of size 88 free<span class="string">'d</span></span><br><span class="line"><span class="string">==1346085==    at 0x4C2B1CD: operator delete(void*) (vg_replace_malloc.c:576)</span></span><br><span class="line"><span class="string">==1346085==    by 0x489253: WorkItemCompletion::~WorkItemCompletion() (thread_work_item.cc:29)</span></span><br><span class="line"><span class="string">==1346085==    by 0x4572E4: FileGateway::issue_filegw_redis_workitem(FileOp*, FileInfo*, bool, bool, void (*)(void*), void*) (file_gateway.cc:298)</span></span><br><span class="line"><span class="string">==1346085==    by 0x457D31: FileGateway::do_read(FileOp*) (file_gateway.cc:455)</span></span><br><span class="line"><span class="string">==1346085==    by 0x455298: GatewayWorkItem::process() (gateway_work_item.cc:74)</span></span><br><span class="line"><span class="string">==1346085==    by 0x486742: WorkThread::process_work_item() (work_thread.cc:49)</span></span><br><span class="line"><span class="string">==1346085==    by 0x48687E: WorkThread::entry() (work_thread.cc:78)</span></span><br><span class="line"><span class="string">==1346085==    by 0x481D68: Thread::_entry_func(void*) (thread.cc:74)</span></span><br><span class="line"><span class="string">==1346085==    by 0x4E3DDC4: start_thread (in /usr/lib64/libpthread-2.17.so)</span></span><br><span class="line"><span class="string">==1346085==    by 0x6D9FCEC: clone (in /usr/lib64/libc-2.17.so)</span></span><br><span class="line"><span class="string">==1346085==  Block was alloc'</span>d at</span><br><span class="line">==1346085==    at 0x4C2A243: operator new(unsigned long) (vg_replace_malloc.c:334)</span><br><span class="line">==1346085==    by 0x457171: FileGateway::issue_filegw_redis_workitem(FileOp*, FileInfo*, bool, bool, void (*)(void*), void*) (file_gateway.cc:286)</span><br><span class="line">==1346085==    by 0x457D31: FileGateway::do_read(FileOp*) (file_gateway.cc:455)</span><br><span class="line">==1346085==    by 0x455298: GatewayWorkItem::process() (gateway_work_item.cc:74)</span><br><span class="line">==1346085==    by 0x486742: WorkThread::process_work_item() (work_thread.cc:49)</span><br><span class="line">==1346085==    by 0x48687E: WorkThread::entry() (work_thread.cc:78)</span><br><span class="line">==1346085==    by 0x481D68: Thread::_entry_func(void*) (thread.cc:74)</span><br><span class="line">==1346085==    by 0x4E3DDC4: start_thread (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1346085==    by 0x6D9FCEC: <span class="built_in">clone</span> (<span class="keyword">in</span> /usr/lib64/libc-2.17.so)</span><br></pre></td></tr></table></figure>
<h3 id="SUMMARY"><a href="#SUMMARY" class="headerlink" title="SUMMARY"></a>SUMMARY</h3><p>在<code>valgrind</code>最后会有内存分析的总结</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">==1366931== HEAP SUMMARY:</span><br><span class="line">==1366931==     <span class="keyword">in</span> use at <span class="built_in">exit</span>: 41,110 bytes <span class="keyword">in</span> 1,019 blocks</span><br><span class="line">==1366931==   total heap usage: 1,275,222 allocs, 1,274,203 frees, 334,495,820 bytes allocated</span><br><span class="line">==1366931==</span><br><span class="line">==1366931== LEAK SUMMARY:</span><br><span class="line">==1366931==    definitely lost: 11,632 bytes <span class="keyword">in</span> 191 blocks</span><br><span class="line">==1366931==    indirectly lost: 80 bytes <span class="keyword">in</span> 2 blocks</span><br><span class="line">==1366931==      possibly lost: 608 bytes <span class="keyword">in</span> 1 blocks</span><br><span class="line">==1366931==    still reachable: 28,790 bytes <span class="keyword">in</span> 825 blocks</span><br><span class="line">==1366931==                       of <span class="built_in">which</span> reachable via heuristic:</span><br><span class="line">==1366931==                         stdstring          : 145 bytes <span class="keyword">in</span> 4 blocks</span><br><span class="line">==1366931==         suppressed: 0 bytes <span class="keyword">in</span> 0 blocks</span><br><span class="line">==1366931== Rerun with --leak-check=full to see details of leaked memory</span><br><span class="line">==1366931==</span><br><span class="line">==1366931== For counts of detected and suppressed errors, rerun with: -v</span><br><span class="line">==1366931== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)</span><br></pre></td></tr></table></figure>
<p><code>LEAK SUMMARY</code>：内存泄露信息的总结，详细信息从前面的log中查找</p>
<ul>
<li><code>definitely lost</code>: 肯定丢失的内存，这部分必须处理</li>
<li><code>indirectly lost</code>: 间接丢失的内存，可能是一个<code>structure</code>里指向的内存</li>
<li><code>possibly lost</code>: 可能丢失的部分，这是由于C/C++语言指针处理的特点造成的，可能不太准确</li>
<li><code>still reachable</code>: 程序可能是ok的，可以配置<code>--show-reachable=no</code>不显示这部分</li>
</ul>
<p><strong>若想显示泄露内存的详细信息，使用参数<code>--leak-check=full</code></strong></p>
<p><code>/usr/local/bin/valgrind --leak-check=full --log-file=mylog  ./flle-gateway</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">==1373210== HEAP SUMMARY:</span><br><span class="line">==1373210==     <span class="keyword">in</span> use at <span class="built_in">exit</span>: 30,758 bytes <span class="keyword">in</span> 843 blocks</span><br><span class="line">==1373210==   total heap usage: 405,641 allocs, 404,798 frees, 44,538,821 bytes allocated</span><br><span class="line">==1373210==</span><br><span class="line">==1373210== 608 bytes <span class="keyword">in</span> 1 blocks are possibly lost <span class="keyword">in</span> loss record 605 of 613</span><br><span class="line">==1373210==    at 0x4C2B9B5: calloc (vg_replace_malloc.c:711)</span><br><span class="line">==1373210==    by 0x4011DE4: _dl_allocate_tls (<span class="keyword">in</span> /usr/lib64/ld-2.17.so)</span><br><span class="line">==1373210==    by 0x4E3E960: pthread_create@@GLIBC_2.2.5 (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1373210==    by 0x489969: libsgsvc_init (<span class="keyword">in</span> /home/yangguanjun3/storage-file-gateway/userspace/build/storage-flle-gw)</span><br><span class="line">==1373210==    by 0x456B06: FileGateway::init_netlink() (file_gateway.cc:218)</span><br><span class="line">==1373210==    by 0x456CA4: FileGateway::init() (file_gateway.cc:234)</span><br><span class="line">==1373210==    by 0x4537A2: main (main.cc:79)</span><br><span class="line">==1373210==</span><br><span class="line">==1373210== 1,360 bytes <span class="keyword">in</span> 17 blocks are definitely lost <span class="keyword">in</span> loss record 611 of 613</span><br><span class="line">==1373210==    at 0x4C29C23: malloc (vg_replace_malloc.c:299)</span><br><span class="line">==1373210==    by 0x4785C7: Aws::Utils::Stream::PreallocatedStreamBuf* Aws::New&lt;Aws::Utils::Stream::PreallocatedStreamBuf, Aws::Utils::Array&lt;unsigned char&gt;*, unsigned long&gt;(char const*, Aws::Utils::Array&lt;unsigned char&gt;*&amp;&amp;, unsigned long&amp;&amp;) (AWSMemory.h:70)</span><br><span class="line">==1373210==    by 0x473446: S3BackendStorage::put_object_from_file_slice(std::basic_string&lt;char, std::char_traits&lt;char&gt;, Aws::Allocator&lt;char&gt; &gt;, std::basic_string&lt;char, std::char_traits&lt;char&gt;, Aws::Allocator&lt;char&gt; &gt;, std::string const&amp;, unsigned long, unsigned long) (s3_storage.cc:294)</span><br><span class="line">==1373210==    by 0x480110: FileGwS3WorkItem::file_upload() (s3_work_item.cc:147)</span><br><span class="line">==1373210==    by 0x480C0D: FileGwS3WorkItem::process() (s3_work_item.cc:221)</span><br><span class="line">==1373210==    by 0x486316: WorkThread::process_work_item() (work_thread.cc:49)</span><br><span class="line">==1373210==    by 0x486452: WorkThread::entry() (work_thread.cc:78)</span><br><span class="line">==1373210==    by 0x48193C: Thread::_entry_func(void*) (thread.cc:74)</span><br><span class="line">==1373210==    by 0x4E3DDC4: start_thread (<span class="keyword">in</span> /usr/lib64/libpthread-2.17.so)</span><br><span class="line">==1373210==    by 0x6D9FCEC: <span class="built_in">clone</span> (<span class="keyword">in</span> /usr/lib64/libc-2.17.so)</span><br><span class="line">==1373210==</span><br><span class="line">==1373210== LEAK SUMMARY:</span><br><span class="line">==1373210==    definitely lost: 1,360 bytes <span class="keyword">in</span> 17 blocks</span><br><span class="line">==1373210==    indirectly lost: 0 bytes <span class="keyword">in</span> 0 blocks</span><br><span class="line">==1373210==      possibly lost: 608 bytes <span class="keyword">in</span> 1 blocks</span><br><span class="line">==1373210==    still reachable: 28,790 bytes <span class="keyword">in</span> 825 blocks</span><br><span class="line">==1373210==                       of <span class="built_in">which</span> reachable via heuristic:</span><br><span class="line">==1373210==                         stdstring          : 145 bytes <span class="keyword">in</span> 4 blocks</span><br><span class="line">==1373210==         suppressed: 0 bytes <span class="keyword">in</span> 0 blocks</span><br><span class="line">==1373210== Reachable blocks (those to <span class="built_in">which</span> a pointer was found) are not shown.</span><br><span class="line">==1373210== To see them, rerun with: --leak-check=full --show-leak-kinds=all</span><br><span class="line">==1373210==</span><br><span class="line">==1373210== For counts of detected and suppressed errors, rerun with: -v</span><br><span class="line">==1373210== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)</span><br></pre></td></tr></table></figure>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://valgrind.org/docs/manual/manual.html" target="_blank" rel="noopener">http://valgrind.org/docs/manual/manual.html</a><br><a href="http://www.oschina.net/translate/valgrind-memcheck" target="_blank" rel="noopener">http://www.oschina.net/translate/valgrind-memcheck</a><br><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-valgrind/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/l-cn-valgrind/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yangguanjun.com/2017/12/20/ceph-radosgw-where-to-store-data/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/20/ceph-radosgw-where-to-store-data/" itemprop="url">Ceph radosgw where to store data?</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-20T16:31:17+08:00">
                2017-12-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/20/ceph-radosgw-where-to-store-data/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/12/20/ceph-radosgw-where-to-store-data/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>基于ceph jewel 10.2.5版本</p>
<p>参考文档：<a href="http://docs.ceph.com/docs/master/radosgw/layout/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/radosgw/layout/</a></p>
<h2 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h2><p>创建一个user：<code>ictfox</code><br>创建这个user下的一个bucket：<code>bruins</code><br>往bucket里写一个object：<code>hello.txt</code></p>
<p>所以这里的测试数据有：</p>
<ul>
<li>user info</li>
<li>bucket info</li>
<li>object info</li>
</ul>
<blockquote>
<p>注：本文描述了查询radosgw数据和元数据的方法，没有深入去解析一些命令输出；若有错误，欢迎指正 ;)</p>
</blockquote>
<h2 id="RadosGW的pools"><a href="#RadosGW的pools" class="headerlink" title="RadosGW的pools"></a>RadosGW的pools</h2><p>查看<code>radosgw</code>对应的所有pools，其所有的数据也都存在这些pools里。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados lspools</span></span><br><span class="line">.rgw.root</span><br><span class="line">default.rgw.control</span><br><span class="line">default.rgw.data.root</span><br><span class="line">default.rgw.gc</span><br><span class="line">default.rgw.log</span><br><span class="line">default.rgw.users.uid</span><br><span class="line">default.rgw.users.keys</span><br><span class="line">default.rgw.buckets.index</span><br><span class="line">default.rgw.buckets.data</span><br><span class="line">default.rgw.users.swift</span><br><span class="line">default.rgw.users.email</span><br></pre></td></tr></table></figure>
<p>很多<code>pools</code>的用途通过名字就能明确，若要明确<code>pools</code>的用途，请参考代码: <code>rgw/rgw_rados.cc</code></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_storage_pool_suffix = <span class="string">"rgw.buckets.data"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_bucket_index_pool_suffix = <span class="string">"rgw.buckets.index"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_storage_extra_pool_suffix = <span class="string">"rgw.buckets.non-ec"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> zone_info_oid_prefix = <span class="string">"zone_info."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> zone_names_oid_prefix = <span class="string">"zone_names."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> region_info_oid_prefix = <span class="string">"region_info."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> zone_group_info_oid_prefix = <span class="string">"zonegroup_info."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> realm_names_oid_prefix = <span class="string">"realms_names."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> realm_info_oid_prefix = <span class="string">"realms."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_region_info_oid = <span class="string">"default.region"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_zone_group_info_oid = <span class="string">"default.zonegroup"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> period_info_oid_prefix = <span class="string">"periods."</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> period_latest_epoch_info_oid = <span class="string">".latest_epoch"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> region_map_oid = <span class="string">"region_map"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> zonegroup_map_oid = <span class="string">"zonegroup_map"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> log_lock_name = <span class="string">"rgw_log_lock"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> default_realm_info_oid = <span class="string">"default.realm"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="built_in">string</span> default_zonegroup_name = <span class="string">"default"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="built_in">string</span> default_zone_name = <span class="string">"default"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> zonegroup_names_oid_prefix = <span class="string">"zonegroups_names."</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> RGW_DEFAULT_ZONE_ROOT_POOL = <span class="string">"rgw.root"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> RGW_DEFAULT_ZONEGROUP_ROOT_POOL = <span class="string">"rgw.root"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> RGW_DEFAULT_REALM_ROOT_POOL = <span class="string">"rgw.root"</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="built_in">string</span> RGW_DEFAULT_PERIOD_ROOT_POOL = <span class="string">"rgw.root"</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> RGWZoneParams::fix_pool_names()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">list</span>&lt;<span class="built_in">string</span>&gt; zones;</span><br><span class="line">    <span class="keyword">int</span> r = store-&gt;list_zones(zones);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        ldout(cct, <span class="number">10</span>) &lt;&lt; <span class="string">"WARNING: store-&gt;list_zones() returned r="</span> &lt;&lt; r &lt;&lt; dendl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt; pool_names;</span><br><span class="line">    r = get_zones_pool_names_set(cct, store, zones, id, pool_names);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        ldout(cct, <span class="number">0</span>) &lt;&lt; <span class="string">"Error: get_zones_pool_names"</span> &lt;&lt; r &lt;&lt; dendl;</span><br><span class="line">        <span class="keyword">return</span> r;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    domain_root = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.data.root"</span>, domain_root.name);</span><br><span class="line">    <span class="keyword">if</span> (!metadata_heap.name.empty()) &#123;</span><br><span class="line">        metadata_heap = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.meta"</span>, metadata_heap.name);</span><br><span class="line">    &#125;</span><br><span class="line">    control_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.control"</span>, control_pool.name);</span><br><span class="line">    gc_pool = fix_zone_pool_name(pool_names, name,<span class="string">".rgw.gc"</span>, gc_pool.name);</span><br><span class="line">    log_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.log"</span>, log_pool.name);</span><br><span class="line">    intent_log_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.intent-log"</span>, intent_log_pool.name);</span><br><span class="line">    usage_log_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.usage"</span>, usage_log_pool.name);</span><br><span class="line">    user_keys_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.users.keys"</span>, user_keys_pool.name);</span><br><span class="line">    user_email_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.users.email"</span>, user_email_pool.name);</span><br><span class="line">    user_swift_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.users.swift"</span>, user_swift_pool.name);</span><br><span class="line">    user_uid_pool = fix_zone_pool_name(pool_names, name, <span class="string">".rgw.users.uid"</span>, user_uid_pool.name);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span>&amp; iter : placement_pools) &#123;</span><br><span class="line">        iter.second.index_pool = fix_zone_pool_name(pool_names, name, <span class="string">"."</span> + default_bucket_index_pool_suffix,</span><br><span class="line">                                 iter.second.index_pool);</span><br><span class="line">        iter.second.data_pool = fix_zone_pool_name(pool_names, name, <span class="string">"."</span> + default_storage_pool_suffix,</span><br><span class="line">                                iter.second.data_pool);</span><br><span class="line">        iter.second.data_extra_pool= fix_zone_pool_name(pool_names, name, <span class="string">"."</span> + default_storage_extra_pool_suffix,</span><br><span class="line">                                     iter.second.data_extra_pool);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="radosgw的元数据信息"><a href="#radosgw的元数据信息" class="headerlink" title="radosgw的元数据信息"></a>radosgw的元数据信息</h2><p>通过命令<code>radosgw-admin</code>查看原数据信息，包括<code>bucket信息</code>和<code>user信息</code>。</p>
<h3 id="user信息"><a href="#user信息" class="headerlink" title="user信息"></a>user信息</h3><p><code>radosgw-admin user info</code>命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># radosgw-admin user info --uid=ictfox</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"user_id"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">    <span class="string">"display_name"</span>: <span class="string">"mike"</span>,</span><br><span class="line">    <span class="string">"email"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="string">"suspended"</span>: 0,</span><br><span class="line">    <span class="string">"max_buckets"</span>: 1000,</span><br><span class="line">    <span class="string">"auid"</span>: 0,</span><br><span class="line">    <span class="string">"subusers"</span>: [],</span><br><span class="line">    <span class="string">"keys"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"user"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">            <span class="string">"access_key"</span>: <span class="string">"IYZ800MDM7VF3EDLISC7"</span>,</span><br><span class="line">            <span class="string">"secret_key"</span>: <span class="string">"05HfpRrrh1Gs1p8bxBbcn2HcGp0n7UvuaMNPCuHS"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"swift_keys"</span>: [],</span><br><span class="line">    <span class="string">"caps"</span>: [],</span><br><span class="line">    <span class="string">"op_mask"</span>: <span class="string">"read, write, delete"</span>,</span><br><span class="line">    <span class="string">"default_placement"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="string">"placement_tags"</span>: [],</span><br><span class="line">    <span class="string">"bucket_quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"user_quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"temp_url_keys"</span>: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>radosgw-admin metadata</code>命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># radosgw-admin metadata list user</span></span><br><span class="line">[</span><br><span class="line">    <span class="string">"ictfox"</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># radosgw-admin metadata get user:ictfox</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"key"</span>: <span class="string">"user:ictfox"</span>,</span><br><span class="line">    <span class="string">"ver"</span>: &#123;</span><br><span class="line">        <span class="string">"tag"</span>: <span class="string">"_laJXG6YTAtNd-Dzt78okwU5"</span>,</span><br><span class="line">        <span class="string">"ver"</span>: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mtime"</span>: <span class="string">"2017-03-14 08:49:04.735466Z"</span>,</span><br><span class="line">    <span class="string">"data"</span>: &#123;</span><br><span class="line">        <span class="string">"user_id"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">        <span class="string">"display_name"</span>: <span class="string">"mike"</span>,</span><br><span class="line">        <span class="string">"email"</span>: <span class="string">""</span>,</span><br><span class="line">        <span class="string">"suspended"</span>: 0,</span><br><span class="line">        <span class="string">"max_buckets"</span>: 1000,</span><br><span class="line">        <span class="string">"auid"</span>: 0,</span><br><span class="line">        <span class="string">"subusers"</span>: [],</span><br><span class="line">        <span class="string">"keys"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"user"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">                <span class="string">"access_key"</span>: <span class="string">"IYZ800MDM7VF3EDLISC7"</span>,</span><br><span class="line">                <span class="string">"secret_key"</span>: <span class="string">"05HfpRrrh1Gs1p8bxBbcn2HcGp0n7UvuaMNPCuHS"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"swift_keys"</span>: [],</span><br><span class="line">        <span class="string">"caps"</span>: [],</span><br><span class="line">        <span class="string">"op_mask"</span>: <span class="string">"read, write, delete"</span>,</span><br><span class="line">        <span class="string">"default_placement"</span>: <span class="string">""</span>,</span><br><span class="line">        <span class="string">"placement_tags"</span>: [],</span><br><span class="line">        <span class="string">"bucket_quota"</span>: &#123;</span><br><span class="line">            <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">            <span class="string">"max_objects"</span>: -1</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"user_quota"</span>: &#123;</span><br><span class="line">            <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">            <span class="string">"max_objects"</span>: -1</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"temp_url_keys"</span>: [],</span><br><span class="line">        <span class="string">"attrs"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"key"</span>: <span class="string">"user.rgw.idtag"</span>,</span><br><span class="line">                <span class="string">"val"</span>: <span class="string">""</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"key"</span>: <span class="string">"user.rgw.manifest"</span>,</span><br><span class="line">                <span class="string">"val"</span>: <span class="string">""</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="bucket信息"><a href="#bucket信息" class="headerlink" title="bucket信息"></a>bucket信息</h3><p><code>radosgw-admin bucket stats</code>命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># radosgw-admin bucket stats --bucket=bruins</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"bucket"</span>: <span class="string">"bruins"</span>,</span><br><span class="line">    <span class="string">"pool"</span>: <span class="string">"default.rgw.buckets.data"</span>,</span><br><span class="line">    <span class="string">"index_pool"</span>: <span class="string">"default.rgw.buckets.index"</span>,</span><br><span class="line">    <span class="string">"id"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">    <span class="string">"marker"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">    <span class="string">"owner"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">    <span class="string">"ver"</span>: <span class="string">"0#11"</span>,</span><br><span class="line">    <span class="string">"master_ver"</span>: <span class="string">"0#0"</span>,</span><br><span class="line">    <span class="string">"mtime"</span>: <span class="string">"2017-03-15 00:46:37.189715"</span>,</span><br><span class="line">    <span class="string">"max_marker"</span>: <span class="string">"0#"</span>,</span><br><span class="line">    <span class="string">"usage"</span>: &#123;</span><br><span class="line">        <span class="string">"rgw.main"</span>: &#123;</span><br><span class="line">            <span class="string">"size_kb"</span>: 1,</span><br><span class="line">            <span class="string">"size_kb_actual"</span>: 4,</span><br><span class="line">            <span class="string">"num_objects"</span>: 1</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"bucket_quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>radosgw-admin metadata</code>命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># radosgw-admin metadata list bucket</span></span><br><span class="line">[</span><br><span class="line">    <span class="string">"bruins"</span>,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># radosgw-admin metadata get bucket:bruins</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"key"</span>: <span class="string">"bucket:bruins"</span>,</span><br><span class="line">    <span class="string">"ver"</span>: &#123;</span><br><span class="line">        <span class="string">"tag"</span>: <span class="string">"_osgTpZcD-jCFgcwdi3yvHmH"</span>,</span><br><span class="line">        <span class="string">"ver"</span>: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mtime"</span>: <span class="string">"2017-03-15 04:46:37.193584Z"</span>,</span><br><span class="line">    <span class="string">"data"</span>: &#123;</span><br><span class="line">        <span class="string">"bucket"</span>: &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"bruins"</span>,</span><br><span class="line">            <span class="string">"pool"</span>: <span class="string">"default.rgw.buckets.data"</span>,</span><br><span class="line">            <span class="string">"data_extra_pool"</span>: <span class="string">"default.rgw.buckets.non-ec"</span>,</span><br><span class="line">            <span class="string">"index_pool"</span>: <span class="string">"default.rgw.buckets.index"</span>,</span><br><span class="line">            <span class="string">"marker"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">            <span class="string">"bucket_id"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">            <span class="string">"tenant"</span>: <span class="string">""</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"owner"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">        <span class="string">"creation_time"</span>: <span class="string">"0.000000"</span>,</span><br><span class="line">        <span class="string">"linked"</span>: <span class="string">"true"</span>,</span><br><span class="line">        <span class="string">"has_bucket_info"</span>: <span class="string">"false"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># radosgw-admin metadata list bucket.instance</span></span><br><span class="line">[</span><br><span class="line">    <span class="string">"bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># radosgw-admin metadata get bucket.instance:bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"key"</span>: <span class="string">"bucket.instance:bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">    <span class="string">"ver"</span>: &#123;</span><br><span class="line">        <span class="string">"tag"</span>: <span class="string">"_n2XczjnP1PYx3Hg88iruBbm"</span>,</span><br><span class="line">        <span class="string">"ver"</span>: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"mtime"</span>: <span class="string">"2017-03-15 04:46:37.189715Z"</span>,</span><br><span class="line">    <span class="string">"data"</span>: &#123;</span><br><span class="line">        <span class="string">"bucket_info"</span>: &#123;</span><br><span class="line">            <span class="string">"bucket"</span>: &#123;</span><br><span class="line">                <span class="string">"name"</span>: <span class="string">"bruins"</span>,</span><br><span class="line">                <span class="string">"pool"</span>: <span class="string">"default.rgw.buckets.data"</span>,</span><br><span class="line">                <span class="string">"data_extra_pool"</span>: <span class="string">"default.rgw.buckets.non-ec"</span>,</span><br><span class="line">                <span class="string">"index_pool"</span>: <span class="string">"default.rgw.buckets.index"</span>,</span><br><span class="line">                <span class="string">"marker"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">                <span class="string">"bucket_id"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">                <span class="string">"tenant"</span>: <span class="string">""</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"creation_time"</span>: <span class="string">"0.000000"</span>,</span><br><span class="line">            <span class="string">"owner"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">            <span class="string">"flags"</span>: 0,</span><br><span class="line">            <span class="string">"zonegroup"</span>: <span class="string">"d40f14ea-4700-43e7-a92e-fa232f28b590"</span>,</span><br><span class="line">            <span class="string">"placement_rule"</span>: <span class="string">"default-placement"</span>,</span><br><span class="line">            <span class="string">"has_instance_obj"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"quota"</span>: &#123;</span><br><span class="line">                <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">                <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">                <span class="string">"max_objects"</span>: -1</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"num_shards"</span>: 0,</span><br><span class="line">            <span class="string">"bi_shard_hash_type"</span>: 0,</span><br><span class="line">            <span class="string">"requester_pays"</span>: <span class="string">"false"</span>,</span><br><span class="line">            <span class="string">"has_website"</span>: <span class="string">"false"</span>,</span><br><span class="line">            <span class="string">"swift_versioning"</span>: <span class="string">"false"</span>,</span><br><span class="line">            <span class="string">"swift_ver_location"</span>: <span class="string">""</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"attrs"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"key"</span>: <span class="string">"user.rgw.acl"</span>,</span><br><span class="line">                <span class="string">"val"</span>: <span class="string">"AgJ7AAAAAwISAAAABgAAAGljdGZveAQAAABtaWtlAwNdAAAAAQEAAAAGAAAAaWN0Zm94DwAAAAEAAAAGAAAAaWN0Zm94BAMyAAAAAgIEAAAAAAAAAAYAAABpY3Rmb3gAAAAAAAAAAAICBAAAAA8AAAAEAAAAbWlrZQAAAAAAAAAA"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"key"</span>: <span class="string">"user.rgw.idtag"</span>,</span><br><span class="line">                <span class="string">"val"</span>: <span class="string">""</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"key"</span>: <span class="string">"user.rgw.manifest"</span>,</span><br><span class="line">                <span class="string">"val"</span>: <span class="string">""</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="rgw的user-uid信息保存格式"><a href="#rgw的user-uid信息保存格式" class="headerlink" title="rgw的user uid信息保存格式"></a>rgw的user uid信息保存格式</h2><p>每个user在该pool里都有两个<code>objects</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados ls -p default.rgw.users.uid</span></span><br><span class="line">ictfox.buckets</span><br><span class="line">ictfox</span><br></pre></td></tr></table></figure>
<p>查看两个<code>objects</code>的<code>omap</code>和<code>存储数据</code>：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.users.uid listomapvals ictfox</span></span><br><span class="line"><span class="comment"># rados -p default.rgw.users.uid get ictfox file</span></span><br><span class="line"><span class="comment"># cat file</span></span><br><span class="line">ictfox   .IYZ800MDM7VF3EDLISC7(05HfpRrrh1Gs1p8bxBbcn2HcGp0n7UvuaMNPCuHSmikeictfoxIYZ800MDM7VF3EDLISC7HIYZ800MDM7VF3EDLISC7(05HfpRrrh1Gs1p8bxBbcn2HcGp0n7UvuaMNPCuHS���������������������������������</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.users.uid listomapkeys ictfox.buckets</span></span><br><span class="line">bruins</span><br><span class="line"><span class="comment"># rados -p default.rgw.users.uid listomapvals ictfox.buckets</span></span><br><span class="line">bruins</span><br><span class="line">value (246 bytes) :</span><br><span class="line">00000000  07 05 f0 00 00 00 00 00  00 00 0c 00 00 00 00 00  |................|</span><br><span class="line">00000010  00 00 2d c7 c8 58 01 00  00 00 00 00 00 00 07 03  |..-..X..........|</span><br><span class="line">00000020  c1 00 00 00 06 00 00 00  62 72 75 69 6e 73 18 00  |........bruins..|</span><br><span class="line">00000030  00 00 64 65 66 61 75 6c  74 2e 72 67 77 2e 62 75  |..default.rgw.bu|</span><br><span class="line">00000040  63 6b 65 74 73 2e 64 61  74 61 2c 00 00 00 30 37  |ckets.data,...07|</span><br><span class="line">00000050  30 65 63 31 32 39 2d 32  65 38 34 2d 34 37 66 65  |0ec129-2e84-47fe|</span><br><span class="line">00000060  2d 62 33 32 61 2d 62 30  62 66 39 39 31 34 61 35  |-b32a-b0bf9914a5|</span><br><span class="line">00000070  31 66 2e 31 34 32 37 34  2e 31 2c 00 00 00 30 37  |1f.14274.1,...07|</span><br><span class="line">00000080  30 65 63 31 32 39 2d 32  65 38 34 2d 34 37 66 65  |0ec129-2e84-47fe|</span><br><span class="line">00000090  2d 62 33 32 61 2d 62 30  62 66 39 39 31 34 61 35  |-b32a-b0bf9914a5|</span><br><span class="line">000000a0  31 66 2e 31 34 32 37 34  2e 31 19 00 00 00 64 65  |1f.14274.1....de|</span><br><span class="line">000000b0  66 61 75 6c 74 2e 72 67  77 2e 62 75 63 6b 65 74  |fault.rgw.bucket|</span><br><span class="line">000000c0  73 2e 69 6e 64 65 78 1a  00 00 00 64 65 66 61 75  |s.index....defau|</span><br><span class="line">000000d0  6c 74 2e 72 67 77 2e 62  75 63 6b 65 74 73 2e 6e  |lt.rgw.buckets.n|</span><br><span class="line">000000e0  6f 6e 2d 65 63 00 10 00  00 00 00 00 00 01 2d c7  |on-ec.........-.|</span><br><span class="line">000000f0  c8 58 1a 7f b4 0b                                 |.X....|</span><br><span class="line">000000f6</span><br></pre></td></tr></table></figure>
<h2 id="rgw的user-keys信息保存格式"><a href="#rgw的user-keys信息保存格式" class="headerlink" title="rgw的user keys信息保存格式"></a>rgw的user keys信息保存格式</h2><p>每个user在该pool里都有一个以<code>&lt;access_key&gt;</code>的值命名的<code>object</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados ls -p default.rgw.users.keys</span></span><br><span class="line">IYZ800MDM7VF3EDLISC7</span><br></pre></td></tr></table></figure>
<p>查看该<code>object</code>的<code>omap</code>和<code>存储数据</code>：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.users.keys listomapvals IYZ800MDM7VF3EDLISC7</span></span><br><span class="line"><span class="comment"># rados -p default.rgw.users.keys get IYZ800MDM7VF3EDLISC7 file</span></span><br><span class="line"><span class="comment"># cat file</span></span><br><span class="line">ictfox</span><br></pre></td></tr></table></figure>
<h2 id="rgw的user-bucket原数据信息保存格式"><a href="#rgw的user-bucket原数据信息保存格式" class="headerlink" title="rgw的user bucket原数据信息保存格式"></a>rgw的user bucket原数据信息保存格式</h2><p>格式：<code>.dir.&lt;bucket id&gt;</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.buckets.index ls</span></span><br><span class="line">.dir.070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span><br></pre></td></tr></table></figure>
<p>查看该<code>object</code>的<code>omap</code>和<code>存储数据</code>：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.buckets.index get .dir.070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1 file</span></span><br><span class="line"><span class="comment"># cat file</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># rados -p default.rgw.buckets.index listomapkeys .dir.070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span></span><br><span class="line">hello.txt</span><br><span class="line"><span class="comment"># rados -p default.rgw.buckets.index listomapvals .dir.070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span></span><br><span class="line">hello.txt</span><br><span class="line">value (196 bytes) :</span><br><span class="line">00000000  08 03 be 00 00 00 09 00  00 00 68 65 6c 6c 6f 2e  |..........hello.|</span><br><span class="line">00000010  74 78 74 06 00 00 00 00  00 00 00 01 04 03 53 00  |txt...........S.|</span><br><span class="line">00000020  00 00 01 0c 00 00 00 00  00 00 00 21 e8 c8 58 42  |...........!..XB|</span><br><span class="line">00000030  2f 40 29 20 00 00 00 65  64 30 37 36 32 38 37 35  |/@) ...ed0762875|</span><br><span class="line">00000040  33 32 65 38 36 33 36 35  65 38 34 31 65 39 32 62  |32e86365e841e92b|</span><br><span class="line">00000050  66 63 35 30 64 38 63 06  00 00 00 69 63 74 66 6f  |fc50d8c....ictfo|</span><br><span class="line">00000060  78 04 00 00 00 6d 69 6b  65 00 00 00 00 0c 00 00  |x....mike.......|</span><br><span class="line">00000070  00 00 00 00 00 00 00 00  00 00 00 00 00 01 01 02  |................|</span><br><span class="line">00000080  00 00 00 09 06 0a 2c 00  00 00 30 37 30 65 63 31  |......,...070ec1|</span><br><span class="line">00000090  32 39 2d 32 65 38 34 2d  34 37 66 65 2d 62 33 32  |29-2e84-47fe-b32|</span><br><span class="line">000000a0  61 2d 62 30 62 66 39 39  31 34 61 35 31 66 2e 31  |a-b0bf9914a51f.1|</span><br><span class="line">000000b0  34 32 34 35 2e 35 00 00  00 00 00 00 00 00 00 00  |4245.5..........|</span><br><span class="line">000000c0  00 00 00 00                                       |....|</span><br><span class="line">000000c4</span><br></pre></td></tr></table></figure>
<h2 id="rgw的user-bucket中对象数据保存格式"><a href="#rgw的user-bucket中对象数据保存格式" class="headerlink" title="rgw的user bucket中对象数据保存格式"></a>rgw的user bucket中对象数据保存格式</h2><p>每个<code>object</code>没有<code>omap</code>信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.buckets.data ls</span></span><br><span class="line">070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1_hello.txt</span><br><span class="line"><span class="comment"># rados -p default.rgw.buckets.data get 070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1_hello.txt file</span></span><br><span class="line"><span class="comment"># cat file</span></span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line"><span class="comment"># rados -p default.rgw.buckets.data listomapvals 070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1_hello.txt</span></span><br></pre></td></tr></table></figure>
<p>查看<code>object</code>的<code>xattr</code>信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.buckets.data listxattr 070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1_hello.txt</span></span><br><span class="line">user.rgw.acl</span><br><span class="line">user.rgw.cache_control</span><br><span class="line">user.rgw.etag</span><br><span class="line">user.rgw.idtag</span><br><span class="line">user.rgw.manifest</span><br><span class="line">user.rgw.pg_ver</span><br><span class="line">user.rgw.source_zone</span><br><span class="line"><span class="comment"># rados -p default.rgw.buckets.data getxattr 070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1_hello.txt user.rgw.acl</span></span><br><span class="line">&#123;ictfoxmike]ictfoxictfox2ictfoxmike</span><br></pre></td></tr></table></figure>
<h2 id="rgw的user-bucket的metadata信息"><a href="#rgw的user-bucket的metadata信息" class="headerlink" title="rgw的user bucket的metadata信息"></a>rgw的user bucket的metadata信息</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.data.root ls</span></span><br><span class="line">bruins</span><br><span class="line">.bucket.meta.bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span><br></pre></td></tr></table></figure>
<p>每个<code>object</code>没有<code>omap</code>信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># rados -p default.rgw.data.root listomapvals bruins</span><br><span class="line"># rados -p default.rgw.data.root listomapvals .bucket.meta.bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span><br></pre></td></tr></table></figure>
<p>查看<code>object</code>的<code>存储数据</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.data.root get bruins file</span></span><br><span class="line"><span class="comment"># cat file</span></span><br><span class="line"></span><br><span class="line">�bruinsdefault.rgw.buckets.data,070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1,070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1default.rgw.buckets.indexdefault.rgw.buckets.non-ecictfoxictfox</span><br><span class="line"></span><br><span class="line"><span class="comment"># rados -p default.rgw.data.root get .bucket.meta.bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1 file</span></span><br><span class="line"><span class="comment"># ceph-dencoder type RGWBucketInfo import file decode dump_json</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"bucket"</span>: &#123;</span><br><span class="line">        <span class="string">"name"</span>: <span class="string">"bruins"</span>,</span><br><span class="line">        <span class="string">"pool"</span>: <span class="string">"default.rgw.buckets.data"</span>,</span><br><span class="line">        <span class="string">"data_extra_pool"</span>: <span class="string">"default.rgw.buckets.non-ec"</span>,</span><br><span class="line">        <span class="string">"index_pool"</span>: <span class="string">"default.rgw.buckets.index"</span>,</span><br><span class="line">        <span class="string">"marker"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">        <span class="string">"bucket_id"</span>: <span class="string">"070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1"</span>,</span><br><span class="line">        <span class="string">"tenant"</span>: <span class="string">""</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"creation_time"</span>: <span class="string">"0.000000"</span>,</span><br><span class="line">    <span class="string">"owner"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">    <span class="string">"flags"</span>: 0,</span><br><span class="line">    <span class="string">"zonegroup"</span>: <span class="string">"d40f14ea-4700-43e7-a92e-fa232f28b590"</span>,</span><br><span class="line">    <span class="string">"placement_rule"</span>: <span class="string">"default-placement"</span>,</span><br><span class="line">    <span class="string">"has_instance_obj"</span>: <span class="string">"true"</span>,</span><br><span class="line">    <span class="string">"quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"num_shards"</span>: 0,</span><br><span class="line">    <span class="string">"bi_shard_hash_type"</span>: 0,</span><br><span class="line">    <span class="string">"requester_pays"</span>: <span class="string">"false"</span>,</span><br><span class="line">    <span class="string">"has_website"</span>: <span class="string">"false"</span>,</span><br><span class="line">    <span class="string">"swift_versioning"</span>: <span class="string">"false"</span>,</span><br><span class="line">    <span class="string">"swift_ver_location"</span>: <span class="string">""</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查看<code>object</code>的<code>xattr</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rados -p default.rgw.data.root listxattr bruins</span></span><br><span class="line">ceph.objclass.version</span><br><span class="line"><span class="comment"># rados -p default.rgw.data.root getxattr bruins ceph.objclass.version</span></span><br><span class="line"><span class="variable">$_osgTpZcD</span>-jCFgcwdi3yvHmH</span><br><span class="line"></span><br><span class="line"><span class="comment"># rados -p default.rgw.data.root listxattr .bucket.meta.bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1</span></span><br><span class="line">ceph.objclass.version</span><br><span class="line">user.rgw.acl</span><br><span class="line"><span class="comment"># rados -p default.rgw.data.root getxattr .bucket.meta.bruins:070ec129-2e84-47fe-b32a-b0bf9914a51f.14274.1 user.rgw.acl &gt; file</span></span><br><span class="line"><span class="comment"># ceph-dencoder type RGWAccessControlPolicy import file decode dump_json</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"acl"</span>: &#123;</span><br><span class="line">        <span class="string">"acl_user_map"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"user"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">                <span class="string">"acl"</span>: 15</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"acl_group_map"</span>: [],</span><br><span class="line">        <span class="string">"grant_map"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"id"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">                <span class="string">"grant"</span>: &#123;</span><br><span class="line">                    <span class="string">"type"</span>: &#123;</span><br><span class="line">                        <span class="string">"type"</span>: 0</span><br><span class="line">                    &#125;,</span><br><span class="line">                    <span class="string">"id"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">                    <span class="string">"email"</span>: <span class="string">""</span>,</span><br><span class="line">                    <span class="string">"permission"</span>: &#123;</span><br><span class="line">                        <span class="string">"flags"</span>: 15</span><br><span class="line">                    &#125;,</span><br><span class="line">                    <span class="string">"name"</span>: <span class="string">"mike"</span>,</span><br><span class="line">                    <span class="string">"group"</span>: 0</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"owner"</span>: &#123;</span><br><span class="line">        <span class="string">"id"</span>: <span class="string">"ictfox"</span>,</span><br><span class="line">        <span class="string">"display_name"</span>: <span class="string">"mike"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/ictfox.jpg"
                alt="ictfox" />
            
              <p class="site-author-name" itemprop="name">ictfox</p>
              <p class="site-description motion-element" itemprop="description">学无止境</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">77</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">50</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ictfox" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/smart_bruins" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://weibo.com/ictfox" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.askceph.com" title="Ceph问答社区" target="_blank">Ceph问答社区</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.csdn.net/for_tech" title="CSDN博客" target="_blank">CSDN博客</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ictfox</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://ictfox.disqus.com/count.js" async></script>
    

    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
