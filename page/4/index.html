<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="ictfox blog">
<meta property="og:url" content="http://www.ictfox.cn/page/4/index.html">
<meta property="og:site_name" content="ictfox blog">
<meta property="og:description" content="学无止境">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ictfox blog">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.ictfox.cn/page/4/"/>





  <title>ictfox blog</title>
  








  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-7472013512056838",
    enable_page_level_ads: true
  });
</script>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ictfox blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">ForTech</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/06/12/ceph-radosgw-multisite/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/12/ceph-radosgw-multisite/" itemprop="url">对象存储跨区灾备 - RGW MultiSite</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-12T21:31:37+08:00">
                2017-06-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/12/ceph-radosgw-multisite/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/06/12/ceph-radosgw-multisite/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>实现对象存储的跨区灾备，提供应用的高可用。</p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>针对对象存储的跨区灾备，在Jewel版本之前，需要通过独立的radosgw-agent进程来实现，配置步骤参考：<a href="http://www.yangguanjun.com/2017/05/09/rgw-multi-region/" target="_blank" rel="noopener">对象存储跨机房容灾调研</a></p>
<p>但在<code>Jewel</code>版本中，RGW直接通过<code>radosgw进程</code>实现对象存储的跨区灾备，不需要额外的<code>radosgw-agent</code>进程，同时一些概念也有所变化；例如替换<code>region</code>为<code>zonegroup</code>，提出新的<code>realm</code>，<code>period</code>概念等；</p>
<h3 id="配置参考"><a href="#配置参考" class="headerlink" title="配置参考"></a>配置参考</h3><p><a href="http://docs.ceph.com/docs/jewel/radosgw/multisite/" target="_blank" rel="noopener">http://docs.ceph.com/docs/jewel/radosgw/multisite/</a></p>
<p><a href="https://access.redhat.com/documentation/en/red-hat-ceph-storage/2/paged/object-gateway-guide-for-red-hat-enterprise-linux/chapter-8-multi-site" target="_blank" rel="noopener">https://access.redhat.com/documentation/en/red-hat-ceph-storage/2/paged/object-gateway-guide-for-red-hat-enterprise-linux/chapter-8-multi-site</a></p>
<p>ceph官网的配置<code>multisite</code>的文档不完善，还有一些错误；参考RedHat的文档比较好</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Ceph版本：Jewel 10.2.3</p>
<p>Ceph Cluster：两个Ceph Cluster集群（虚拟机搭建）</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><p>两个Ceph Cluster集群，每个上面选择一台机器提供radosgw服务；</p>
<table>
<thead>
<tr>
<th>cluster</th>
<th>节点</th>
<th>radosgw节点</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ceph集群1</td>
<td>ceph21, ceph22, ceph23</td>
<td>ceph21</td>
</tr>
<tr>
<td>Ceph集群2</td>
<td>ceph31, ceph32, ceph33</td>
<td>ceph31</td>
</tr>
</tbody>
</table>
<h3 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h3><p>对<code>RGW MULTISITE</code>来说，在一个<code>realm</code>里，需要配置一个<code>master zonegroup</code>，一个或多个<code>secondary zonegroups</code>（貌似可以配置多个独立的<code>zonegroup</code>）；在一个<code>zonegroup</code>中需要配置一个<code>master zone</code>，一个或多个<code>secondary zones</code>；<br><img src="/images/ceph-radosgw-multisite1.jpg" alt="radosgw multisite"></p>
<p>而在我们的应用中，我们只需要北京的两个sites做灾备，所以我们的配置如下：</p>
<p>配置一个<code>realm</code>，包含一个<code>master zonegroup</code>，里面配置ceph集群1作为<code>master zone</code>，ceph集群2作为<code>secondary zone</code>；</p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><h4 id="ceph21节点配置master-zone"><a href="#ceph21节点配置master-zone" class="headerlink" title="ceph21节点配置master zone"></a>ceph21节点配置master zone</h4><ol>
<li><p>创建需要的pools</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@ceph21:~/mikeyang/rgw<span class="comment"># cat rgwPoolCreate.sh</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">ceph osd pool create .rgw.root 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.control 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.data.root 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.gc 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.log 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.intent-log 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.usage 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.users.keys 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.users.email 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.users.swift 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.users.uid 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.buckets.index 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.buckets.data 32 32</span><br><span class="line">ceph osd pool create bj-zone02.rgw.meta 32 32</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建realm，zonegroup和master zone</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create realm, zonegroup and zone</span></span><br><span class="line">radosgw-admin realm create --rgw-realm=cloudin --default</span><br><span class="line">radosgw-admin zonegroup create --rgw-zonegroup=bj --endpoints=http://&lt;self-ip&gt;:80 --rgw-realm=cloudin --master --default</span><br><span class="line">radosgw-admin zone create --rgw-zonegroup=bj --rgw-zone=bj-zone02 --endpoints=http://&lt;self-ip&gt;:80 --default --master</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除default的zonegrou，zone，更新period</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># remove default zonegroup and zone, which maybe not needed</span></span><br><span class="line">radosgw-admin zonegroup remove --rgw-zonegroup=default --rgw-zone=default</span><br><span class="line">radosgw-admin period update --commit</span><br><span class="line">radosgw-admin zone delete --rgw-zone=default</span><br><span class="line">radosgw-admin period update --commit</span><br><span class="line">radosgw-admin zonegroup delete --rgw-zonegroup=default</span><br><span class="line">radosgw-admin period update --commit</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建同步需要的user</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">radosgw-admin user create --uid=zone.user --display-name=<span class="string">"Zone User"</span> --system</span><br><span class="line">radosgw-admin zone modify --rgw-zone=bj-zone02 --access-key=&#123;system-key&#125; --secret=&#123;secret&#125;</span><br><span class="line">radosgw-admin period update --commit</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注释：–access-key={system-key} –secret={secret}，对应user create中的access-key, secret</p>
</blockquote>
</li>
</ol>
<ol>
<li><p>修改ceph.conf，启动radosgw</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ceph/ceph.conf</span><br><span class="line">[client.rgw.ceph21]</span><br><span class="line">   host = ceph21</span><br><span class="line">   rgw_frontends = <span class="string">"civetweb port=80"</span></span><br><span class="line">   rgw_zone=bj-zone02</span><br><span class="line"> </span><br><span class="line">service radosgw start id=rgw.ceph21</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="ceph31节点配置secondary-zone"><a href="#ceph31节点配置secondary-zone" class="headerlink" title="ceph31节点配置secondary zone"></a>ceph31节点配置secondary zone</h4><ol>
<li><p>创建需要的pools</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@ceph31:~/mikeyang/rgw<span class="comment"># cat rgwPoolCreate.sh</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">ceph osd pool create .rgw.root 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.control 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.data.root 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.gc 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.log 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.intent-log 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.usage 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.users.keys 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.users.email 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.users.swift 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.users.uid 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.buckets.index 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.buckets.data 32 32</span><br><span class="line">ceph osd pool create bj-zone03.rgw.meta 32 32</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取master zone的realm，zonegroup，period信息</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">radosgw-admin realm pull --url=http://&lt;master-zone-ip&gt;:80 --access-key=&#123;system-key&#125; --secret=&#123;secret&#125;</span><br><span class="line">radosgw-admin realm default --rgw-realm=cloudin</span><br><span class="line">radosgw-admin period pull --url=http://&lt;master-zone-ip&gt;:80 --access-key=&#123;system-key&#125; --secret=&#123;secret&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注释：–access-key={system-key} –secret={secret}，这部分是master zone的同步user的access-key, secret</p>
</blockquote>
</li>
<li><p>创建secondary zone</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">radosgw-admin zone create --rgw-zonegroup=bj --rgw-zone=bj-zone03 --endpoints=http://&lt;self-ip&gt;:80 --access-key=&#123;system-key&#125; --secret=&#123;secret&#125;</span><br><span class="line">radosgw-admin zone delete --rgw-zone=default</span><br><span class="line">radosgw-admin period update --commit</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注释：–access-key={system-key} –secret={secret}，这部分是master zone的同步user的access-key, secret</p>
</blockquote>
</li>
<li><p>修改ceph.conf，启动radosgw</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ceph/ceph.conf</span><br><span class="line">[client.rgw.ceph31]</span><br><span class="line">   host = ceph31</span><br><span class="line">   rgw_frontends = <span class="string">"civetweb port=80"</span></span><br><span class="line">   rgw_zone=bj-zone03</span><br><span class="line"> </span><br><span class="line">service radosgw start id=rgw.ceph31</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="检查集群状态"><a href="#检查集群状态" class="headerlink" title="检查集群状态"></a>检查集群状态</h4><ol>
<li><p>master zone节点检查</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@ceph21:~/mikeyang/rgw<span class="comment"># radosgw-admin sync status</span></span><br><span class="line">2016-10-26 11:18:45.124701 7fd18c502900  0 error <span class="keyword">in</span> read_id <span class="keyword">for</span> id  : (2) No such file or directory</span><br><span class="line">2016-10-26 11:18:45.125156 7fd18c502900  0 error <span class="keyword">in</span> read_id <span class="keyword">for</span> id  : (2) No such file or directory</span><br><span class="line">          realm 0b64b20e-2a90-4fc4-a1d6-57fc67457564 (cloudin)</span><br><span class="line">      zonegroup 1bfc8ccd-01ae-477e-a332-af4cb00d3f20 (bj)</span><br><span class="line">           zone 9f621425-cd68-4d2f-b3e7-e85814caef2c (bj-zone02)</span><br><span class="line">  metadata sync no sync (zone is master)</span><br><span class="line">      data sync <span class="built_in">source</span>: 249b96bd-8f86-4326-80e0-7fceca78dec1 (bj-zone03)</span><br><span class="line">                        syncing</span><br><span class="line">                        full sync: 0/128 shards</span><br><span class="line">                        incremental sync: 128/128 shards</span><br><span class="line">                        data is caught up with <span class="built_in">source</span></span><br><span class="line">root@ceph21:~/mikeyang/rgw<span class="comment">#</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>secondary zone节点检查</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@ceph31:~/mikeyang/rgw<span class="comment"># radosgw-admin sync status</span></span><br><span class="line">2016-10-26 11:19:41.715683 7fa016bef900  0 error <span class="keyword">in</span> read_id <span class="keyword">for</span> id  : (2) No such file or directory</span><br><span class="line">2016-10-26 11:19:41.716289 7fa016bef900  0 error <span class="keyword">in</span> read_id <span class="keyword">for</span> id  : (2) No such file or directory</span><br><span class="line">          realm 0b64b20e-2a90-4fc4-a1d6-57fc67457564 (cloudin)</span><br><span class="line">      zonegroup 1bfc8ccd-01ae-477e-a332-af4cb00d3f20 (bj)</span><br><span class="line">           zone 249b96bd-8f86-4326-80e0-7fceca78dec1 (bj-zone03)</span><br><span class="line">  metadata sync syncing</span><br><span class="line">                full sync: 0/64 shards</span><br><span class="line">                metadata is caught up with master</span><br><span class="line">                incremental sync: 64/64 shards</span><br><span class="line">      data sync <span class="built_in">source</span>: 9f621425-cd68-4d2f-b3e7-e85814caef2c (bj-zone02)</span><br><span class="line">                        syncing</span><br><span class="line">                        full sync: 0/128 shards</span><br><span class="line">                        incremental sync: 128/128 shards</span><br><span class="line">                        data is caught up with <span class="built_in">source</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注释：上述输出中有两条error log输出，这个是radosgw的一个bug，还没修复，对正确性没有影响。</p>
</blockquote>
</li>
</ol>
<h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>之前说过，<code>Jewel</code>版本的radosgw对应的pool和使用方式都跟<code>Hammer</code>有不少区别，所以在从<code>Hammer</code>升级到<code>Jewel</code>后，需要考虑之前的对象存储数据迁移；</p>
<p>鉴于我们现在对象存储仅仅<code>RDS</code>在使用，数据量也不大，所以在中断对象存储服务的情况下，迁移是比较容易完成的，步骤如下：</p>
<ol>
<li><p>导出现有的user信息；</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">openstack@BJBGP02-02-01:~$ radosgw-admin metadata list user</span><br><span class="line">[</span><br><span class="line">    <span class="string">"cloudInS3User"</span></span><br><span class="line">]</span><br><span class="line">openstack@BJBGP02-02-01:~$ radosgw-admin user info --uid=cloudInS3User</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"user_id"</span>: <span class="string">"cloudInS3User"</span>,</span><br><span class="line">    <span class="string">"display_name"</span>: <span class="string">"user for s3"</span>,</span><br><span class="line">    <span class="string">"email"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="string">"suspended"</span>: 0,</span><br><span class="line">    <span class="string">"max_buckets"</span>: 1000,</span><br><span class="line">    <span class="string">"auid"</span>: 0,</span><br><span class="line">    <span class="string">"subusers"</span>: [],</span><br><span class="line">    <span class="string">"keys"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"user"</span>: <span class="string">"cloudInS3User"</span>,</span><br><span class="line">            <span class="string">"access_key"</span>: <span class="string">"N8JYDX1HCAM55XDWGL10"</span>,</span><br><span class="line">            <span class="string">"secret_key"</span>: <span class="string">"uRpR6EbR9YkyjfvdQmuJq0VgEx1a0KONl0NCKlJ9"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"swift_keys"</span>: [],</span><br><span class="line">    <span class="string">"caps"</span>: [],</span><br><span class="line">    <span class="string">"op_mask"</span>: <span class="string">"read, write, delete"</span>,</span><br><span class="line">    <span class="string">"default_placement"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="string">"placement_tags"</span>: [],</span><br><span class="line">    <span class="string">"bucket_quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"user_quota"</span>: &#123;</span><br><span class="line">        <span class="string">"enabled"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"max_size_kb"</span>: -1,</span><br><span class="line">        <span class="string">"max_objects"</span>: -1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"temp_url_keys"</span>: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 当前系统只有一个用于RDS备份的user：cloudInS3User</p>
</li>
<li><p>导出现有user下的bucket信息；</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openstack@BJBGP02-02-01:~$ radosgw-admin metadata list bucket</span><br><span class="line">[</span><br><span class="line">    <span class="string">"database_backups"</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</li>
<li><p>导出现有bucket下的对象；</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	ictfox@YangGuanjun-MacBook-Pro:~$ s3cmd ls s3://database_backups</span><br><span class="line">	2016-09-01 08:22    276864   s3://database_backups/03f55add-fda5-404e-99b2-04b34b32ec56.xbstream.gz.enc</span><br><span class="line">	2016-09-05 03:14    279232   s3://database_backups/147a2c80-0f7d-4ecd-9c4a-e9a48b7cd703.xbstream.gz.enc</span><br><span class="line">...</span><br><span class="line">	2016-09-01 09:38    278320   s3://database_backups/dbfee332-5f4e-4596-bef6-63797a24d9e0.xbstream.gz.enc</span><br><span class="line">	2016-08-31 09:54    276144   s3://database_backups/f703131f-7dd7-43a6-9b20-7fe33a9fbe59.xbstream.gz.enc</span><br></pre></td></tr></table></figure>
<p> 然后通过命令把bucket下的对象保存下来：<code>s3cmd get s3://database_backups/OBJECT LOCAL_FILE</code></p>
</li>
<li><p>radosgw升级后恢复数据</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># radosgw-admin user create --uid="cloudInS3User" --display-name="user for s3" --access-key=N8JYDX1HCAM55XDWGL10 --secret=uRpR6EbR9YkyjfvdQmuJq0VgEx1a0KONl0NCKlJ9</span></span><br></pre></td></tr></table></figure>
<p> 通过测试的RDS实例创建一备份，会自动创建bucket: database_backups<br> 然后恢复第3步中备份下来的各个对象文件</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># s3cmd put FILE [FILE...] s3://database_backups/</span></span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/06/08/cephfs-client-debug/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/08/cephfs-client-debug/" itemprop="url">cephfs kernel client debug</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-08T12:01:17+08:00">
                2017-06-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/08/cephfs-client-debug/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/06/08/cephfs-client-debug/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="获取源码"><a href="#获取源码" class="headerlink" title="获取源码"></a>获取源码</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uname -a</span></span><br><span class="line">Linux Server 3.10.0-327.el7.x86_64 <span class="comment">#1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>
<p>从网上搜索下载Linux对应版本的源码，这里的源码版本为：3.10.0-327</p>
<h2 id="查看cephfs-client端模块"><a href="#查看cephfs-client端模块" class="headerlink" title="查看cephfs client端模块"></a>查看cephfs client端模块</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsmod | grep ceph</span></span><br><span class="line">ceph                  202130  1</span><br><span class="line">libceph               189287  2 rbd,ceph</span><br><span class="line"></span><br><span class="line"><span class="comment"># modinfo ceph</span></span><br><span class="line">filename:       /lib/modules/3.10.0-327.el7.x86_64/kernel/fs/ceph/ceph.ko</span><br><span class="line">license:        GPL</span><br><span class="line">description:    Ceph filesystem <span class="keyword">for</span> Linux</span><br><span class="line">author:         Patience Warnick &lt;patience@newdream.net&gt;</span><br><span class="line">author:         Yehuda Sadeh &lt;yehuda@hq.newdream.net&gt;</span><br><span class="line">author:         Sage Weil &lt;sage@newdream.net&gt;</span><br><span class="line"><span class="built_in">alias</span>:          fs-ceph</span><br><span class="line">rhelversion:    7.2</span><br><span class="line">srcversion:     268CE83A90FA60A7654BE27</span><br><span class="line">depends:        libceph</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       3.10.0-327.el7.x86_64 SMP mod_unload modversions</span><br><span class="line">signer:         CentOS Linux kernel signing key</span><br><span class="line">sig_key:        79:AD:88:6A:11:3C:A0:22:35:26:33:6C:0F:82:5B:8A:94:29:6A:B3</span><br><span class="line">sig_hashalgo:   sha25</span><br><span class="line"></span><br><span class="line"><span class="comment"># modinfo libceph</span></span><br><span class="line">filename:       /lib/modules/3.10.0-327.el7.x86_64/kernel/net/ceph/libceph.ko</span><br><span class="line">license:        GPL</span><br><span class="line">description:    Ceph filesystem <span class="keyword">for</span> Linux</span><br><span class="line">author:         Patience Warnick &lt;patience@newdream.net&gt;</span><br><span class="line">author:         Yehuda Sadeh &lt;yehuda@hq.newdream.net&gt;</span><br><span class="line">author:         Sage Weil &lt;sage@newdream.net&gt;</span><br><span class="line">rhelversion:    7.2</span><br><span class="line">srcversion:     BA3AB21E57822D9AC6B9463</span><br><span class="line">depends:        libcrc32c,dns_resolver</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       3.10.0-327.el7.x86_64 SMP mod_unload modversions</span><br><span class="line">signer:         CentOS Linux kernel signing key</span><br><span class="line">sig_key:        79:AD:88:6A:11:3C:A0:22:35:26:33:6C:0F:82:5B:8A:94:29:6A:B3</span><br><span class="line">sig_hashalgo:   sha256</span><br></pre></td></tr></table></figure>
<h2 id="修改cephfs源码"><a href="#修改cephfs源码" class="headerlink" title="修改cephfs源码"></a>修改cephfs源码</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">到kernel源码目录</span><br><span class="line"><span class="comment"># vim include/linux/ceph/ceph_debug.h</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># if defined(DEBUG) || defined(CONFIG_DYNAMIC_DEBUG)</span></span><br><span class="line">/* 删除这块代码</span><br><span class="line">extern const char *ceph_file_part(const char *s, int len);</span><br><span class="line"><span class="comment">#  define dout(fmt, ...)                        \</span></span><br><span class="line">    pr_debug(<span class="string">"%.*s %12.12s:%-4d : "</span> fmt,                \</span><br><span class="line">         8 - (int)sizeof(KBUILD_MODNAME), <span class="string">"    "</span>,       \</span><br><span class="line">         ceph_file_part(__FILE__, sizeof(__FILE__)),        \</span><br><span class="line">         __LINE__, <span class="comment">##__VA_ARGS__)</span></span><br><span class="line"><span class="comment"># else</span></span><br><span class="line">*/</span><br><span class="line">/* faux printk call just to see any compiler warnings. */</span><br><span class="line"><span class="comment">#  define dout(fmt, ...)    do &#123;                \</span></span><br><span class="line">        <span class="keyword">if</span> (1)                      \                   // <span class="keyword">if</span>(0) 修改为 <span class="keyword">if</span>(1)</span><br><span class="line">            printk(KERN_DEBUG fmt, <span class="comment">##__VA_ARGS__);  \</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (0)</span><br><span class="line"><span class="comment"># endif</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#else</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>结合自己版本里的源码，随意修改，使dout()函数能正常打印log就ok；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># cp /boot/config-3.10.0-327.el7.x86_64 ./</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># mv config-3.10.0-327.el7.x86_64 .config</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># vim .config</span></span><br><span class="line">...</span><br><span class="line">CONFIG_CEPH_LIB_PRETTYDEBUG=y		// 打开CEPH的相关DEBUG配置</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="编译并替换cephfs的模块"><a href="#编译并替换cephfs的模块" class="headerlink" title="编译并替换cephfs的模块"></a>编译并替换cephfs的模块</h2><p>编译cephfs使用的kernel module</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># make</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># ll fs/ceph/ceph.ko</span></span><br><span class="line">-rw-r--r-- 1 root root 4901829 Jun  7 09:39 fs/ceph/ceph.ko</span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># ll net/ceph/libceph.ko</span></span><br><span class="line">-rw-r--r-- 1 root root 4099969 Jun  7 09:40 net/ceph/libceph.ko</span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># ll drivers/block/rbd.ko</span></span><br><span class="line">-rw-r--r-- 1 root root 966206 Jun  7 09:37 drivers/block/rbd.ko</span><br></pre></td></tr></table></figure>
<p>替换cephfs的这几个模块</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># lsmod | grep rbd</span></span><br><span class="line">rbd                    58242  0</span><br><span class="line">libceph               189287  2 rbd,ceph    // rbd使用libceph module，替换libceph的话，先要删除rbd module</span><br><span class="line"></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># rmmod rbd</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># rmmod ceph</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># rmmod libceph</span></span><br><span class="line"></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># cp net/ceph/libceph.ko /lib/modules/3.10.0-327.el7.x86_64/kernel/net/ceph/libceph.ko</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># cp fs/ceph/ceph.ko /lib/modules/3.10.0-327.el7.x86_64/kernel/fs/ceph/ceph.ko</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># cp drivers/block/rbd.ko /lib/modules/3.10.0-327.el7.x86_64/kernel/drivers/block/rbd.ko</span></span><br><span class="line"></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># modprobe ceph</span></span><br><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># modprobe rbd</span></span><br></pre></td></tr></table></figure>
<p>并不是每次修改cephfs的代码，都需要编译整个kernel的，后续仅仅需要编译对应的module即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@server linux-3.10.0-327.el7]<span class="comment"># make M=fs/ceph</span></span><br></pre></td></tr></table></figure>
<h2 id="测试查看cephfs-debug-log"><a href="#测试查看cephfs-debug-log" class="headerlink" title="测试查看cephfs debug log"></a>测试查看cephfs debug log</h2><p>mount cephfs并触发写操作</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -t ceph 10.10.1.1:6789:/ /mnt/</span></span><br><span class="line"><span class="comment"># cd /mnt</span></span><br><span class="line"><span class="comment"># dd if=/dev/zero of=tstfile bs=4M count=1 oflag=direct</span></span><br></pre></td></tr></table></figure>
<p>检查cephfs的kernel log</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmesg -c &gt; /dev/null</span></span><br><span class="line"><span class="comment"># dmesg -c &gt; ~/cephfs.log</span></span><br><span class="line"><span class="comment"># vim ~/cephfs.log</span></span><br><span class="line">...</span><br><span class="line">[3034497.087430] aio_write ffff8801271b0e48 10000002393.fffffffffffffffe 0~4194304 got <span class="built_in">cap</span> refs on Fwb</span><br><span class="line">[3034497.087432] sync_direct_write on file ffff882013dddf00 0~4194304</span><br><span class="line">[3034497.087449] ceph_msg_new ffff88135e1ec000 front 512</span><br><span class="line">[3034497.087450] ceph_msg_new ffff88135e1ec0f0 front 277</span><br><span class="line">[3034497.087451] mapping 0~4194304  osize 4194304 fl_su 4194304</span><br><span class="line">[3034497.087452] osize 4194304 / su 4194304 = su_per_object 1</span><br><span class="line">[3034497.087454] off 0 / su 4194304 = bl 0</span><br><span class="line">[3034497.087455] objset 0 * sc 1 = ono 0</span><br><span class="line">[3034497.087455]  obj extent 0~4194304</span><br><span class="line">[3034497.087457] calc_layout objnum=0 0~4194304</span><br><span class="line">[3034497.087576] oid <span class="string">'10000002393.00000000'</span> len 20</span><br><span class="line">[3034497.087578] build_request msg_size was 197</span><br><span class="line">[3034497.087580] __register_request ffff88111d798000 tid 8</span><br><span class="line">[3034497.087585] ceph_osdc_get_request ffff88111d798000 (was 1)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="配置kernel-log文件"><a href="#配置kernel-log文件" class="headerlink" title="配置kernel log文件"></a>配置kernel log文件</h2><p>若不想每次从dmesg里获取kernel debug log，在centos里可以配置到指定文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/rsyslog.conf</span></span><br><span class="line">...</span><br><span class="line">kern.*                                                 /var/<span class="built_in">log</span>/kern.log   // 配置kernel <span class="built_in">log</span>文件</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># service rsyslog restart		// 重启rsyslog服务</span></span><br></pre></td></tr></table></figure>
<p>之后就可以在<code>/var/log/kern.log</code>里查看cephfs的debug log了</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/06/02/cephfs-intro-fun/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/02/cephfs-intro-fun/" itemprop="url">cephfs介绍和功能测试</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-02T18:31:17+08:00">
                2017-06-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/06/02/cephfs-intro-fun/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/06/02/cephfs-intro-fun/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="cephfs简介"><a href="#cephfs简介" class="headerlink" title="cephfs简介"></a>cephfs简介</h2><p>cephfs是ceph提供的兼容POSIX协议的文件系统，对比rbd和rgw功能，这个是ceph里最晚满足production ready的一个功能，它底层还是使用rados存储数据</p>
<h3 id="cephfs的架构"><a href="#cephfs的架构" class="headerlink" title="cephfs的架构"></a>cephfs的架构</h3><p><img src="/images/cephfs-intro-fun1.jpg" alt="cephfs arch"></p>
<h3 id="使用cephfs的两种方式"><a href="#使用cephfs的两种方式" class="headerlink" title="使用cephfs的两种方式"></a>使用cephfs的两种方式</h3><ol>
<li>cephfs kernel module</li>
<li>cephfs-fuse</li>
</ol>
<p>从上面的架构可以看出，cephfs-fuse的IO path比较长，性能会比cephfs kernel module的方式差一些；</p>
<h3 id="client端访问cephfs的流程"><a href="#client端访问cephfs的流程" class="headerlink" title="client端访问cephfs的流程"></a>client端访问cephfs的流程</h3><p><img src="/images/ceph-used-in-cloudin7.jpg" alt="mds work"></p>
<ol>
<li>client端与mds节点通讯，获取metadata信息（metadata也存在osd上）</li>
<li>client直接写数据到osd</li>
</ol>
<h2 id="mds部署"><a href="#mds部署" class="headerlink" title="mds部署"></a>mds部署</h2><p>使用ceph-deploy部署ceph mds很方便，只需要简单的一条命令就搞定，不过它依赖之前ceph-deploy时候生成的一些配置和keyring文件；</p>
<p>在之前部署ceph集群的节点目录，执行ceph-deploy mds create：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph-deploy --overwrite-conf mds create server1:mds-daemon-1</span></span><br><span class="line"></span><br><span class="line">// 去节点检查下daemon</span><br><span class="line">[root@server1 yangguanjun]<span class="comment"># ps aux | grep ceph-mds</span></span><br><span class="line">ceph      1138  0.0  0.0 3011880 14301 ?       Ssl  10:21   0:00 /usr/bin/ceph-mds -f --cluster ceph --id mds-daemon-2 --setuser ceph --setgroup ceph</span><br></pre></td></tr></table></figure>
<h2 id="创建cephfs"><a href="#创建cephfs" class="headerlink" title="创建cephfs"></a>创建cephfs</h2><h3 id="创建第一个cephfs"><a href="#创建第一个cephfs" class="headerlink" title="创建第一个cephfs"></a>创建第一个cephfs</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph osd pool create cephfs_data 512 512        // 创建data pool</span></span><br><span class="line">pool <span class="string">'cephfs_data'</span> created</span><br><span class="line"><span class="comment"># ceph osd pool create cephfs_metadata 512 512    // 创建metadata pool</span></span><br><span class="line">pool <span class="string">'cephfs_metadata'</span> created</span><br><span class="line"><span class="comment"># ceph fs new tstfs cephfs_metadata cephfs_data   // 创建cephfs</span></span><br><span class="line">new fs with metadata pool 10 and data pool 9</span><br><span class="line"><span class="comment"># ceph fs ls</span></span><br><span class="line">name: tstfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]</span><br></pre></td></tr></table></figure>
<h3 id="创建第二个cephfs"><a href="#创建第二个cephfs" class="headerlink" title="创建第二个cephfs"></a>创建第二个cephfs</h3><p>默认cephfs是不支持多个fs的，这个还是试验阶段的feature，需要打开 enable_multiple 的flag</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph osd pool create cephfs_metadata2 512 512</span></span><br><span class="line">pool <span class="string">'cephfs_metadata2’ created</span></span><br><span class="line"><span class="string"># ceph osd pool create cephfs_data2 512 512</span></span><br><span class="line"><span class="string">pool '</span>cephfs_data2’ created</span><br><span class="line"></span><br><span class="line"><span class="comment"># ceph fs new tstfs2 cephfs_metadata2 cephfs_data2</span></span><br><span class="line">Error EINVAL: Creation of multiple filesystems is disabled.  To <span class="built_in">enable</span> this experimental feature, use <span class="string">'ceph fs flag set enable_multiple true'</span></span><br><span class="line"><span class="comment"># ceph fs flag set enable_multiple true</span></span><br><span class="line">Warning! This feature is experimental.It may cause problems up to and including data loss.Consult the documentation at ceph.com, and <span class="keyword">if</span> unsure, <span class="keyword">do</span> not proceed.Add --yes-i-really-mean-it <span class="keyword">if</span> you are certain.</span><br><span class="line"><span class="comment"># ceph fs flag set enable_multiple true --yes-i-really-mean-it</span></span><br><span class="line"><span class="comment"># ceph fs new tstfs2 cephfs_metadata2 cephfs_data2</span></span><br><span class="line">new fs with metadata pool 11 and data pool 12</span><br></pre></td></tr></table></figure>
<h3 id="查看mds状态"><a href="#查看mds状态" class="headerlink" title="查看mds状态"></a>查看mds状态</h3><p>ceph的mds是一个单独的daemon，它只能服务于一个cephfs，若cephfs指定多个rank了，它只能服务于其中一个rank</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph mds stat</span></span><br><span class="line">e8: tstfs-1/1/1 up tstfs2-0/0/1 up &#123;[tstfs:0]=mds-daemon-1=up:active&#125;</span><br></pre></td></tr></table></figure>
<p>对输出解释如下：</p>
<ul>
<li><code>e8</code> : e标识epoch，8是epoch号</li>
<li><code>tstfs-1/1/1 up</code> : <code>tstfs</code>是cephfs名字，后面的三个1分别是<code>mds_map.in/mds_map.up/mds_map.max_mds</code>，<code>up</code>是cephfs状态</li>
<li><code>{[tstfs:0]=mds-daemon-1=up:active}</code> :  <code>[tstfs:0]</code>指tstfs的rank 0，<code>mds-daemon-1</code>是服务tstfs的mds daemon name，<code>up:active</code>是cephfs的状态为 up &amp; active</li>
</ul>
<p>从上面的输出可以看出，两个cephfs只有<code>tstfs</code>是active的，它的mds daemon为<code>mds-daemon-1</code></p>
<h4 id="在ceph-deploy节点添加mds-daemon-2-1"><a href="#在ceph-deploy节点添加mds-daemon-2-1" class="headerlink" title="在ceph-deploy节点添加mds-daemon-2-1"></a>在ceph-deploy节点添加mds-daemon-2-1</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph mds stat</span></span><br><span class="line">e11: tstfs-1/1/1 up tstfs2-1/1/1 up &#123;[tstfs2:0]=mds-daemon-2-1=up:active,[tstfs:0]=mds-daemon-1=up:active&#125;</span><br></pre></td></tr></table></figure>
<p>添加新的mds daemon后，它会自动服务于一个没有mds daemon的cephfs</p>
<h4 id="在ceph-deploy节点添加mds-daemon-2-2"><a href="#在ceph-deploy节点添加mds-daemon-2-2" class="headerlink" title="在ceph-deploy节点添加mds-daemon-2-2"></a>在ceph-deploy节点添加mds-daemon-2-2</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph mds stat</span></span><br><span class="line">e12: tstfs-1/1/1 up tstfs2-1/1/1 up &#123;[tstfs2:0]=mds-daemon-2=up:active,[tstfs:0]=mds-daemon=up:active&#125;, 1 up:standby</span><br></pre></td></tr></table></figure>
<p>又添加一个新的mds daemon后，它会处于standby状态，若前两个mds daemon出问题，它会顶替上去，顶替的规则可以配置，详情参考文章：<a href="http://docs.ceph.com/docs/master/cephfs/standby/#configuring-standby-daemons" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/cephfs/standby/#configuring-standby-daemons</a></p>
<p>查看节点上的两个mds daemon进程</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@server2 yangguanjun]<span class="comment"># ps aux | grep ceph-mds</span></span><br><span class="line">ceph      2362  0.0  0.0 3061884 14604 ?       Ssl  10:26   0:00 /usr/bin/ceph-mds -f --cluster ceph --id mds-daemon-2-1 --setuser ceph --setgroup ceph</span><br><span class="line">ceph      3031  0.0  0.0 3390588 13872 ?       Ssl  10:27   0:00 /usr/bin/ceph-mds -f --cluster ceph --id mds-daemon-2-2 --setuser ceph --setgroup ceph</span><br></pre></td></tr></table></figure>
<h2 id="cephfs的使用"><a href="#cephfs的使用" class="headerlink" title="cephfs的使用"></a>cephfs的使用</h2><h3 id="mount-amp-umount"><a href="#mount-amp-umount" class="headerlink" title="mount &amp; umount"></a>mount &amp; umount</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -t ceph 10.10.1.2:6789:/ /mnt/tstfs2/</span></span><br><span class="line"><span class="comment"># umount /mnt/tstfs2</span></span><br><span class="line"><span class="comment"># mount | grep tstfs2</span></span><br><span class="line">10.10.1.1:6789:/ on /mnt/tstfs2 <span class="built_in">type</span> ceph (rw,relatime)</span><br></pre></td></tr></table></figure>
<h3 id="是否支持多个cephfs？"><a href="#是否支持多个cephfs？" class="headerlink" title="是否支持多个cephfs？"></a>是否支持多个cephfs？</h3><p>前面我们提到可以在一个ceph cluster里创建多个cephfs，指定不同的data/metadata pool，有不同的mds daemon服务，但如何使用不同的cephfs呢？</p>
<ol>
<li><p>kernel cephfs</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -t ceph 10.10.1.2:6789:/ /mnt/tstfs2/ -o mds_namespace=tstfs</span></span><br><span class="line">mount error 22 = Invalid argument</span><br></pre></td></tr></table></figure>
<p> 这个问题的bug信息：<a href="http://tracker.ceph.com/issues/18161" target="_blank" rel="noopener">http://tracker.ceph.com/issues/18161</a></p>
</li>
<li><p>ceph-fuse<br> <strong>待验证</strong></p>
</li>
</ol>
<h3 id="查看cephfs状态"><a href="#查看cephfs状态" class="headerlink" title="查看cephfs状态"></a>查看cephfs状态</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph fs get tstfs</span></span><br><span class="line">Filesystem <span class="string">'tstfs'</span> (1)</span><br><span class="line">fs_name    tstfs</span><br><span class="line">epoch    13</span><br><span class="line">flags    0</span><br><span class="line">created    2017-05-23 10:21:55.889234</span><br><span class="line">modified    2017-05-23 10:21:55.889234</span><br><span class="line">tableserver    0</span><br><span class="line">root    0</span><br><span class="line">session_timeout    60</span><br><span class="line">session_autoclose    300</span><br><span class="line">max_file_size    1099511627776</span><br><span class="line">last_failure    0</span><br><span class="line">last_failure_osd_epoch    0</span><br><span class="line">compat    compat=&#123;&#125;,rocompat=&#123;&#125;,incompat=&#123;1=base v0.20,2=client writeable ranges,3=default file layouts on <span class="built_in">dirs</span>,4=dir inode <span class="keyword">in</span> separate object,5=mds uses versioned encoding,6=dirfrag is stored <span class="keyword">in</span> omap,8=file layout v2&#125;</span><br><span class="line">max_mds    1</span><br><span class="line"><span class="keyword">in</span>    0</span><br><span class="line">up    &#123;0=4456&#125;</span><br><span class="line">failed</span><br><span class="line">damaged</span><br><span class="line">stopped</span><br><span class="line">data_pools    9</span><br><span class="line">metadata_pool    10</span><br><span class="line">inline_data    disabled</span><br><span class="line">4456:    10.10.1.1:6820/1655250084 <span class="string">'mds-daemon-1'</span> mds.0.4 up:active seq 484</span><br></pre></td></tr></table></figure>
<h3 id="配置cephfs的multi-mds"><a href="#配置cephfs的multi-mds" class="headerlink" title="配置cephfs的multi mds"></a>配置cephfs的multi mds</h3><p><strong>cephfs的multi mds属性还不是production ready，不要用在生成环境哦，自己测试下玩玩就行</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph mds stat</span></span><br><span class="line">e13: tstfs-1/1/1 up tstfs2-1/1/1 up &#123;[tstfs2:0]=mds-daemon-2-1=up:active,[tstfs:0]=mds-daemon-1=up:active&#125;, 1 up:standby</span><br><span class="line"><span class="comment"># ceph fs set tstfs allow_multimds true --yes-i-really-mean-it</span></span><br><span class="line"><span class="comment"># ceph fs set tstfs max_mds 2</span></span><br><span class="line"><span class="comment"># ceph mds stat</span></span><br><span class="line">e17: tstfs-2/2/2 up tstfs2-1/1/1 up &#123;[tstfs2:0]=mds-daemon-2-1=up:active,[tstfs:0]=mds-daemon-1=up:active,[tstfs:1]=mds-daemon-2-2=up:active&#125;</span><br></pre></td></tr></table></figure>
<p>从上面输出可以看出，设置<code>tstfs</code>的<code>max_mds</code>为2后，它会自动寻找一个standby的mds daemon服务，现在看到的<code>tstfs</code>的信息为：<br><code>tstfs-2/2/2 up</code>和<code>[tstfs:0]=mds-daemon-1=up:active,[tstfs:1]=mds-daemon-2-2=up:active</code></p>
<h2 id="删除cephfs和mds"><a href="#删除cephfs和mds" class="headerlink" title="删除cephfs和mds"></a>删除cephfs和mds</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">机器上停止ceph mds服务</span><br><span class="line"><span class="comment"># systemctl stop ceph-mds.target</span></span><br><span class="line"></span><br><span class="line">删除cephfs，有mds daemons的cephfs删除会报错，然后去mds daemon机器上停止mds服务即可</span><br><span class="line"><span class="comment"># ceph fs rm tstfs</span></span><br><span class="line">Error EINVAL: all MDS daemons must be inactive before removing filesystem</span><br><span class="line"><span class="comment"># ceph fs rm tstfs2</span></span><br><span class="line">Error EPERM: this is a DESTRUCTIVE operation and will make data <span class="keyword">in</span> your filesystem permanentlyinaccessible.  Add --yes-i-really-mean-it <span class="keyword">if</span> you are sure you wish to <span class="built_in">continue</span>.</span><br><span class="line"><span class="comment"># ceph fs rm tstfs2 --yes-i-really-mean-it</span></span><br><span class="line"><span class="comment"># ceph fs rm tstfs --yes-i-really-mean-it</span></span><br><span class="line"></span><br><span class="line">删除ceph nonactive mds，mds的id默认从0开始，指定不存在的id并不会报错</span><br><span class="line"><span class="comment"># ceph mds rm 0</span></span><br><span class="line">mds gid 0 dne</span><br><span class="line"><span class="comment"># ceph mds rm 1</span></span><br><span class="line">mds gid 1 dne</span><br><span class="line"><span class="comment"># ceph mds rm 2</span></span><br><span class="line">mds gid 2 dne</span><br><span class="line"></span><br><span class="line">删除cephfs使用的pool</span><br><span class="line"><span class="comment"># ceph osd pool delete cephfs_metadata cephfs_metadata --yes-i-really-really-mean-it</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://docs.ceph.com/docs/master/cephfs/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/cephfs/</a><br><a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html-single/ceph_file_system_guide_technology_preview/" target="_blank" rel="noopener">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/2/html-single/ceph_file_system_guide_technology_preview/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/31/ceph-pg-inconsistent-error/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/31/ceph-pg-inconsistent-error/" itemprop="url">Ceph PG Inconsistent Error处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-31T00:31:17+08:00">
                2017-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/31/ceph-pg-inconsistent-error/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/31/ceph-pg-inconsistent-error/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>ceph集群状态为<code>HEALTH_ERR</code>，<code>ceph -s</code>显示有pg状态不一致，<code>ceph health detail</code>输出如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph health detail</span></span><br><span class="line">HEALTH_ERR 2 pgs inconsistent; 1 pgs repair; 8 scrub errors</span><br><span class="line">pg 14.16a is active+clean+scrubbing+deep+inconsistent+repair, acting [1,27,16]</span><br><span class="line">pg 15.118 is active+clean+inconsistent, acting [0,15,27]</span><br><span class="line">8 scrub errors</span><br></pre></td></tr></table></figure>
<h2 id="分析-amp-解决"><a href="#分析-amp-解决" class="headerlink" title="分析 &amp; 解决"></a>分析 &amp; 解决</h2><ol>
<li><p>手动执行pg修复<br> <code>ceph pg repair 14.16a</code><br> <code>ceph pg deep-scrub 14.16a</code><br> <strong>结果</strong>：集群状态依旧<code>HEALTH_ERR</code></p>
</li>
<li><p>重启对应osd daemon<br> <code>systemctl restart ceph-osd@&lt;osdid&gt;.service</code><br> <strong>结果</strong>：集群状态依旧<code>HEALTH_ERR</code></p>
</li>
<li><p>检查ceph-osd log</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim ceph-osd.1.log-20170531.gz</span></span><br><span class="line">...</span><br><span class="line">2017-05-31 02:30:14.166348 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56a14fcc:::10000002380.0000061d:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.166358 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56a7ab13:::10000002380.00000446:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.166361 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56b34a7a:::10000002356.00000218:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.166363 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56c557e8:::10000002380.0000007a:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.166366 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56c8ceeb:::10000002380.00000854:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.166372 7f7aeefff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a shard 27: soid 14:56f50799:::1000000237c.0000019a:head candidate had a <span class="built_in">read</span> error</span><br><span class="line">2017-05-31 02:30:14.168485 7f7acebff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a deep-scrub 0 missing, 6 inconsistent objects</span><br><span class="line">2017-05-31 02:30:14.168499 7f7acebff700 -1 log_channel(cluster) <span class="built_in">log</span> [ERR] : 14.16a deep-scrub 6 errors</span><br></pre></td></tr></table></figure>
<p> 上面可以看出<code>pg 14.16a</code>里有几个objects报告<code>candidate had a read error</code></p>
<p> 查看出错的object的md5值</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># md5sum /var/lib/ceph/osd/ceph-1/current/14.16a_head/10000002380.0000061d__head_33F2856A__e</span></span><br><span class="line">dc191d3144c49077952ed059425d68b1  /var/lib/ceph/osd/ceph-1/current/14.16a_head/10000002380.0000061d__head_33F2856A__e</span><br><span class="line"></span><br><span class="line"><span class="comment"># md5sum /var/lib/ceph/osd/ceph-16/current/14.16a_head/10000002380.0000061d__head_33F2856A__e</span></span><br><span class="line">dc191d3144c49077952ed059425d68b1  /var/lib/ceph/osd/ceph-16/current/14.16a_head/10000002380.0000061d__head_33F2856A__e</span><br><span class="line"></span><br><span class="line"><span class="comment"># md5sum /var/lib/ceph/osd/ceph-27/current/14.16a_head/10000002380.0000061d__head_33F2856A__e</span></span><br><span class="line">md5sum: /var/lib/ceph/osd/ceph-27/current/14.16a_head/10000002380.0000061d__head_33F2856A__e: Input/output error</span><br></pre></td></tr></table></figure>
<p> 上面得出<code>ceph-27</code>上的object获取md5值失败，报<code>Input/output error</code>，这里猜测其对应的磁盘有问题；<br> 查看<code>ceph-27</code>上<code>pg 14.16a</code>里别的object的md5值，输出正常，则证明磁盘还能工作，可能是文件有损坏，也可能磁盘上有部分坏道；</p>
<p> 删除md5sum报IO错误的文件，然后执行<code>ceph pg repair 14.16a</code>，pg状态恢复正常；</p>
</li>
</ol>
<h2 id="磁盘检查与恢复"><a href="#磁盘检查与恢复" class="headerlink" title="磁盘检查与恢复"></a>磁盘检查与恢复</h2><p>那磁盘是否有问题呢？执行以下步骤来检测并恢复：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl stop ceph-osd@27.service</span></span><br><span class="line"><span class="comment"># umount /dev/sdi1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># badblocks -svn /dev/sdi1 -o badblocks.log</span></span><br><span class="line">Checking <span class="keyword">for</span> bad blocks <span class="keyword">in</span> non-destructive <span class="built_in">read</span>-write mode</span><br><span class="line">From block 0 to 3906984774</span><br><span class="line">Checking <span class="keyword">for</span> bad blocks (non-destructive <span class="built_in">read</span>-write <span class="built_in">test</span>)</span><br><span class="line">Testing with random pattern: 0.00% <span class="keyword">done</span>, 16:22 elapsed. (223/0/0 errors)</span><br></pre></td></tr></table></figure>
<p>上述检查会花费比较长时间，一般SATA盘的read速度为100-120MB/s，4TB大小的SATA盘，约需要<code>4*1024*1024/120/3600 = 9.7</code>小时；</p>
<p>不过你可以在别的窗口查看输出文件<code>badblocks.log</code>的内容，如果里面有信息，那证明你的磁盘确实有坏块，就需要尝试恢复检查了:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># head -n 10 badblocks.log</span></span><br><span class="line">10624</span><br><span class="line">10625</span><br><span class="line">10626</span><br><span class="line">10627</span><br><span class="line">10628</span><br><span class="line">10629</span><br><span class="line">10630</span><br><span class="line">10631</span><br><span class="line">10632</span><br><span class="line">10633</span><br><span class="line"></span><br><span class="line"><span class="built_in">kill</span> badblocks检查进程</span><br><span class="line"><span class="comment"># ps aux | pgrep badblocks | xargs kill -9</span></span><br><span class="line">[1]+  Killed                  badblocks -v /dev/sdi1 &gt; badblocks</span><br></pre></td></tr></table></figure>
<p>通过badblocks修复坏块，<strong>注意会丢失坏块里的数据</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># badblocks -ws /dev/sdi1 10633 10624</span></span><br><span class="line">Testing with pattern 0xaa: <span class="keyword">done</span></span><br><span class="line">Reading and comparing: <span class="keyword">done</span></span><br><span class="line">Testing with pattern 0x55: <span class="keyword">done</span></span><br><span class="line">Reading and comparing: <span class="keyword">done</span></span><br><span class="line">Testing with pattern 0xff: <span class="keyword">done</span></span><br><span class="line">Reading and comparing: <span class="keyword">done</span></span><br><span class="line">Testing with pattern 0x00: <span class="keyword">done</span></span><br><span class="line">Reading and comparing: <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># badblocks -svn /dev/sdi1 10633 10624</span></span><br><span class="line">Checking <span class="keyword">for</span> bad blocks <span class="keyword">in</span> non-destructive <span class="built_in">read</span>-write mode</span><br><span class="line">From block 10624 to 10633</span><br><span class="line">Checking <span class="keyword">for</span> bad blocks (non-destructive <span class="built_in">read</span>-write <span class="built_in">test</span>)</span><br><span class="line">Testing with random pattern: <span class="keyword">done</span></span><br><span class="line">Pass completed, 0 bad blocks found. (0/0/0 errors)</span><br></pre></td></tr></table></figure>
<p>通过上述步骤恢复了磁盘中的坏块，有如下两种情况：</p>
<ol>
<li><p>坏块中有xfs的元数据信息<br> 执行xfs_repair修复磁盘上的xfs系统，很可能报错；<br> 没有办法，只能重新格式化磁盘，然后执行ceph的recovery了；</p>
</li>
<li><p>坏块中无xfs的元数据信息<br> 通过xfs_repair修复磁盘上的xfs系统，报告done</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xfs_repair  -f /dev/sdi1</span></span><br><span class="line">Phase 1 - find and verify superblock...</span><br><span class="line">Cannot get host filesystem geometry.</span><br><span class="line">Repair may fail <span class="keyword">if</span> there is a sector size mismatch between</span><br><span class="line">the image and the host filesystem.</span><br><span class="line">        - reporting progress <span class="keyword">in</span> intervals of 15 minutes</span><br><span class="line">Phase 2 - using internal <span class="built_in">log</span></span><br><span class="line">        - zero <span class="built_in">log</span>...</span><br><span class="line">        - scan filesystem freespace and inode maps...</span><br><span class="line">        - 15:23:37: scanning filesystem freespace - 32 of 32 allocation groups <span class="keyword">done</span></span><br><span class="line">        - found root inode chunk</span><br><span class="line">Phase 3 - <span class="keyword">for</span> each AG...</span><br><span class="line">        - scan and clear agi unlinked lists...</span><br><span class="line">        - 15:23:37: scanning agi unlinked lists - 32 of 32 allocation groups <span class="keyword">done</span></span><br><span class="line">        - process known inodes and perform inode discovery...</span><br><span class="line">        - agno = 15</span><br><span class="line">        - agno = 0</span><br><span class="line">        - agno = 30</span><br><span class="line">        - agno = 31</span><br><span class="line">        - agno = 16</span><br><span class="line">        - agno = 1</span><br><span class="line">        - agno = 2</span><br><span class="line">        - agno = 17</span><br><span class="line">        - agno = 18</span><br><span class="line">        - agno = 19</span><br><span class="line">        - agno = 3</span><br><span class="line">        - agno = 4</span><br><span class="line">        - agno = 5</span><br><span class="line">        - agno = 6</span><br><span class="line">        - agno = 7</span><br><span class="line">        - agno = 20</span><br><span class="line">        - agno = 21</span><br><span class="line">        - agno = 22</span><br><span class="line">        - agno = 23</span><br><span class="line">        - agno = 24</span><br><span class="line">        - agno = 25</span><br><span class="line">        - agno = 26</span><br><span class="line">        - agno = 8</span><br><span class="line">        - agno = 9</span><br><span class="line">        - agno = 10</span><br><span class="line">        - agno = 11</span><br><span class="line">        - agno = 12</span><br><span class="line">        - agno = 27</span><br><span class="line">        - agno = 28</span><br><span class="line">        - agno = 29</span><br><span class="line">        - agno = 13</span><br><span class="line">        - agno = 14</span><br><span class="line">        - 15:23:42: process known inodes and inode discovery - 3584 of 3584 inodes <span class="keyword">done</span></span><br><span class="line">        - process newly discovered inodes...</span><br><span class="line">        - 15:23:42: process newly discovered inodes - 32 of 32 allocation groups <span class="keyword">done</span></span><br><span class="line">Phase 4 - check <span class="keyword">for</span> duplicate blocks...</span><br><span class="line">        - setting up duplicate extent list...</span><br><span class="line">        - 15:23:42: setting up duplicate extent list - 32 of 32 allocation groups <span class="keyword">done</span></span><br><span class="line">        - check <span class="keyword">for</span> inodes claiming duplicate blocks...</span><br><span class="line">        - agno = 0</span><br><span class="line">        - agno = 1</span><br><span class="line">        - agno = 2</span><br><span class="line">        - agno = 3</span><br><span class="line">        - agno = 4</span><br><span class="line">        - agno = 5</span><br><span class="line">        - agno = 7</span><br><span class="line">        - agno = 6</span><br><span class="line">        - agno = 8</span><br><span class="line">        - agno = 11</span><br><span class="line">        - agno = 15</span><br><span class="line">        - agno = 19</span><br><span class="line">        - agno = 22</span><br><span class="line">        - agno = 24</span><br><span class="line">        - agno = 14</span><br><span class="line">        - agno = 28</span><br><span class="line">        - agno = 16</span><br><span class="line">        - agno = 18</span><br><span class="line">        - agno = 31</span><br><span class="line">        - agno = 20</span><br><span class="line">        - agno = 9</span><br><span class="line">        - agno = 10</span><br><span class="line">        - agno = 21</span><br><span class="line">        - agno = 23</span><br><span class="line">        - agno = 12</span><br><span class="line">        - agno = 13</span><br><span class="line">        - agno = 25</span><br><span class="line">        - agno = 26</span><br><span class="line">        - agno = 27</span><br><span class="line">        - agno = 17</span><br><span class="line">        - agno = 30</span><br><span class="line">        - agno = 29</span><br><span class="line">        - 15:23:42: check <span class="keyword">for</span> inodes claiming duplicate blocks - 3584 of 3584 inodes <span class="keyword">done</span></span><br><span class="line">Phase 5 - rebuild AG headers and trees...</span><br><span class="line">        - 15:23:42: rebuild AG headers and trees - 32 of 32 allocation groups <span class="keyword">done</span></span><br><span class="line">        - reset superblock...</span><br><span class="line">Phase 6 - check inode connectivity...</span><br><span class="line">        - resetting contents of realtime bitmap and summary inodes</span><br><span class="line">        - traversing filesystem ...</span><br><span class="line">        - traversal finished ...</span><br><span class="line">        - moving disconnected inodes to lost+found ...</span><br><span class="line">Phase 7 - verify and correct link counts...</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p> 这时mount，start ceph-osd damon后，ceph报<code>HEALTH_OK</code>，但其实osd上的部分数据已经丢失，这个等ceph的deep scrub触发后会自动修复；</p>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://ceph.com/planet/ceph-manually-repair-object/" target="_blank" rel="noopener">http://ceph.com/planet/ceph-manually-repair-object/</a><br><a href="https://linux.cn/article-7961-1.html" target="_blank" rel="noopener">https://linux.cn/article-7961-1.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/25/Ceph-BackoffThrottle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/25/Ceph-BackoffThrottle/" itemprop="url"> Ceph BackoffThrottle分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-25T10:31:17+08:00">
                2017-05-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/25/Ceph-BackoffThrottle/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/25/Ceph-BackoffThrottle/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文讨论下Ceph在Jewel中引入的 dynamic throttle：BackoffThrottle；分析后优化Ceph filestore，journal相关的throttle配置；</p>
<p><strong>参考文章：</strong></p>
<p><a href="http://blog.wjin.org/posts/ceph-dynamic-throttle.html" target="_blank" rel="noopener">http://blog.wjin.org/posts/ceph-dynamic-throttle.html</a><br><a href="https://fossies.org/linux/ceph/src/doc/dynamic-throttle.txt" target="_blank" rel="noopener">https://fossies.org/linux/ceph/src/doc/dynamic-throttle.txt</a></p>
<h2 id="BackoffThrottle"><a href="#BackoffThrottle" class="headerlink" title="BackoffThrottle"></a>BackoffThrottle</h2><p>Jewel引入了dynamic的throttle，就是代码中BackoffThrottle，现在filestore和Journal都是使用它来做throttle的；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FileStore</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    BackoffThrottle throttle_ops, throttle_bytes;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JournalThrottle</span> &#123;</span></span><br><span class="line">    BackoffThrottle throttle;</span><br><span class="line">…</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>BackoffThrottle定义和相关参数如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * BackoffThrottle</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Creates a throttle which gradually induces delays when get() is called</span></span><br><span class="line"><span class="comment"> * based on params low_threshhold, high_threshhold, expected_throughput,</span></span><br><span class="line"><span class="comment"> * high_multiple, and max_multiple.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * In [0, low_threshhold), we want no delay.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * In [low_threshhold, high_threshhold), delays should be injected based</span></span><br><span class="line"><span class="comment"> * on a line from 0 at low_threshhold to</span></span><br><span class="line"><span class="comment"> * high_multiple * (1/expected_throughput) at high_threshhold.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * In [high_threshhold, 1), we want delays injected based on a line from</span></span><br><span class="line"><span class="comment"> * (high_multiple * (1/expected_throughput)) at high_threshhold to</span></span><br><span class="line"><span class="comment"> * (high_multiple * (1/expected_throughput)) +</span></span><br><span class="line"><span class="comment"> * (max_multiple * (1/expected_throughput)) at 1.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Let the current throttle ratio (current/max) be r, low_threshhold be l,</span></span><br><span class="line"><span class="comment"> * high_threshhold be h, high_delay (high_multiple / expected_throughput) be e,</span></span><br><span class="line"><span class="comment"> * and max_delay (max_muliple / expected_throughput) be m.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * delay = 0, r \in [0, l)</span></span><br><span class="line"><span class="comment"> * delay = (r - l) * (e / (h - l)), r \in [l, h)</span></span><br><span class="line"><span class="comment"> * delay = h + (r - h)((m - e)/(1 - h))</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BackoffThrottle</span> &#123;</span></span><br><span class="line">…</span><br><span class="line">    <span class="comment">/// see above, values are in [0, 1].</span></span><br><span class="line">    <span class="keyword">double</span> low_threshhold = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> high_threshhold = <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/// see above, values are in seconds</span></span><br><span class="line">    <span class="keyword">double</span> high_delay_per_count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> max_delay_per_count = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/// Filled in in set_params</span></span><br><span class="line">    <span class="keyword">double</span> s0 = <span class="number">0</span>; <span class="comment">///&lt; e / (h - l), l != h, 0 otherwise</span></span><br><span class="line">    <span class="keyword">double</span> s1 = <span class="number">0</span>; <span class="comment">///&lt; (m - e)/(1 - h), 1 != h, 0 otherwise</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/// max</span></span><br><span class="line">    <span class="keyword">uint64_t</span> max = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">uint64_t</span> current = <span class="number">0</span>;</span><br><span class="line">…</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="filestore-throttle举例分析"><a href="#filestore-throttle举例分析" class="headerlink" title="filestore throttle举例分析"></a>filestore throttle举例分析</h2><p>下面以使用BackoffThrottle的filestore throttle举例分析下其参数配置</p>
<h3 id="filestore-throttle的相关配置项"><a href="#filestore-throttle的相关配置项" class="headerlink" title="filestore throttle的相关配置项"></a>filestore throttle的相关配置项</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">OPTION(filestore_expected_throughput_bytes, OPT_DOUBLE, <span class="number">200</span> &lt;&lt; <span class="number">20</span>)</span><br><span class="line">OPTION(filestore_expected_throughput_ops, OPT_DOUBLE, <span class="number">200</span>)</span><br><span class="line">  </span><br><span class="line">OPTION(filestore_queue_max_bytes, OPT_U64, <span class="number">100</span> &lt;&lt; <span class="number">20</span>)</span><br><span class="line">OPTION(filestore_queue_max_ops, OPT_U64, <span class="number">50</span>)</span><br><span class="line">  </span><br><span class="line">OPTION(filestore_queue_max_delay_multiple, OPT_DOUBLE, <span class="number">0</span>)</span><br><span class="line">OPTION(filestore_queue_high_delay_multiple, OPT_DOUBLE, <span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line">OPTION(filestore_queue_low_threshhold, OPT_DOUBLE, <span class="number">0.3</span>)</span><br><span class="line">OPTION(filestore_queue_high_threshhold, OPT_DOUBLE, <span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<h3 id="根据配置项初始化BackoffThrottle"><a href="#根据配置项初始化BackoffThrottle" class="headerlink" title="根据配置项初始化BackoffThrottle"></a>根据配置项初始化BackoffThrottle</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> BackoffThrottle::set_params(</span><br><span class="line">    <span class="keyword">double</span> _low_threshhold,</span><br><span class="line">    <span class="keyword">double</span> _high_threshhold,</span><br><span class="line">    <span class="keyword">double</span> _expected_throughput,</span><br><span class="line">    <span class="keyword">double</span> _high_multiple,</span><br><span class="line">    <span class="keyword">double</span> _max_multiple,</span><br><span class="line">    <span class="keyword">uint64_t</span> _throttle_max,</span><br><span class="line">    ostream *errstream)</span><br><span class="line">&#123;</span><br><span class="line">    low_threshhold = _low_threshhold;</span><br><span class="line">    high_threshhold = _high_threshhold;</span><br><span class="line">    high_delay_per_count = _high_multiple / _expected_throughput;</span><br><span class="line">    max_delay_per_count = _max_multiple / _expected_throughput;</span><br><span class="line">    max = _throttle_max;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (high_threshhold - low_threshhold &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        s0 = high_delay_per_count / (high_threshhold - low_threshhold);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        low_threshhold = high_threshhold;</span><br><span class="line">        s0 = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (<span class="number">1</span> - high_threshhold &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        s1 = (max_delay_per_count - high_delay_per_count)</span><br><span class="line">             / (<span class="number">1</span> - high_threshhold);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        high_threshhold = <span class="number">1</span>;</span><br><span class="line">        s1 = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">int</span> FileStore::set_throttle_params()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">stringstream</span> ss;</span><br><span class="line">    <span class="keyword">bool</span> valid = throttle_bytes.set_params(</span><br><span class="line">                     g_conf-&gt;filestore_queue_low_threshhold,</span><br><span class="line">                     g_conf-&gt;filestore_queue_high_threshhold,</span><br><span class="line">                     g_conf-&gt;filestore_expected_throughput_bytes,</span><br><span class="line">                     g_conf-&gt;filestore_queue_high_delay_multiple,</span><br><span class="line">                     g_conf-&gt;filestore_queue_max_delay_multiple,</span><br><span class="line">                     g_conf-&gt;filestore_queue_max_bytes,</span><br><span class="line">                     &amp;ss);</span><br><span class="line"> </span><br><span class="line">    valid &amp;= throttle_ops.set_params(</span><br><span class="line">                 g_conf-&gt;filestore_queue_low_threshhold,</span><br><span class="line">                 g_conf-&gt;filestore_queue_high_threshhold,</span><br><span class="line">                 g_conf-&gt;filestore_expected_throughput_ops,</span><br><span class="line">                 g_conf-&gt;filestore_queue_high_delay_multiple,</span><br><span class="line">                 g_conf-&gt;filestore_queue_max_delay_multiple,</span><br><span class="line">                 g_conf-&gt;filestore_queue_max_ops,</span><br><span class="line">                 &amp;ss);</span><br><span class="line">…</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="获取delay值"><a href="#获取delay值" class="headerlink" title="获取delay值"></a>获取delay值</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::chrono::duration&lt;<span class="keyword">double</span>&gt; BackoffThrottle::_get_delay(<span class="keyword">uint64_t</span> c) <span class="keyword">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (max == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">std</span>::chrono::duration&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">double</span> r = ((<span class="keyword">double</span>)current) / ((<span class="keyword">double</span>)max);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; low_threshhold) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">std</span>::chrono::duration&lt;<span class="keyword">double</span>&gt;(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (r &lt; high_threshhold) &#123;</span><br><span class="line">        <span class="keyword">return</span> c * <span class="built_in">std</span>::chrono::duration&lt;<span class="keyword">double</span>&gt;(</span><br><span class="line">                   (r - low_threshhold) * s0);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> c * <span class="built_in">std</span>::chrono::duration&lt;<span class="keyword">double</span>&gt;(</span><br><span class="line">                   high_delay_per_count + ((r - high_threshhold) * s1));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如上述函数描述，分四种情况计算delay值：</p>
<ol>
<li>max = 0时：永远返回 0</li>
<li>current/max &lt; low_threshhold时：返回 0</li>
<li>low_threshhold &lt;= current/max &lt; high_threshhold时：计算一值</li>
<li>high_threshhold &lt;= current/max时：计算一值</li>
</ol>
<p><img src="/images/ceph-backoffthrottle.jpg" alt="backofthrottle"></p>
<p>如图所示，在第一个区间的时候，也就是压力不大的情况下，delay值为0，是不需要wait的。当压力增大，x落入第二个区间后，delay值开始起作用，并且逐步增大， 当压力过大的时候，会落入第三个区间，这时候delay值增加明显加快，wait值明显增大，尽量减慢io速度，减缓压力，故而得名dynamic throttle。</p>
<h3 id="默认情况下filestore-throttle分析"><a href="#默认情况下filestore-throttle分析" class="headerlink" title="默认情况下filestore throttle分析"></a>默认情况下filestore throttle分析</h3><p>filestore有bytes和ops两个throttle，这里以bytes为例分析：</p>
<p>默认情况下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filestore_queue_high_delay_multiple = 0</span><br><span class="line">filestore_queue_max_delay_multiple = 0</span><br></pre></td></tr></table></figure>
<p>相当于BackoffThrottle中的值如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">low_threshhold = 0.3</span><br><span class="line">high_threshhold = 0.9</span><br><span class="line">high_delay_per_count = 0</span><br><span class="line">max_delay_per_count = 0</span><br><span class="line">s0 = 0</span><br><span class="line">s1 = 0</span><br><span class="line">max = 100 &lt;&lt; 20</span><br></pre></td></tr></table></figure>
<p>所以默认配置下，是关闭dynamic delay的；</p>
<h3 id="开启dynamic-throttle"><a href="#开启dynamic-throttle" class="headerlink" title="开启dynamic throttle"></a>开启dynamic throttle</h3><p>参考最早的代码，配置：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filestore_queue_high_delay_multiple = 2</span><br><span class="line">filestore_queue_max_delay_multiple = 10</span><br></pre></td></tr></table></figure>
<p>其他使用默认值是，BackoffThrottle中的值如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">low_threshhold = 0.3</span><br><span class="line">high_threshhold = 0.9</span><br><span class="line">high_delay_per_count = 2/(200 &lt;&lt; 20)</span><br><span class="line">max_delay_per_count = 10/(200 &lt;&lt; 20)</span><br><span class="line">s0 = (2/(200 &lt;&lt; 20))/0.6</span><br><span class="line">s1 = (8/(200 &lt;&lt; 20))/0.1</span><br><span class="line">max = 100 &lt;&lt; 20</span><br></pre></td></tr></table></figure>
<p>则此时的delay分为如下几种：</p>
<p><strong>c：op-&gt;bytes，即一次请求的数据量</strong><br><strong>current：当前filestore queue的数据量，初始化为 0，每次调用：throttle_bytes.get(o-&gt;bytes)；{ current + = c;}</strong></p>
<ol>
<li><p>current/max &lt; low_threshhold时：<br> 此时 current &lt; (30 &lt;&lt; 20)；delay = 0</p>
</li>
<li><p>low_threshhold &lt;= current/max &lt; high_threshhold时：<br> 此时 (30 &lt;&lt; 20) &lt;= current &lt; (90 &lt;&lt; 20)<br> delay = c <em> ((current/max - 0.3) </em> s0)<br> a）current = 30 &lt;&lt; 20时：delay = 0<br> b）current = 90 &lt;&lt; 20时：delay = c / (100 &lt;&lt; 20)</p>
</li>
<li><p>high_threshhold &lt;= current/max时:<br> 此时 (90 &lt;&lt; 20) &lt; current<br> delay = c <em> (2/(200 &lt;&lt; 20) + (current/max - 0.9) </em> s1)<br> a）current = 90 &lt;&lt; 20时：delay = c / (100 &lt;&lt; 20)<br> b）current = 100 &lt;&lt; 20时：delay = 5 * c / (100 &lt;&lt; 20)</p>
</li>
</ol>
<h3 id="当前配置下的dynamic-throttle"><a href="#当前配置下的dynamic-throttle" class="headerlink" title="当前配置下的dynamic throttle"></a>当前配置下的dynamic throttle</h3><p>配置如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filestore_expected_throughput_bytes =  536870912    // 512M</span><br><span class="line">filestore_queue_max_bytes= 1048576000               // 1000M</span><br><span class="line">filestore_queue_low_threshhold = 0.6</span><br><span class="line">filestore_queue_high_threshhold = 0.9   // 默认值</span><br><span class="line">filestore_queue_high_delay_multiple = 2</span><br><span class="line">filestore_queue_max_delay_multiple = 10</span><br></pre></td></tr></table></figure>
<p>BackoffThrottle中的值如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">low_threshhold = 0.6</span><br><span class="line">high_threshhold = 0.9</span><br><span class="line">high_delay_per_count = 2/(512 &lt;&lt; 20)</span><br><span class="line">max_delay_per_count = 10/(512 &lt;&lt; 20)</span><br><span class="line">s0 = (2/(512 &lt;&lt; 20))/0.3</span><br><span class="line">s1 = (8/(512 &lt;&lt; 20))/0.1</span><br><span class="line">max = 1000 &lt;&lt; 20</span><br></pre></td></tr></table></figure>
<p>则此时的delay分为如下几种：</p>
<ol>
<li><p>current/max &lt; low_threshhold时：此时 current &lt; (600 &lt;&lt; 20)；delay = 0</p>
</li>
<li><p>low_threshhold &lt;= current/max &lt; high_threshhold时：<br> 此时 (600 &lt;&lt; 20) &lt;= current &lt; (900 &lt;&lt; 20)<br> delay = c <em> ((current/max - 0.6) </em> s0)<br> a）current = 600 &lt;&lt; 20时：delay = 0<br> b）current = 900 &lt;&lt; 20时：delay = c / (256 &lt;&lt; 20)</p>
</li>
<li><p>high_threshhold &lt;= current/max时:<br> 此时 (900 &lt;&lt; 20) &lt; current<br> delay = c <em> (2/(512 &lt;&lt; 20) + (current/max - 0.9) </em> s1)<br> a）current = 900 &lt;&lt; 20时：delay = c / (256 &lt;&lt; 20)<br> b）current = 1000 &lt;&lt; 20时：delay = 5 * c / (256 &lt;&lt; 20)</p>
</li>
</ol>
<p><strong>结论：这里的参数配置不是很合理；600M之前的delay都是0；后续随着current的增大，delay的值小于默认时候的值，可能会加大filestore的压力；</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/24/Ceph-PGLock-RWState/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/24/Ceph-PGLock-RWState/" itemprop="url">Ceph PG Lock and RWState</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-24T18:31:17+08:00">
                2017-05-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/24/Ceph-PGLock-RWState/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/24/Ceph-PGLock-RWState/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在RWG的压力测试中，经常看到op的如下信息：”event”: “waiting for rw locks”</p>
<p>并且在RWG的压力很大时，这个waiting event会出现很多次，导致op的latency很高，所以需要分析下为什么会有这个waiting for rw locks的event？它与PG Lock的关系？</p>
<h2 id="PG-Lock"><a href="#PG-Lock" class="headerlink" title="PG Lock"></a>PG Lock</h2><p>从 Ceph OSD op_shardedwq 中分析知道：</p>
<ol>
<li>OSD的<code>osd_op_tp</code>在处理OPRequest的时候就会先获取PG Lock；</li>
<li>OSD的<code>osd_op_tp</code>在调用<code>OSD::dequeue_op()</code>返回后会释放PG Lock；</li>
</ol>
<p><code>OSD::dequeue_op</code>的调用过程如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">OSD::dequeue_op()</span><br><span class="line">    |-- ReplicatedPG::do_request()</span><br><span class="line">        |-- ReplicatedPG::do_op()   <span class="comment">//在op类型为CEPH_MSG_OSD_OP时</span></span><br><span class="line">            |-- ReplicatedPG::execute_ctx() <span class="comment">// 之前会会先获取RW Lock，失败后把op重新加入work queue</span></span><br><span class="line">                |-- ReplicatedPG::issue_repop() <span class="comment">// 写case，读的话在ReplicatedPG::prepare_transaction()里处理</span></span><br><span class="line">                    |-- ReplicatedBackend::submit_transaction()</span><br><span class="line">                        |-- ReplicatedBackend::issue_op()   <span class="comment">// 发送rep ops</span></span><br><span class="line">                            FileStore::queue_transactions() <span class="comment">// 有journal时把transaction放到journal的work queue里</span></span><br></pre></td></tr></table></figure>
<p>从上面的调用可以看出，OSD的<code>osd_op_tp</code>里的线程处理过程在获取PG Lock后，只会把op组装为transaction后交给FileStore的work queue，然后就返回释放PG Lock了；<br>返回后写的数据可能还没有写到journal和disk，即还没有commit/apply成功；<br>所以针对同一个object的操作，虽说对它的操作有PG Lock，但也可能在PG Lock释放后，对object的实际操作RW还没有完成；</p>
<p>这就引入了object的读写锁，即<code>struct ObjectContext</code>里的<code>struct RWState</code>，通过它来互斥对同一object的读写，但允许对同一object的同时多读、同时多写（详细见下面RWState的分析）；</p>
<p>对于同时多写，因为有PG Lock，所以多写并不会引起data consistency问题（PG Lock保证多写是顺序的），多个写提交到FileStore后可以并发或合并（<strong>待分析</strong>）；</p>
<h2 id="RWState"><a href="#RWState" class="headerlink" title="RWState"></a>RWState</h2><p><code>RWState</code>的定义</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectContext</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">RWState</span> &#123;</span></span><br><span class="line">        <span class="keyword">enum</span> State &#123;</span><br><span class="line">            RWNONE,     <span class="comment">// 初始状态，count = 0时设置</span></span><br><span class="line">            RWREAD,     <span class="comment">// read lock</span></span><br><span class="line">            RWWRITE,    <span class="comment">// write lock</span></span><br><span class="line">            RWEXCL,     <span class="comment">// exclusive lock</span></span><br><span class="line">        &#125;;</span><br><span class="line">...</span><br><span class="line">        <span class="built_in">list</span>&lt;OpRequestRef&gt; waiters;  <span class="comment">///&lt; ops waiting on state change</span></span><br><span class="line">        <span class="keyword">int</span> count;              <span class="comment">///&lt; number of readers or writers</span></span><br><span class="line">        State state:<span class="number">4</span>;               <span class="comment">///&lt; rw state</span></span><br><span class="line">        <span class="comment">/// if set, restart backfill when we can get a read lock</span></span><br><span class="line">        <span class="keyword">bool</span> recovery_read_marker:<span class="number">1</span>;</span><br><span class="line">        <span class="comment">/// if set, requeue snaptrim on lock release</span></span><br><span class="line">        <span class="keyword">bool</span> snaptrimmer_write_marker:<span class="number">1</span>;</span><br><span class="line">...</span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_read</span><span class="params">(OpRequestRef op)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (get_read_lock()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="comment">// else</span></span><br><span class="line">            waiters.push_back(op);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/// this function adjusts the counts if necessary</span></span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_read_lock</span><span class="params">()</span> </span>&#123;      <span class="comment">// 获取read lock</span></span><br><span class="line">            <span class="comment">// don't starve anybody!</span></span><br><span class="line">            <span class="keyword">if</span> (!waiters.empty()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">switch</span> (state) &#123;</span><br><span class="line">            <span class="keyword">case</span> RWNONE:</span><br><span class="line">                assert(count == <span class="number">0</span>);</span><br><span class="line">                state = RWREAD;</span><br><span class="line">            <span class="comment">// fall through</span></span><br><span class="line">            <span class="keyword">case</span> RWREAD:    <span class="comment">// 支持同时多读</span></span><br><span class="line">                count++;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">case</span> RWWRITE:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">case</span> RWEXCL:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                assert(<span class="number">0</span> == <span class="string">"unhandled case"</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">  </span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_write</span><span class="params">(OpRequestRef op, <span class="keyword">bool</span> greedy=<span class="literal">false</span>)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (get_write_lock(greedy)) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="comment">// else</span></span><br><span class="line">            <span class="keyword">if</span> (op)</span><br><span class="line">                waiters.push_back(op);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_write_lock</span><span class="params">(<span class="keyword">bool</span> greedy=<span class="literal">false</span>)</span> </span>&#123;    <span class="comment">// 获取write lock</span></span><br><span class="line">            <span class="keyword">if</span> (!greedy) &#123;</span><br><span class="line">                <span class="comment">// don't starve anybody!</span></span><br><span class="line">                <span class="keyword">if</span> (!waiters.empty() ||</span><br><span class="line">                        recovery_read_marker) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">switch</span> (state) &#123;</span><br><span class="line">            <span class="keyword">case</span> RWNONE:</span><br><span class="line">                assert(count == <span class="number">0</span>);</span><br><span class="line">                state = RWWRITE;</span><br><span class="line">            <span class="comment">// fall through</span></span><br><span class="line">            <span class="keyword">case</span> RWWRITE:   <span class="comment">// 支持同时多写</span></span><br><span class="line">                count++;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">case</span> RWREAD:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">case</span> RWEXCL:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                assert(<span class="number">0</span> == <span class="string">"unhandled case"</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_excl_lock</span><span class="params">()</span> </span>&#123;  <span class="comment">// 获取exclusive lock</span></span><br><span class="line">            <span class="keyword">switch</span> (state) &#123;</span><br><span class="line">            <span class="keyword">case</span> RWNONE:</span><br><span class="line">                assert(count == <span class="number">0</span>);</span><br><span class="line">                state = RWEXCL;</span><br><span class="line">                count = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">case</span> RWWRITE:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">case</span> RWREAD:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">case</span> RWEXCL:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                assert(<span class="number">0</span> == <span class="string">"unhandled case"</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">bool</span> <span class="title">get_excl</span><span class="params">(OpRequestRef op)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (get_excl_lock()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="comment">// else</span></span><br><span class="line">            <span class="keyword">if</span> (op)</span><br><span class="line">                waiters.push_back(op);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">...</span><br><span class="line">    &#125; rwstate;</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>从上面的定义中看出，RW lock支持同时多读、同时多写；<br>在<code>do_op</code>中，会根据op类型，尝试获取rw locks：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** do_op - do an op</span></span><br><span class="line"><span class="comment"> * pg lock will be held (if multithreaded)</span></span><br><span class="line"><span class="comment"> * osd_lock NOT held.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">void</span> ReplicatedPG::do_op(OpRequestRef&amp; op)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!get_rw_locks(write_ordered, ctx)) &#123;     <span class="comment">// 获取rw lock失败</span></span><br><span class="line">        dout(<span class="number">20</span>) &lt;&lt; __func__ &lt;&lt; <span class="string">" waiting for rw locks "</span> &lt;&lt; dendl;</span><br><span class="line">        op-&gt;mark_delayed(<span class="string">"waiting for rw locks"</span>);</span><br><span class="line">        close_op_ctx(ctx);  <span class="comment">// close op ctx，会把当前op重新加入queue中</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">-- get_rw_locks [ReplicatedPG]</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Grabs locks for OpContext, should be cleaned up in close_op_ctx</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * @param ctx [in,out] ctx to get locks for</span></span><br><span class="line"><span class="comment">     * @return true on success, false if we are queued</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">get_rw_locks</span><span class="params">(<span class="keyword">bool</span> write_ordered, OpContext *ctx)</span> </span>&#123;</span><br><span class="line">        <span class="comment">/* If snapset_obc, !obc-&gt;obs-&gt;exists and we will always take the</span></span><br><span class="line"><span class="comment">         * snapdir lock *before* the head lock.  Since all callers will do</span></span><br><span class="line"><span class="comment">         * this (read or write) if we get the first we will be guaranteed</span></span><br><span class="line"><span class="comment">         * to get the second.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (write_ordered &amp;&amp; ctx-&gt;op-&gt;may_read()) &#123;       <span class="comment">// 根据op的flag设置lock type</span></span><br><span class="line">            ctx-&gt;lock_type = ObjectContext::RWState::RWEXCL;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (write_ordered) &#123;</span><br><span class="line">            ctx-&gt;lock_type = ObjectContext::RWState::RWWRITE;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            assert(ctx-&gt;op-&gt;may_read());</span><br><span class="line">            ctx-&gt;lock_type = ObjectContext::RWState::RWREAD;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (ctx-&gt;snapset_obc) &#123;</span><br><span class="line">            assert(!ctx-&gt;obc-&gt;obs.exists);</span><br><span class="line">            <span class="keyword">if</span> (!ctx-&gt;lock_manager.get_lock_type(</span><br><span class="line">                        ctx-&gt;lock_type,</span><br><span class="line">                        ctx-&gt;snapset_obc-&gt;obs.oi.soid,</span><br><span class="line">                        ctx-&gt;snapset_obc,</span><br><span class="line">                        ctx-&gt;op)) &#123;</span><br><span class="line">                ctx-&gt;lock_type = ObjectContext::RWState::RWNONE;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (ctx-&gt;lock_manager.get_lock_type( <span class="comment">// 尝试获取lock</span></span><br><span class="line">                    ctx-&gt;lock_type,</span><br><span class="line">                    ctx-&gt;obc-&gt;obs.oi.soid,</span><br><span class="line">                    ctx-&gt;obc,</span><br><span class="line">                    ctx-&gt;op)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            assert(!ctx-&gt;snapset_obc);</span><br><span class="line">            ctx-&gt;lock_type = ObjectContext::RWState::RWNONE;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><code>close_op_ctx</code>的调用关系如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">osd/ReplicatedPG.h</span><br><span class="line">-- close_op_ctx [ReplicatedPG]</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Cleans up OpContext</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * @param ctx [in] ctx to clean up</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">close_op_ctx</span><span class="params">(OpContext *ctx)</span> </span>&#123;</span><br><span class="line">        release_object_locks(ctx-&gt;lock_manager);     <span class="comment">// 调用</span></span><br><span class="line">        ctx-&gt;<span class="keyword">op_t</span>.reset();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> p = ctx-&gt;on_finish.begin();</span><br><span class="line">                p != ctx-&gt;on_finish.end();</span><br><span class="line">                ctx-&gt;on_finish.erase(p++)) &#123;</span><br><span class="line">            (*p)();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">delete</span> ctx;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">-- release_object_locks [ReplicatedPG]</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Releases locks</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * @param manager [in] manager with locks to release</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">release_object_locks</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        ObcLockManager &amp;lock_manager)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">list</span>&lt;pair&lt;<span class="keyword">hobject_t</span>, <span class="built_in">list</span>&lt;OpRequestRef&gt; &gt; &gt; to_req;</span><br><span class="line">        <span class="keyword">bool</span> requeue_recovery = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">bool</span> requeue_snaptrim = <span class="literal">false</span>;</span><br><span class="line">        lock_manager.put_locks(     <span class="comment">// 调用获取to_req</span></span><br><span class="line">            &amp;to_req,</span><br><span class="line">            &amp;requeue_recovery,</span><br><span class="line">            &amp;requeue_snaptrim);</span><br><span class="line">        <span class="keyword">if</span> (requeue_recovery)</span><br><span class="line">            osd-&gt;recovery_wq.<span class="built_in">queue</span>(<span class="keyword">this</span>);</span><br><span class="line">        <span class="keyword">if</span> (requeue_snaptrim)</span><br><span class="line">            queue_snap_trim();</span><br><span class="line">        <span class="keyword">if</span> (!to_req.empty()) &#123;  <span class="comment">// to_req不为空</span></span><br><span class="line">            <span class="comment">// requeue at front of scrub blocking queue if we are blocked by scrub</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;&amp;p: to_req) &#123;</span><br><span class="line">                <span class="keyword">if</span> (scrubber.write_blocked_by_scrub(</span><br><span class="line">                            p.first.get_head(),</span><br><span class="line">                            get_sort_bitwise())) &#123;</span><br><span class="line">                    waiting_for_active.splice(</span><br><span class="line">                        waiting_for_active.begin(),</span><br><span class="line">                        p.second,</span><br><span class="line">                        p.second.begin(),</span><br><span class="line">                        p.second.end());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    requeue_ops(p.second);  <span class="comment">// 把request重新加入队列</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">osd/osd_types.h</span><br><span class="line">--  put_locks [ObcLockManager]</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put_locks</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="built_in">list</span>&lt;pair&lt;<span class="keyword">hobject_t</span>, <span class="built_in">list</span>&lt;OpRequestRef&gt; &gt; &gt; *to_requeue,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">bool</span> *requeue_recovery,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">bool</span> *requeue_snaptrimmer)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> p: locks) &#123;</span><br><span class="line">            <span class="built_in">list</span>&lt;OpRequestRef&gt; _to_requeue;</span><br><span class="line">            p.second.obc-&gt;put_lock_type(</span><br><span class="line">                p.second.type,</span><br><span class="line">                &amp;_to_requeue,</span><br><span class="line">                requeue_recovery,</span><br><span class="line">                requeue_snaptrimmer);</span><br><span class="line">            <span class="keyword">if</span> (to_requeue) &#123;</span><br><span class="line">                to_requeue-&gt;push_back(</span><br><span class="line">                    make_pair(</span><br><span class="line">                        p.second.obc-&gt;obs.oi.soid,</span><br><span class="line">                        <span class="built_in">std</span>::move(_to_requeue)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        locks.clear();</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">-- put_lock_type [ObjectContext]</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put_lock_type</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        ObjectContext::RWState::State type,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="built_in">list</span>&lt;OpRequestRef&gt; *to_wake,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">bool</span> *requeue_recovery,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">bool</span> *requeue_snaptrimmer)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">        <span class="keyword">case</span> ObjectContext::RWState::RWWRITE:</span><br><span class="line">            <span class="keyword">return</span> put_write(to_wake, requeue_recovery, requeue_snaptrimmer);</span><br><span class="line">        <span class="keyword">case</span> ObjectContext::RWState::RWREAD:</span><br><span class="line">            <span class="keyword">return</span> put_read(to_wake);</span><br><span class="line">        <span class="keyword">case</span> ObjectContext::RWState::RWEXCL:</span><br><span class="line">            <span class="keyword">return</span> put_excl(to_wake, requeue_recovery, requeue_snaptrimmer);</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            assert(<span class="number">0</span> == <span class="string">"invalid lock type"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>系统调用<code>close_op_ctx()</code>函数的地方有：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>    <span class="number">166</span>  osd/ReplicatedPG.cc &lt;&lt;finish&gt;&gt;</span><br><span class="line">           ctx-&gt;pg-&gt;close_op_ctx(ctx);</span><br><span class="line"> <span class="number">2</span>   <span class="number">2099</span>  osd/ReplicatedPG.cc &lt;&lt;do_op&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">3</span>   <span class="number">2105</span>  osd/ReplicatedPG.cc &lt;&lt;do_op&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">4</span>   <span class="number">2134</span>  osd/ReplicatedPG.cc &lt;&lt;do_op&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">5</span>   <span class="number">2970</span>  osd/ReplicatedPG.cc &lt;&lt;execute_ctx&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">6</span>   <span class="number">3112</span>  osd/ReplicatedPG.cc &lt;&lt;reply_ctx&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">7</span>   <span class="number">3119</span>  osd/ReplicatedPG.cc &lt;&lt;reply_ctx&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"> <span class="number">8</span>   <span class="number">3422</span>  osd/ReplicatedPG.cc &lt;&lt;trim_object&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx.release());</span><br><span class="line"> <span class="number">9</span>   <span class="number">3430</span>  osd/ReplicatedPG.cc &lt;&lt;trim_object&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx.release());</span><br><span class="line"><span class="number">10</span>   <span class="number">6888</span>  osd/ReplicatedPG.cc &lt;&lt;complete_read_ctx&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx);</span><br><span class="line"><span class="number">11</span>   <span class="number">8174</span>  osd/ReplicatedPG.cc &lt;&lt;try_flush_mark_clean&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx.release());</span><br><span class="line"><span class="number">12</span>   <span class="number">8180</span>  osd/ReplicatedPG.cc &lt;&lt;try_flush_mark_clean&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx.release());</span><br><span class="line"><span class="number">13</span>  <span class="number">10153</span>  osd/ReplicatedPG.cc &lt;&lt;on_change&gt;&gt;</span><br><span class="line">           close_op_ctx(i-&gt;second);</span><br><span class="line"><span class="number">14</span>  <span class="number">12183</span>  osd/ReplicatedPG.cc &lt;&lt;agent_maybe_evict&gt;&gt;</span><br><span class="line">           close_op_ctx(ctx.release());</span><br></pre></td></tr></table></figure>
<p>所以分析得出在op无论是出错、锁竞争、操作完成的情况下，都会调用<code>close_op_ctx()</code>，它会把等待在object的RWState锁上的op重新入队处理；</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/23/Ceph-osd_enable_op_tracker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/23/Ceph-osd_enable_op_tracker/" itemprop="url">Ceph osd_enable_op_tracker配置分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-23T11:31:17+08:00">
                2017-05-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/23/Ceph-osd_enable_op_tracker/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/23/Ceph-osd_enable_op_tracker/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文分析Ceph OpTracker相关实现，提供<code>osd_enable_op_tracker</code>的配置分析，并做相关测试对比性能；</p>
<h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><h3 id="op-tracker定义"><a href="#op-tracker定义" class="headerlink" title="op_tracker定义"></a>op_tracker定义</h3><p><code>osd_enable_op_tracker</code>对应的配置是osd中的<code>op_tracker</code>，每个osd会初始化一个<code>op_tracker</code>，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">## op_tracker的定义</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OSD</span> :</span> <span class="keyword">public</span> Dispatcher, <span class="keyword">public</span> <span class="keyword">md_config_obs_t</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">// -- op tracking --</span></span><br><span class="line">    OpTracker op_tracker;</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br><span class="line">  </span><br><span class="line">## op_tracker的初始化</span><br><span class="line">OSD::OSD(...) :</span><br><span class="line">...</span><br><span class="line">    op_tracker(cct, cct-&gt;_conf-&gt;osd_enable_op_tracker,  <span class="comment">// 是否enable op tracker</span></span><br><span class="line">               cct-&gt;_conf-&gt;osd_num_op_tracker_shard),   <span class="comment">// op tracker shard数，每个shard一个mutex锁，多个shard可以避免op更新的性能瓶颈问题</span></span><br><span class="line">...</span><br><span class="line">&#123;</span><br><span class="line">    monc-&gt;set_messenger(client_messenger);</span><br><span class="line">    op_tracker.set_complaint_and_threshold(cct-&gt;_conf-&gt;osd_op_complaint_time, <span class="comment">// op complaint time配置，超出后有warning log</span></span><br><span class="line">                                           cct-&gt;_conf-&gt;osd_op_log_threshold); <span class="comment">// op log的阈值</span></span><br><span class="line">    op_tracker.set_history_size_and_duration(cct-&gt;_conf-&gt;osd_op_history_size, <span class="comment">// op history的最大size</span></span><br><span class="line">                                             cct-&gt;_conf-&gt;osd_op_history_duration); <span class="comment">// op history的最长保留时间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>OpTracker</code>的定义如下，里面维护了一个sharded list，会把op映射到对应的list上，每个shard有一个mutex锁，保证这里的track操作不会成为性能瓶颈；</p>
<p>每个list的单位是<code>TrackedOp</code></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpTracker</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ShardedTrackingData</span> &#123;</span></span><br><span class="line">        Mutex ops_in_flight_lock_sharded;</span><br><span class="line">        xlist&lt;TrackedOp *&gt; ops_in_flight_sharded;</span><br><span class="line">        explicit ShardedTrackingData(string lock_name):</span><br><span class="line">            ops_in_flight_lock_sharded(lock_name.c_str()) &#123;&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;ShardedTrackingData*&gt; sharded_in_flight_list;</span><br><span class="line">    <span class="keyword">uint32_t</span> num_optracker_shards;</span><br><span class="line">    OpHistory history;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="TrackedOp定义"><a href="#TrackedOp定义" class="headerlink" title="TrackedOp定义"></a>TrackedOp定义</h3><p><code>TrackedOp</code>是一个tracked的operation，它会指向所属的<code>OpTracker</code>，定义如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrackedOp</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">OpHistory</span>;</span></span><br><span class="line">    <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">OpTracker</span>;</span></span><br><span class="line">    xlist&lt;TrackedOp*&gt;::item xitem;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    OpTracker *tracker; <span class="comment">/// the tracker we are associated with</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ceph osd中的每个op都是<code>TrackedOp</code>的子类；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OpRequest</span> :</span> <span class="keyword">public</span> TrackedOp &#123;</span><br><span class="line">    <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">OpTracker</span>;</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>OpRequest</code>会在osd dispatch的时候初始化，会根据是否enable op tracker初始化对应值：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">osd/OSD.cc &lt;&lt;ms_fast_dispatch&gt;&gt;</span><br><span class="line">    OpRequestRef op = op_tracker.create_request&lt;OpRequest, Message*&gt;(m);</span><br><span class="line"> osd/OSD.cc &lt;&lt;_dispatch&gt;&gt;</span><br><span class="line">    OpRequestRef op = op_tracker.create_request&lt;OpRequest, Message*&gt;(m);</span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpTracker</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line">    <span class="keyword">typename</span> T::<span class="function">Ref <span class="title">create_request</span><span class="params">(U params)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        typename T::Ref retval(new T(params, this),     // 初始化OpRequest类</span><br><span class="line">                               RemoveOnDelete(<span class="keyword">this</span>));</span><br><span class="line">        retval-&gt;tracking_start();    <span class="comment">// OpRequest放到OpTracker的shard list里，设置 is_tracked = true；后于OpReuest类的初始化</span></span><br><span class="line">        <span class="keyword">return</span> retval;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrackedOp</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">tracking_start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (tracker-&gt;register_inflight_op(&amp;xitem)) &#123;</span><br><span class="line">            events.push_back(make_pair(initiated_at, <span class="string">"initiated"</span>));</span><br><span class="line">            is_tracked = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">OpRequest::OpRequest(Message *req, OpTracker *tracker) :</span><br><span class="line">    TrackedOp(tracker, req-&gt;get_recv_stamp()),   <span class="comment">// TrackedOp的is_tracked默认为false</span></span><br><span class="line">    rmw_flags(<span class="number">0</span>), request(req),</span><br><span class="line">    hit_flag_points(<span class="number">0</span>), latest_flag_point(<span class="number">0</span>),</span><br><span class="line">    send_map_update(<span class="literal">false</span>), sent_epoch(<span class="number">0</span>),</span><br><span class="line">    hitset_inserted(<span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (req-&gt;get_priority() &lt; tracker-&gt;cct-&gt;_conf-&gt;osd_client_op_priority) &#123;</span><br><span class="line">        <span class="comment">// don't warn as quickly for low priority ops</span></span><br><span class="line">        warn_interval_multiplier = tracker-&gt;cct-&gt;_conf-&gt;osd_recovery_op_warn_multiple;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (req-&gt;get_type() == CEPH_MSG_OSD_OP) &#123;</span><br><span class="line">        reqid = <span class="keyword">static_cast</span>&lt;MOSDOp*&gt;(req)-&gt;get_reqid();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (req-&gt;get_type() == MSG_OSD_SUBOP) &#123;</span><br><span class="line">        reqid = <span class="keyword">static_cast</span>&lt;MOSDSubOp*&gt;(req)-&gt;reqid;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (req-&gt;get_type() == MSG_OSD_REPOP) &#123;</span><br><span class="line">        reqid = <span class="keyword">static_cast</span>&lt;MOSDRepOp*&gt;(req)-&gt;reqid;</span><br><span class="line">    &#125;</span><br><span class="line">    tracker-&gt;mark_event(<span class="keyword">this</span>, <span class="string">"header_read"</span>, request-&gt;get_recv_stamp());  <span class="comment">//??? 因为此时is_tracked为false，所以这些event log不会打印出来</span></span><br><span class="line">    tracker-&gt;mark_event(<span class="keyword">this</span>, <span class="string">"throttled"</span>, request-&gt;get_throttle_stamp());</span><br><span class="line">    tracker-&gt;mark_event(<span class="keyword">this</span>, <span class="string">"all_read"</span>, request-&gt;get_recv_complete_stamp());</span><br><span class="line">    tracker-&gt;mark_event(<span class="keyword">this</span>, <span class="string">"dispatched"</span>, request-&gt;get_dispatch_stamp());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="OpTracker记录op"><a href="#OpTracker记录op" class="headerlink" title="OpTracker记录op"></a>OpTracker记录op</h3><p>在创建一个op request的时候，就会把op分到<code>OpTracker</code>的不同shard list上</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> OpTracker::register_inflight_op(xlist&lt;TrackedOp*&gt;::item *i)</span><br><span class="line">&#123;</span><br><span class="line">    RWLock::<span class="function">RLocker <span class="title">l</span><span class="params">(lock)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (!tracking_enabled)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">uint64_t</span> current_seq = seq.inc();</span><br><span class="line">    <span class="keyword">uint32_t</span> shard_index = current_seq % num_optracker_shards;</span><br><span class="line">    ShardedTrackingData* sdata = sharded_in_flight_list[shard_index];</span><br><span class="line">    assert(<span class="literal">NULL</span> != sdata);</span><br><span class="line">    &#123;</span><br><span class="line">        Mutex::<span class="function">Locker <span class="title">locker</span><span class="params">(sdata-&gt;ops_in_flight_lock_sharded)</span></span>;</span><br><span class="line">        sdata-&gt;ops_in_flight_sharded.push_back(i);</span><br><span class="line">        sdata-&gt;ops_in_flight_sharded.back()-&gt;seq = current_seq;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之后可以通过<code>ceph daemon &lt;osd.id&gt; dump_ops_in_flight/dump_historic_ops</code>查看该osd上的op情况；</p>
<h3 id="TrackedOp-mark-event"><a href="#TrackedOp-mark-event" class="headerlink" title="TrackedOp mark event"></a>TrackedOp mark event</h3><p>当开启了op tracker，<code>TrackedOp</code>就会根据配置的debug等级把一些event打印到osd的log文件里，这个操作会影响系统性能；但也可以帮我们分析出一个op哪个阶段比较费时，找出系统瓶颈；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> TrackedOp::mark_event(<span class="keyword">const</span> <span class="built_in">string</span> &amp;event)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (!is_tracked)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">utime_t</span> now = ceph_clock_now(g_ceph_context);</span><br><span class="line">    &#123;</span><br><span class="line">        Mutex::<span class="function">Locker <span class="title">l</span><span class="params">(lock)</span></span>;</span><br><span class="line">        events.push_back(make_pair(now, event));    <span class="comment">// events记录一个op所有的event信息</span></span><br><span class="line">    &#125;</span><br><span class="line">    tracker-&gt;mark_event(<span class="keyword">this</span>, event);    <span class="comment">// mark event，打印log</span></span><br><span class="line">    _event_marked();    <span class="comment">// 可以自己实现event mark后的操作，现在为空</span></span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">void</span> OpTracker::mark_event(TrackedOp *op, <span class="keyword">const</span> <span class="built_in">string</span> &amp;dest, <span class="keyword">utime_t</span> time)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (!op-&gt;is_tracked)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">return</span> _mark_event(op, dest, time);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> OpTracker::_mark_event(TrackedOp *op, <span class="keyword">const</span> <span class="built_in">string</span> &amp;evt,</span><br><span class="line">                            <span class="keyword">utime_t</span> time)</span><br><span class="line">&#123;</span><br><span class="line">    dout(<span class="number">5</span>);</span><br><span class="line">    *_dout  &lt;&lt;  <span class="string">"seq: "</span> &lt;&lt; op-&gt;seq</span><br><span class="line">            &lt;&lt; <span class="string">", time: "</span> &lt;&lt; time &lt;&lt; <span class="string">", event: "</span> &lt;&lt; evt</span><br><span class="line">            &lt;&lt; <span class="string">", op: "</span>;</span><br><span class="line">    op-&gt;_dump_op_descriptor_unlocked(*_dout);</span><br><span class="line">    *_dout &lt;&lt; dendl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>基于之前搭建的RGW cosbench，对比测试了<code>osd_enable_op_tracker</code>为false/true的情况下的性能，结果如下：</p>
<p>测试参数：两个cosbench driver，写一个bucket 5,000,000个objects，workers=100，runtime=2000；</p>
<h3 id="debug-optracker-0-0-amp-osd-enable-op-tracker-false"><a href="#debug-optracker-0-0-amp-osd-enable-op-tracker-false" class="headerlink" title="debug_optracker = 0/0 &amp; osd_enable_op_tracker = false"></a><code>debug_optracker = 0/0</code> &amp; <code>osd_enable_op_tracker = false</code></h3><p>先写两个bucket的结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Op-Type</th>
<th>OOp-Count</th>
<th>OByte-Count</th>
<th>OAvg-ResTime</th>
<th>OAvg-ProcTime</th>
<th>OThroughput</th>
<th>OBandwidth</th>
<th>OSucc-Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>write</td>
<td>2.57 mops</td>
<td>82.15 GB</td>
<td>77.79 ms</td>
<td>77.64 ms</td>
<td>1284.26 op/s</td>
<td>41.1 MB/S</td>
<td>100%</td>
</tr>
<tr>
<td>2</td>
<td>write</td>
<td>1.32 mops</td>
<td>42.28 GB</td>
<td>151.05 ms</td>
<td>150.8 ms</td>
<td>661.69 op/s</td>
<td>21.17 MB/S</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>【第二次写入的性能较差，感觉应该是测试误差导致的，或者是当时有别的io影响，没再重复测试】</p>
<p>删除之前写的bucket的结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Op-Type</th>
<th>OOp-Count</th>
<th>OByte-Count</th>
<th>OAvg-ResTime</th>
<th>OAvg-ProcTime</th>
<th>OThroughput</th>
<th>OBandwidth</th>
<th>OSucc-Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>cleanup-delete</td>
<td>5 mops</td>
<td>0 B</td>
<td>8.03 ms</td>
<td>8.03 ms</td>
<td>12468.13 op/s</td>
<td>0 B/S</td>
<td>100%</td>
</tr>
<tr>
<td>2</td>
<td>cleanup-delete</td>
<td>5 mops</td>
<td>0 B</td>
<td>4.79 ms</td>
<td>4.79 ms</td>
<td>20898.72 op/s</td>
<td>0 B/S</td>
<td>100%</td>
</tr>
</tbody>
</table>
<h3 id="debug-optracker-0-0-amp-osd-enable-op-tracker-true"><a href="#debug-optracker-0-0-amp-osd-enable-op-tracker-true" class="headerlink" title="debug_optracker = 0/0 &amp; osd_enable_op_tracker = true"></a><code>debug_optracker = 0/0</code> &amp; <code>osd_enable_op_tracker = true</code></h3><p>先写两个bucket的结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Op-Type</th>
<th>OOp-Count</th>
<th>OByte-Count</th>
<th>OAvg-ResTime</th>
<th>OAvg-ProcTime</th>
<th>OThroughput</th>
<th>OBandwidth</th>
<th>OSucc-Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>write</td>
<td>2.67 mops</td>
<td>85.47 GB</td>
<td>74.79 ms</td>
<td>74.59 ms</td>
<td>1335.65 op/s</td>
<td>42.74 MB/S</td>
<td>100%</td>
</tr>
<tr>
<td>2</td>
<td>write</td>
<td>2.47 mops</td>
<td>79.02 GB</td>
<td>80.91 ms</td>
<td>80.76 ms</td>
<td>1234.71 op/s</td>
<td>39.51 MB/S</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>删除之前写的bucket的结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Op-Type</th>
<th>OOp-Count</th>
<th>OByte-Count</th>
<th>OAvg-ResTime</th>
<th>OAvg-ProcTime</th>
<th>OThroughput</th>
<th>OBandwidth</th>
<th>OSucc-Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>cleanup-delete</td>
<td>5 mops</td>
<td>0 B</td>
<td>10.3 ms</td>
<td>10.3 ms</td>
<td>9709.31 op/s</td>
<td>0 B/S</td>
<td>100%</td>
</tr>
<tr>
<td>2</td>
<td>cleanup-delete</td>
<td>5 mops</td>
<td>0 B</td>
<td>8.63 ms</td>
<td>8.63 ms</td>
<td>11581.92 op/s</td>
<td>0 B/S</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>【删除的相应时间比之前还是慢的比较多，不清晰是测试误差，还是别的原因】</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>从上述两项的对比可以看出，false/true的测试结果在误差范围内，印证了<code>osd_enable_op_tracker</code>设置为true对Ceph系统性能没什么影响；</p>
<h3 id="打开debug-optracker"><a href="#打开debug-optracker" class="headerlink" title="打开debug_optracker"></a>打开debug_optracker</h3><p>为了追踪op在osd中各个阶段的时间开销，我们可以打开<code>debug_optracker</code>，然后在osd的log中查到对应的event log；</p>
<p>打开关闭debug_optracker的方法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon &lt;osd-id&gt; config <span class="built_in">set</span> debug_optracker 5\/5  // 打开debug <span class="built_in">log</span></span><br><span class="line">ceph daemon &lt;osd-id&gt; config <span class="built_in">set</span> debug_optracker 0\/0  // 关闭debug <span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<p>之后可以在对应osd的log文件中看到如下log，以其中一个write op为例：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">2017-05-09 11:15:58.925362 7f556af0f700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925362, event: queued_for_pg, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 (undecoded) ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925388 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925388, event: reached_pg, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 (undecoded) ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925509 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925509, event: started, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925595 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925595, event: waiting <span class="keyword">for</span> subops from 29,76, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925735 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925735, event: commit_queued_for_journal_write, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925773 7f561cfec700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925772, event: write_thread_in_journal_buffer, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925947 7f561c7eb700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925946, event: journaled_completion_queued, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.925962 7f5614fff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.925961, event: op_commit, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.926400 7f55d3be3700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.926400, event: sub_op_commit_rec from 76, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.926440 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.926439, event: sub_op_commit_rec from 29, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.926456 7f55b27ff700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.926456, event: commit_sent, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.926793 7f5613ffd700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.926792, event: op_applied, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br><span class="line">2017-05-09 11:15:58.926825 7f5613ffd700  5 -- op tracker -- seq: 682036, time: 2017-05-09 11:15:58.926824, event: <span class="keyword">done</span>, op: osd_op(client.1027809.0:366525835 31.36c4e4e0 f31f020f-aaa2-4570-b6f7-19258064e5b5.1027809.13_myobjects449924 [create 0~0 [excl],setxattr user.rgw.idtag (55),writefull 0~32000,setxattr user.rgw.manifest (600),setxattr user.rgw.acl (145),setxattr user.rgw.content_type (25),setxattr user.rgw.etag (33),call rgw.obj_store_pg_ver,setxattr user.rgw.source_zone (4)] snapc 0=[] ondisk+write+known_if_redirected e2611)</span><br></pre></td></tr></table></figure>
<p>打开debug_optracker会有大量的osd log写入，严重影响osd的性能，所以这里只是建议在调试osd性能的时候偶尔打开收集下信息，然后分析osd的性能瓶颈；</p>
<h3 id="dump-historic-ops"><a href="#dump-historic-ops" class="headerlink" title="dump_historic_ops"></a><code>dump_historic_ops</code></h3><p>在不打开<code>debug_optracker</code>的情况下，也可以获取部分<code>OpRequest</code>的event信息，这就是通过<code>dump_historic_ops</code>获取；然后就可以分析op的各个时间段开销了；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph daemon osd.11 dump_historic_ops</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"num to keep"</span>: 20,</span><br><span class="line">    <span class="string">"duration to keep"</span>: 600,</span><br><span class="line">    <span class="string">"Ops"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"osd_op(client.1027809.0:458241652 17.e6e072e1 .dir.f31f020f-aaa2-4570-b6f7-19258064e5b5.859142.3.77 [] snapc 0=[] ack+ondisk+write+known_if_redirected e2850)"</span>,</span><br><span class="line">            <span class="string">"initiated_at"</span>: <span class="string">"2017-05-09 18:54:50.987435"</span>,</span><br><span class="line">            <span class="string">"age"</span>: 412.664363,</span><br><span class="line">            <span class="string">"duration"</span>: 0.338724,</span><br><span class="line">            <span class="string">"type_data"</span>: [</span><br><span class="line">                <span class="string">"commit sent; apply or cleanup"</span>,</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"client"</span>: <span class="string">"client.1027809"</span>,</span><br><span class="line">                    <span class="string">"tid"</span>: 458241652</span><br><span class="line">                &#125;,</span><br><span class="line">                [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:50.987435"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"initiated"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:50.987453"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"queued_for_pg"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:50.987483"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"reached_pg"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:50.987520"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"waiting for rw locks"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.052956"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"reached_pg"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.052986"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"waiting for rw locks"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.197523"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"reached_pg"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.197562"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"started"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.197812"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"waiting for subops from 33,43"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198068"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"commit_queued_for_journal_write"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198094"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"write_thread_in_journal_buffer"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198195"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"journaled_completion_queued"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198330"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"op_commit"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198454"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"sub_op_commit_rec from 43"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198851"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"sub_op_commit_rec from 33"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.198865"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"commit_sent"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.326034"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"op_applied"</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">"time"</span>: <span class="string">"2017-05-09 18:54:51.326158"</span>,</span><br><span class="line">                        <span class="string">"event"</span>: <span class="string">"done"</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/21/hexo-pagesgithub-build-website/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/21/hexo-pagesgithub-build-website/" itemprop="url">基于Hexo + pages github搭建个人blog站点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-21T19:31:17+08:00">
                2017-05-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index">
                    <span itemprop="name">tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/21/hexo-pagesgithub-build-website/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/21/hexo-pagesgithub-build-website/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前都是把工作学习中写的文章记录在Evernote上，方便自己搜索，然后在CSDN上开了个blog，会发一些整理过的文章；<br>后来感觉有必要自己搭建个技术blog，记录自己的总结，方便自己也有利于他人，就开始搜索如何方便快捷搭建一个blog；<br>首先搜索到的是<code>Jekyll + pages github</code>，学习了半天后发现，想找个喜欢的模板不容易，搭建也不是分分钟的事情，后来就搜索到了<code>Hexo + pages github</code>的方案，应用后发现很便捷，这里记录下来。</p>
<h2 id="创建github库"><a href="#创建github库" class="headerlink" title="创建github库"></a>创建github库</h2><p>github相信大多数朋友都用过，这里介绍的是github提供的pages功能，可以很方便的搭建个人的静态网站，特别适合简介的blog系统；并且默认提供的二级域名就可以访问；</p>
<p>在自己的github账号下创建如下命名的repository：<code>&lt;your-github-name&gt;.github.io</code>，一切选择默认即可；<br>其中<code>&lt;your-github-name&gt;</code>即是你登录github账号的名字；<br><strong>注意：别的名称的repository重命名为上述名称的repository不行</strong></p>
<h2 id="下载repository"><a href="#下载repository" class="headerlink" title="下载repository"></a>下载repository</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir YourGithubName.github.io</span><br><span class="line">$ <span class="built_in">cd</span> YourGithubName.github.io</span><br><span class="line">$ git <span class="built_in">clone</span> &lt;git@github.com:YourGithubName/YourGithubName.github.io.git&gt;</span><br></pre></td></tr></table></figure>
<p><strong>注：上述YourGithubName替换为你自己的github库名字</strong></p>
<p>为了能有权限上传代码到repository，你需要生成自己的ssh-key，并填写到github的配置里； </p>
<ol>
<li><p>首先本地生成ssh key</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen	// 一路回车，选择默认值即可</span><br><span class="line">$ cat ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新ssh key到github<br> 步骤为： <code>右上角头像 -&gt; Settings -&gt; SSH and GPG keys -&gt; New SSH key</code><br> 然后填写<code>Title，Key</code>即可；<br> Title 自己随便命名，Key 为上步骤中<code>cat ~/.ssh/id_rsa.pub</code>的值</p>
</li>
</ol>
<h2 id="Hexo初始化repository目录"><a href="#Hexo初始化repository目录" class="headerlink" title="Hexo初始化repository目录"></a>Hexo初始化repository目录</h2><p>上述我们clone下路的repository还是空目录一个，为了搭建网站，搜索我们需要的就是通过hexo命令来初始化该目录</p>
<p>首先安装hexo，请参考：<a href="https://hexo.io/zh-cn/docs/#安装" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/#安装</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br><span class="line">$ npm install hexo --save</span><br><span class="line">$ npm install hexo-deployer-git --save	// hexo deploy到git时需要</span><br></pre></td></tr></table></figure>
<p>初始化repository目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> YourGithubName.github.io</span><br><span class="line">$ hexo init .</span><br><span class="line">$ npm install</span><br><span class="line">$ ls</span><br><span class="line">_config.yml  node_modules package.json scaffolds    <span class="built_in">source</span>       themes</span><br></pre></td></tr></table></figure>
<p>这里我们主要关注的是：</p>
<ul>
<li>_config.yml 文件：整个hexo的配置文件</li>
<li>source 目录：所有网站相关页面的目录，后续写的markdown文件都应该放在source/_post/目录下</li>
<li>themes 目录：hexo模板的目录，里面每个子目录都是一个hexo的模板</li>
</ul>
<h2 id="网站测试"><a href="#网站测试" class="headerlink" title="网站测试"></a>网站测试</h2><p>初始化repository目录后，即可在本地测试下网站的功能步骤如下：</p>
<ol>
<li><p>启动hexo server</p>
 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>
</li>
<li><p>本地浏览器查看<br> 本地浏览器里输入: <code>http://localhost:4000/</code> 访问</p>
</li>
</ol>
<h2 id="Hexo模板"><a href="#Hexo模板" class="headerlink" title="Hexo模板"></a>Hexo模板</h2><p>Hexo包含了很多美观的模板，我们可以随便选择自己喜欢的Hexo模板来搭建网站<br>Hexo模板：<a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a><br>我选择的是Next模板：<a href="https://github.com/idhyt/hexo-theme-next" target="_blank" rel="noopener">https://github.com/idhyt/hexo-theme-next</a><br>还有一款简洁的模板：<a href="https://github.com/tufu9441/maupassant-hexo.git" target="_blank" rel="noopener">https://github.com/tufu9441/maupassant-hexo.git</a></p>
<p>选择好一个模板后，就可以把它下载到我们的repository里</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/idhyt/hexo-theme-next.git themes/next</span><br><span class="line">$ ls themes/next</span><br><span class="line">README.en.md README.md    _config.yml  bower.json   languages    layout       scripts      <span class="built_in">source</span>       <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>theme里有自己的<code>_config.yml</code>文件，里面是主题相关的配置参数，详情请参考具体模板的README.md</p>
<p>配置repository目录下的<code>_config.yml</code>文件，指定使用模板：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ vim _config.xml</span><br><span class="line">...</span><br><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line">theme: landscape</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">然后修改上面的theme为next即可</span><br><span class="line">theme : next</span><br></pre></td></tr></table></figure>
<p>启动<code>hexo server</code>，本地测试下外观 ;)</p>
<h2 id="更新blog"><a href="#更新blog" class="headerlink" title="更新blog"></a>更新blog</h2><p>网站和选用的模式都确定后，下一步就是更新我们自己的blog了，通过hexo也是异常简单</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new mypage</span><br><span class="line">INFO  Created: ~/YourGithubName.github.io/<span class="built_in">source</span>/_posts/mypage.md</span><br></pre></td></tr></table></figure>
<p>默认这里生产的<code>mypage.md</code>是没有日期格式的，这个可以在<code>_config.yml</code>里配置<code>new_post_name</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim _config.yml</span><br><span class="line">...</span><br><span class="line"><span class="comment"># Writing</span></span><br><span class="line">new_post_name: :year-:month-:day-:title.md <span class="comment"># File name of new posts</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>当然这里我们也可以自己在<code>source/_posts/</code>目录下创建markdown文件，填写自己的内容，为了支持分类和tag，建议markdown文件加入以下头部：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: <span class="string">"my first blog"</span></span><br><span class="line">date: 2016-08-11 17:31:17</span><br><span class="line">tags: [tag1, tag2]</span><br><span class="line">categories: life</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">blog正文</span><br></pre></td></tr></table></figure>
<p>若你在 source 目录下没有看到 tags, categories 等目录，可以通过如下命令创建:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new page tags</span><br><span class="line">$ hexo new page categories</span><br></pre></td></tr></table></figure>
<p>以上的目录需求跟你使用的模板息息相关，详情请仔细阅读hexo帮助文档和你选择模板的README.md。</p>
<h2 id="更新网站内容到github"><a href="#更新网站内容到github" class="headerlink" title="更新网站内容到github"></a>更新网站内容到github</h2><p>当本地网站测试满意后，我们就可以更新网站内容到pages github了</p>
<p>首先要配置<code>_config.yml</code>文件制定github repository</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim _config.yml</span><br><span class="line"><span class="comment"># 添加deploy配置</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: git@github.com:ictfox/ictfox.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<p>然后执行hexo命令部署</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo generate</span><br><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>我写了个脚本来做部署这个事情，免得每次忘记执行某一步</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cat deploy.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">hexo clean</span><br><span class="line"><span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"hexo clean Error!"</span></span><br><span class="line">    <span class="built_in">return</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">hexo generate</span><br><span class="line"><span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"hexo generate Error!"</span></span><br><span class="line">    <span class="built_in">return</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">hexo deploy</span><br><span class="line"><span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"hexo deploy Error!"</span></span><br><span class="line">    <span class="built_in">return</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>更新成功后，我们就可以通过浏览器访问github的二级域名查看网站了，默认为：<a href="YourGithubName.github.io">YourGithubName.github.io</a></p>
<h2 id="申请域名"><a href="#申请域名" class="headerlink" title="申请域名"></a>申请域名</h2><p>国内比较便捷的申请域名的服务是阿里和腾讯提供的</p>
<ul>
<li>阿里 <a href="https://wanwang.aliyun.com/domain/" target="_blank" rel="noopener">https://wanwang.aliyun.com/domain/</a></li>
<li>腾讯 <a href="https://dnspod.qcloud.com/" target="_blank" rel="noopener">https://dnspod.qcloud.com/</a></li>
</ul>
<p>他们都需要注册对应的账户，登录后即可查询自己喜欢的域名是否还没有注册，然后按照流程注册即可。<br>我对比发现腾讯的价格便宜，就选择了腾讯的服务。<br>申请后可以在账号里看到自己的域名信息。</p>
<h2 id="域名绑定"><a href="#域名绑定" class="headerlink" title="域名绑定"></a>域名绑定</h2><p>鉴于国内对cn域名的使用需要审核，这里依com域名为例，cn域名审核后的步骤一样；</p>
<h3 id="github添加CNAME文件"><a href="#github添加CNAME文件" class="headerlink" title="github添加CNAME文件"></a>github添加CNAME文件</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'www.yangguanjun.com'</span> &gt; <span class="built_in">source</span>/CNAME</span><br></pre></td></tr></table></figure>
<p>然后执行deploy.py脚本提交到github repository</p>
<h3 id="解析com域名"><a href="#解析com域名" class="headerlink" title="解析com域名"></a>解析com域名</h3><p>在域名提供商的console界面里，找到域名后面的<code>解析</code>按钮，在里面添加CNAME的解析记录<br><img src="/images/hexo-pagesgithub-build-website1.jpg" alt=""><br><img src="/images/hexo-pagesgithub-build-website2.jpg" alt=""></p>
<p>然后访问域名就可以了 ;)</p>
<h2 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h2><p>我选择的Next模板里，默认的 搜索 和 评论 功能是关闭的，而这两个还是挺有用的，自己可以配置打开</p>
<h3 id="搜索功能"><a href="#搜索功能" class="headerlink" title="搜索功能"></a>搜索功能</h3><p>Next主题里支持 tinysou 和 swiftype 两种搜索功能，我这里实践了 swiftype，感觉还是不错的</p>
<p>配置文件修改：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vim themes/next/_config.yml</span><br><span class="line">...</span><br><span class="line">swiftype_key: <span class="string">'your swiftype key'</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>swiftype官网：<a href="https://swiftype.com/" target="_blank" rel="noopener">https://swiftype.com/</a><br>参考文章：<a href="http://prozhuchen.com/2015/10/03/Hexo%E5%8D%9A%E5%AE%A2%E7%AC%AC%E5%9B%9B%E7%AB%99/" target="_blank" rel="noopener">http://prozhuchen.com/2015/10/03/Hexo%E5%8D%9A%E5%AE%A2%E7%AC%AC%E5%9B%9B%E7%AB%99/</a></p>
<h3 id="评论功能"><a href="#评论功能" class="headerlink" title="评论功能"></a>评论功能</h3><p>Next主题里支持 duoshuo 和 disqus 两种评论功能，duoshuo 马上就要关闭支持了，我就选择了国外的 disqus，但也有个问题，这个disqus是被墙的 ;(，不翻墙的用户是刷不出来的。。。</p>
<p>配置文件修改：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vim themes/next/_config.yml</span><br><span class="line">...</span><br><span class="line">disqus_shortname: ictfox</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>Disqus官网：<a href="https://disqus.com/" target="_blank" rel="noopener">https://disqus.com/</a><br>参考文章：<a href="http://www.lmnsyunhao.cn/2017/03/29/hexo-disqus-comments/" target="_blank" rel="noopener">http://www.lmnsyunhao.cn/2017/03/29/hexo-disqus-comments/</a></p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/</a><br><a href="http://www.jianshu.com/p/834d7cc0668d" target="_blank" rel="noopener">http://www.jianshu.com/p/834d7cc0668d</a><br><a href="https://wsgzao.github.io/post/hexo-guide/" target="_blank" rel="noopener">https://wsgzao.github.io/post/hexo-guide/</a><br><a href="https://linghucong.js.org/2016/04/15/2016-04-15-hexo-github-pages-blog/" target="_blank" rel="noopener">https://linghucong.js.org/2016/04/15/2016-04-15-hexo-github-pages-blog/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/15/Ceph-configuration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/15/Ceph-configuration/" itemprop="url">Ceph配置参数详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-15T19:31:17+08:00">
                2017-05-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/15/Ceph-configuration/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/15/Ceph-configuration/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Ceph的配置参数很多，从网上也能搜索到一大批的调优参数，但这些参数为什么这么设置？设置为这样是否合理？解释的并不多<br>本文从当前我们的ceph.conf文件入手，解释其中的每一项配置，做为以后参数调优和新人学习的依据；</p>
<h2 id="参数详解"><a href="#参数详解" class="headerlink" title="参数详解"></a>参数详解</h2><h3 id="1，一些固定配置参数"><a href="#1，一些固定配置参数" class="headerlink" title="1，一些固定配置参数"></a>1，一些固定配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fsid = 6d529c3d-5745-4fa5-be5f-3962a8e8687c</span><br><span class="line">mon_initial_members = mon1, mon2, mon3</span><br><span class="line">mon_host = 10.10.40.67,10.10.40.68,10.10.40.69</span><br></pre></td></tr></table></figure>
<p>以上通常是通过ceph-deploy生成的，都是ceph monitor相关的参数，不用修改；</p>
<h3 id="2，网络配置参数"><a href="#2，网络配置参数" class="headerlink" title="2，网络配置参数"></a>2，网络配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">public_network = 10.10.40.0/24    默认值 <span class="string">""</span></span><br><span class="line">cluster_network = 10.10.41.0/24  默认值 <span class="string">""</span></span><br></pre></td></tr></table></figure>
<p>public network：monitor与osd，client与monitor，client与osd通信的网络，最好配置为带宽较高的万兆网络；<br>cluster network：OSD之间通信的网络，一般配置为带宽较高的万兆网络；</p>
<p><strong>参考：</strong><br><a href="http://docs.ceph.com/docs/master/rados/configuration/network-config-ref/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/rados/configuration/network-config-ref/</a></p>
<h3 id="3，pool-size配置参数"><a href="#3，pool-size配置参数" class="headerlink" title="3，pool size配置参数"></a>3，pool size配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">osd_pool_default_size = 3       默认值 3</span><br><span class="line">osd_pool_default_min_size = 1  默认值 0 // 0 means no specific default; ceph will use size-size/2</span><br></pre></td></tr></table></figure>
<p>这两个是创建ceph pool的时候的默认size参数，一般配置为3和1，3副本能足够保证数据的可靠性；</p>
<h3 id="4，认证配置参数"><a href="#4，认证配置参数" class="headerlink" title="4，认证配置参数"></a>4，认证配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">auth_service_required = none    默认值 <span class="string">"cephx"</span></span><br><span class="line">auth_client_required = none     默认值 <span class="string">"cephx, none"</span></span><br><span class="line">auth_cluster_required = none   默认值 <span class="string">"cephx"</span></span><br></pre></td></tr></table></figure>
<p>以上是Ceph authentication的配置参数，默认值为开启ceph认证；<br>在内部使用的ceph集群中一般配置为none，即不使用认证，这样能适当加快ceph集群访问速度；</p>
<h3 id="5，osd-down-out配置参数"><a href="#5，osd-down-out配置参数" class="headerlink" title="5，osd down out配置参数"></a>5，osd down out配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mon_osd_down_out_interval = 864000  默认值 300 // seconds</span><br><span class="line">mon_osd_min_down_reporters = 2      默认值 2</span><br><span class="line">mon_osd_report_timeout = 900        默认值 900</span><br><span class="line">osd_heartbeat_interval = 15         默认值 6</span><br><span class="line">osd_heartbeat_grace = 60            默认值 20</span><br></pre></td></tr></table></figure>
<p><code>mon_osd_down_out_interval</code>：ceph标记一个osd为down and out的最大时间间隔<br><code>mon_osd_min_down_reporters</code>：mon标记一个osd为down的最小reporters个数（报告该osd为down的其他osd为一个reporter）<br><code>mon_osd_report_timeout</code>：mon标记一个osd为down的最长等待时间<br><code>osd_heartbeat_interval</code>：osd发送heartbeat给其他osd的间隔时间（同一PG之间的osd才会有heartbeat）<br><code>osd_heartbeat_grace</code>：osd报告其他osd为down的最大时间间隔，grace调大，也有副作用，如果某个osd异常退出，等待其他osd上报的时间必须为grace，在这段时间段内，这个osd负责的pg的io会hang住，所以尽量不要将grace调的太大。</p>
<p>基于实际情况合理配置上述参数，能减少或及时发现osd变为down（降低IO hang住的时间和概率），延长osd变为down and out的时间（防止网络抖动造成的数据recovery）；</p>
<p><strong>参考：</strong><br><a href="http://docs.ceph.com/docs/master/rados/configuration/mon-osd-interaction/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/rados/configuration/mon-osd-interaction/</a><br><a href="http://blog.wjin.org/posts/ceph-osd-heartbeat.html" target="_blank" rel="noopener">http://blog.wjin.org/posts/ceph-osd-heartbeat.html</a></p>
<h3 id="6，objecter配置参数"><a href="#6，objecter配置参数" class="headerlink" title="6，objecter配置参数"></a>6，objecter配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objecter_inflight_ops = 10240               默认值 1024</span><br><span class="line">objecter_inflight_op_bytes = 1048576000     默认值 100M</span><br></pre></td></tr></table></figure>
<p>osd client端objecter的throttle配置，它的配置会影响librbd，RGW端的性能；</p>
<p><strong>配置建议：</strong><br>调大这两个值</p>
<h3 id="7，ceph-rgw配置参数"><a href="#7，ceph-rgw配置参数" class="headerlink" title="7，ceph rgw配置参数"></a>7，ceph rgw配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rgw_frontends = <span class="string">"civetweb port=10080 num_threads=2000"</span>  默认值 <span class="string">"fastcgi, civetweb port=7480"</span></span><br><span class="line">rgw_thread_pool_size = 512                              默认值 100</span><br><span class="line">rgw_override_bucket_index_max_shards = 20               默认值 0</span><br><span class="line"> </span><br><span class="line">rgw_max_chunk_size = 1048576                            默认值 512 * 1024</span><br><span class="line">rgw_cache_lru_size = 1000000                            默认值 10000 // num of entries <span class="keyword">in</span> rgw cache</span><br><span class="line">rgw_bucket_default_quota_max_objects = 10000000         默认值 -1 // number of objects allowed</span><br><span class="line">  </span><br><span class="line">rgw_dns_name = object-storage.ffan.com                  默认值</span><br><span class="line">rgw_swift_url = http://object-storage.ffan.com          默认值</span><br></pre></td></tr></table></figure>
<p><code>rgw_frontends</code>：rgw的前端配置，一般配置为使用轻量级的civetweb；prot为访问rgw的端口，根据实际情况配置；num_threads为civetweb的线程数；<br><code>rgw_thread_pool_size</code>：rgw前端web的线程数，与rgw_frontends中的num_threads含义一致，但num_threads 优于<code>rgw_thread_pool_size</code>的配置，两个只需要配置一个即可；<br><code>rgw_override_bucket_index_max_shards</code>：rgw bucket index object的最大shards数，增大这个值能减少bucket index object的访问时间，但也会加大bucket的ls时间；<br><code>rgw_max_chunk_size</code>：rgw最大chunk size，针对大文件的对象存储场景可以把这个值调大；<br><code>rgw_cache_lru_size</code>：rgw的lru cache size，对于读较多的应用场景，调大这个值能加快rgw的响应速度；<br><code>rgw_bucket_default_quota_max_objects</code>：配合该参数限制一个bucket的最大objects个数；</p>
<p><strong>参考：</strong><br><a href="http://docs.ceph.com/docs/jewel/install/install-ceph-gateway/" target="_blank" rel="noopener">http://docs.ceph.com/docs/jewel/install/install-ceph-gateway/</a><br><a href="http://ceph-users.ceph.narkive.com/mdB90g7R/rgw-increase-the-first-chunk-size" target="_blank" rel="noopener">http://ceph-users.ceph.narkive.com/mdB90g7R/rgw-increase-the-first-chunk-size</a><br><a href="https://access.redhat.com/solutions/2122231" target="_blank" rel="noopener">https://access.redhat.com/solutions/2122231</a></p>
<h3 id="8，debug配置参数"><a href="#8，debug配置参数" class="headerlink" title="8，debug配置参数"></a>8，debug配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">debug_lockdep = 0/0</span><br><span class="line">debug_context = 0/0</span><br><span class="line">debug_crush = 0/0</span><br><span class="line">debug_buffer = 0/0</span><br><span class="line">debug_timer = 0/0</span><br><span class="line">debug_filer = 0/0</span><br><span class="line">debug_objecter = 0/0</span><br><span class="line">debug_rados = 0/0</span><br><span class="line">debug_rbd = 0/0</span><br><span class="line">debug_journaler = 0/0</span><br><span class="line">debug_objectcatcher = 0/0</span><br><span class="line">debug_client = 0/0</span><br><span class="line">debug_osd = 0/0</span><br><span class="line">debug_optracker = 0/0</span><br><span class="line">debug_objclass = 0/0</span><br><span class="line">debug_filestore = 0/0</span><br><span class="line">debug_journal = 0/0</span><br><span class="line">debug_ms = 0/0</span><br><span class="line">debug_mon = 0/0</span><br><span class="line">debug_monc = 0/0</span><br><span class="line">debug_tp = 0/0</span><br><span class="line">debug_auth = 0/0</span><br><span class="line">debug_finisher = 0/0</span><br><span class="line">debug_heartbeatmap = 0/0</span><br><span class="line">debug_perfcounter = 0/0</span><br><span class="line">debug_asok = 0/0</span><br><span class="line">debug_throttle = 0/0</span><br><span class="line">debug_paxos = 0/0</span><br><span class="line">debug_rgw = 0/0</span><br></pre></td></tr></table></figure>
<p>关闭了所有的debug信息，能一定程度加快ceph集群速度，但也会丢失一些关键log，出问题的时候不好分析；</p>
<p><strong>参考：</strong><br><a href="http://www.10tiao.com/html/362/201609/2654062487/1.html" target="_blank" rel="noopener">http://www.10tiao.com/html/362/201609/2654062487/1.html</a></p>
<h3 id="9，osd-op配置参数"><a href="#9，osd-op配置参数" class="headerlink" title="9，osd op配置参数"></a>9，osd op配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">osd_enable_op_tracker = <span class="literal">false</span>       默认值 <span class="literal">true</span></span><br><span class="line">osd_num_op_tracker_shard = 32       默认值 32</span><br><span class="line">osd_op_threads = 10                 默认值 2</span><br><span class="line">osd_disk_threads = 1                默认值 1</span><br><span class="line">osd_op_num_shards = 32                 默认值 5</span><br><span class="line">osd_op_num_threads_per_shard = 2    默认值 2</span><br></pre></td></tr></table></figure>
<p><code>osd_enable_op_tracker</code>：追踪osd op状态的配置参数，默认为true；不建议关闭，关闭后osd的 slow_request，ops_in_flight，historic_ops 无法正常统计；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ceph daemon /var/run/ceph/ceph-osd.0.asok dump_ops_in_flight</span></span><br><span class="line">op_tracker tracking is not enabled now, so no ops are tracked currently, even those get stuck.  Please <span class="built_in">enable</span> <span class="string">"osd_enable_op_tracker"</span>, and the tracker will start to track new ops received afterwards.</span><br><span class="line"><span class="comment"># ceph daemon /var/run/ceph/ceph-osd.0.asok dump_historic_ops</span></span><br><span class="line">op_tracker tracking is not enabled now, so no ops are tracked currently, even those get stuck.  Please <span class="built_in">enable</span> <span class="string">"osd_enable_op_tracker"</span>, and the tracker will start to track new ops received afterwards.</span><br></pre></td></tr></table></figure>
<p>打开op tracker后，若集群iops很高，<code>osd_num_op_tracker_shard</code>可以适当调大，因为每个shard都有个独立的mutex锁；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpTracker</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ShardedTrackingData</span> &#123;</span></span><br><span class="line">        Mutex ops_in_flight_lock_sharded;</span><br><span class="line">        xlist&lt;TrackedOp *&gt; ops_in_flight_sharded;</span><br><span class="line">        explicit ShardedTrackingData(string lock_name):</span><br><span class="line">            ops_in_flight_lock_sharded(lock_name.c_str()) &#123;&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;ShardedTrackingData*&gt; sharded_in_flight_list;</span><br><span class="line">    <span class="keyword">uint32_t</span> num_optracker_shards;</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>osd_op_threads</code>：对应的work queue有<code>peering_wq</code>（osd peering请求），<code>recovery_gen_wq</code>（PG recovery请求）；<br><code>osd_disk_threads</code>：对应的work queue为 <code>remove_wq</code>（PG remove请求）；<br><code>osd_op_num_shards</code>和<code>osd_op_num_threads_per_shard</code>：对应的thread pool为<code>osd_op_tp</code>，work queue为<code>op_shardedwq</code>；</p>
<p>处理的请求包括：</p>
<ol>
<li><code>OpRequestRef</code></li>
<li><code>PGSnapTrim</code></li>
<li><code>PGScrub</code></li>
</ol>
<p>调大<code>osd_op_num_shards</code>可以增大osd ops的处理线程数，增大并发性，提升OSD性能；</p>
<h3 id="10，osd-client-message配置参数"><a href="#10，osd-client-message配置参数" class="headerlink" title="10，osd client message配置参数"></a>10，osd client message配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">osd_client_message_size_cap = 1048576000    默认值 500*1024L*1024L     // client data allowed <span class="keyword">in</span>-memory (<span class="keyword">in</span> bytes)</span><br><span class="line">osd_client_message_cap = 10000              默认值 100     // num client messages allowed <span class="keyword">in</span>-memory</span><br></pre></td></tr></table></figure>
<p>这个是osd端收到client messages的capacity配置，配置大的话能提升osd的处理能力，但会占用较多的系统内存；</p>
<p><strong>配置建议：</strong><br>服务器内存足够大的时候，适当增大这两个值</p>
<h3 id="11，osd-scrub配置参数"><a href="#11，osd-scrub配置参数" class="headerlink" title="11，osd scrub配置参数"></a>11，osd scrub配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">osd_scrub_begin_hour = 2                默认值 0</span><br><span class="line">osd_scrub_end_hour = 6                   默认值 24</span><br><span class="line"> </span><br><span class="line">// The time <span class="keyword">in</span> seconds that scrubbing sleeps between two consecutive scrubs</span><br><span class="line">osd_scrub_sleep = 2                       默认值 0        // sleep between [deep]scrub ops</span><br><span class="line"> </span><br><span class="line">osd_scrub_load_threshold = 5            默认值 0.5</span><br><span class="line">  </span><br><span class="line">// chunky scrub配置的最小/最大objects数，以下是默认值</span><br><span class="line">osd_scrub_chunk_min = 5</span><br><span class="line">osd_scrub_chunk_max = 25</span><br></pre></td></tr></table></figure>
<p>Ceph osd scrub是保证ceph数据一致性的机制，scrub以PG为单位，但每次scrub回获取PG lock，所以它可能会影响PG正常的IO；</p>
<p>Ceph后来引入了chunky的scrub模式，每次scrub只会选取PG的一部分objects，完成后释放PG lock，并把下一次的PG scrub加入队列；这样能很好的减少PG scrub时候占用PG lock的时间，避免过多影响PG正常的IO；</p>
<p>同理，引入的<code>osd_scrub_sleep</code>参数会让线程在每次scrub前释放PG lock，然后睡眠一段时间，也能很好的减少scrub对PG正常IO的影响；</p>
<p><strong>配置建议：</strong></p>
<ul>
<li><code>osd_scrub_begin_hour</code>和<code>osd_scrub_end_hour</code>：OSD Scrub的开始结束时间，根据具体业务指定；</li>
<li><code>osd_scrub_sleep</code>：osd在每次执行scrub时的睡眠时间；有个bug跟这个配置有关，建议关闭； </li>
<li><code>osd_scrub_load_threshold</code>：osd开启scrub的系统load阈值，根据系统的load average值配置该参数；</li>
<li><code>osd_scrub_chunk_min</code>和<code>osd_scrub_chunk_max</code>：根据PG中object的个数配置；针对RGW全是小文件的情况，这两个值需要调大；</li>
</ul>
<p><strong>参考：</strong><br><a href="http://www.jianshu.com/p/ea2296e1555c" target="_blank" rel="noopener">http://www.jianshu.com/p/ea2296e1555c</a><br><a href="http://tracker.ceph.com/issues/19497" target="_blank" rel="noopener">http://tracker.ceph.com/issues/19497</a></p>
<h3 id="12，osd-thread-timeout配置参数"><a href="#12，osd-thread-timeout配置参数" class="headerlink" title="12，osd thread timeout配置参数"></a>12，osd thread timeout配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">osd_op_thread_timeout = 580               默认值 15</span><br><span class="line">osd_op_thread_suicide_timeout = 600         默认值 150</span><br><span class="line"> </span><br><span class="line">osd_recovery_thread_timeout = 580           默认值 30</span><br><span class="line">osd_recovery_thread_suicide_timeout = 600   默认值 300</span><br></pre></td></tr></table></figure>
<p><code>osd_op_thread_timeout</code>和<code>osd_op_thread_suicide_timeout</code>关联的work queue为：</p>
<ul>
<li><code>op_shardedwq</code> - 关联的请求为：<code>OpRequestRef</code>，<code>PGSnapTrim</code>，<code>PGScrub</code></li>
<li><code>peering_wq</code> - 关联的请求为：osd peering</li>
</ul>
<p><code>osd_recovery_thread_timeout</code>和<code>osd_recovery_thread_suicide_timeout</code>关联的work queue为：</p>
<ul>
<li><code>recovery_wq</code> - 关联的请求为：PG recovery</li>
</ul>
<p>Ceph的work queue都有个基类<code>WorkQueue_</code>，定义如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Pool of threads that share work submitted to multiple work queues.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreadPool</span> :</span> <span class="keyword">public</span> <span class="keyword">md_config_obs_t</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">/// Basic interface to a work queue used by the worker threads.</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">WorkQueue_</span> &#123;</span></span><br><span class="line">        <span class="built_in">string</span> name;</span><br><span class="line">        <span class="keyword">time_t</span> timeout_interval, suicide_interval;</span><br><span class="line">        WorkQueue_(<span class="built_in">string</span> n, <span class="keyword">time_t</span> ti, <span class="keyword">time_t</span> sti)</span><br><span class="line">            : name(n), timeout_interval(ti), suicide_interval(sti)</span><br><span class="line">        &#123; &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这里的<code>timeout_interval</code>和<code>suicide_interval</code>分别对应上面所述的配置<code>timeout</code>和<code>suicide_timeout</code>；<br>当thread处理work queue中的一个请求时，会受到这两个timeout时间的限制：</p>
<ul>
<li><code>timeout_interval</code> - 到时间后设置<code>m_unhealthy_workers+1</code></li>
<li><code>suicide_interval</code> - 到时间后调用assert，OSD进程crush</li>
</ul>
<p>对应的处理函数为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> HeartbeatMap::_check(<span class="keyword">const</span> heartbeat_handle_d *h, <span class="keyword">const</span> <span class="keyword">char</span> *who, <span class="keyword">time_t</span> now)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">bool</span> healthy = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">time_t</span> was;</span><br><span class="line">    was = h-&gt;timeout.read();</span><br><span class="line">    <span class="keyword">if</span> (was &amp;&amp; was &lt; now) &#123;</span><br><span class="line">        ldout(m_cct, <span class="number">1</span>) &lt;&lt; who &lt;&lt; <span class="string">" '"</span> &lt;&lt; h-&gt;name &lt;&lt; <span class="string">"'"</span></span><br><span class="line">                        &lt;&lt; <span class="string">" had timed out after "</span> &lt;&lt; h-&gt;grace &lt;&lt; dendl;</span><br><span class="line">        healthy = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    was = h-&gt;suicide_timeout.read();</span><br><span class="line">    <span class="keyword">if</span> (was &amp;&amp; was &lt; now) &#123;</span><br><span class="line">        ldout(m_cct, <span class="number">1</span>) &lt;&lt; who &lt;&lt; <span class="string">" '"</span> &lt;&lt; h-&gt;name &lt;&lt; <span class="string">"'"</span></span><br><span class="line">                        &lt;&lt; <span class="string">" had suicide timed out after "</span> &lt;&lt; h-&gt;suicide_grace &lt;&lt; dendl;</span><br><span class="line">        assert(<span class="number">0</span> == <span class="string">"hit suicide timeout"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> healthy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当前仅有RGW添加了worker的perfcounter，所以也只有RGW可以通过perf dump查看total/unhealthy的worker信息：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ yangguanjun]<span class="comment"># ceph daemon /var/run/ceph/ceph-client.rgw.rgwdaemon.asok perf dump | grep worker</span></span><br><span class="line">        <span class="string">"total_workers"</span>: 32,</span><br><span class="line">        <span class="string">"unhealthy_workers"</span>: 0</span><br></pre></td></tr></table></figure>
<p>对应的配置项为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">OPTION(rgw_num_async_rados_threads, OPT_INT, 32) // num of threads to use <span class="keyword">for</span> async rados operations</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">**配置建议：**</span><br><span class="line"></span><br><span class="line">- `*_thread_timeout`：这个值配置越小越能及时发现处理慢的请求，所以不建议配置很大；特别是针对速度快的设备，建议调小该值；</span><br><span class="line">- `*_thread_suicide_timeout`：这个值配置小了会导致超时后的OSD crush，所以建议调大；特别是在对应的throttle调大后，更应该调大该值；</span><br><span class="line"></span><br><span class="line"><span class="comment">### 13，fielstore op thread配置参数</span></span><br><span class="line">```sh</span><br><span class="line">filestore_op_threads = 10                   默认值 2</span><br><span class="line">filestore_op_thread_timeout = 580           默认值 60</span><br><span class="line">filestore_op_thread_suicide_timeout = 600   默认值 180</span><br></pre></td></tr></table></figure>
<p><code>filestore_op_threads</code>：对应的thread pool为<code>op_tp</code>，对应的work queue为<code>op_wq</code>；filestore的所有请求都经过op_wq处理；<br>增大该参数能提升filestore的处理能力，提升filestore的性能；配合filestore的throttle一起调整； </p>
<p><code>filestore_op_thread_timeout</code>和<code>filestore_op_thread_suicide_timeout</code>关联的work queue为：<code>op_wq</code></p>
<p>配置的含义与上一节中的<code>thread_timeout/thread_suicide_timeout</code>保持一致；</p>
<h3 id="13，filestore-merge-split配置参数"><a href="#13，filestore-merge-split配置参数" class="headerlink" title="13，filestore merge/split配置参数"></a>13，filestore merge/split配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filestore_merge_threshold = -1       默认值 10</span><br><span class="line">filestore_split_multiple = 16000      默认值 2</span><br></pre></td></tr></table></figure>
<p>这两个参数是管理filestore的目录分裂/合并的，filestore的每个目录允许的最大文件数为：<br><code>filestore_split_multiple * abs(filestore_merge_threshold) * 16</code></p>
<p>在RGW的小文件应用场景，会很容易达到默认配置的文件数（320），若在写的过程中触发了filestore的分裂，则会非常影响filestore的性能；</p>
<p>每次filestore的目录分裂，会依据如下规则分裂为多层目录，最底层16个子目录：<br>例如PG 31.4C0,   hash结尾是4C0，若该目录分裂，会分裂为 <code>DIR_0/DIR_C/DIR_4/{DIR_0, DIR_F}</code>；</p>
<p>原始目录下的object会根据规则放到不同的子目录里，object的名称格式为: <code>*__head_xxxxX4C0_*</code>，分裂时候X是几，就放进子目录DIR_X里。比如object：<code>*__head_xxxxA4C0_*</code>,  就放进子目录 <code>DIR_0/DIR_C/DIR_4/DIR_A</code> 里；</p>
<p><strong>解决办法：</strong></p>
<ol>
<li>增大merge/split配置参数的值，使单个目录容纳更多的文件；</li>
<li><code>filestore_merge_threshold</code>配置为负数；这样会提前触发目录的预分裂，避免目录在某一时间段的集中分裂，详细机制没有调研；</li>
<li>创建pool时指定<code>expected-num-objects</code>；这样会依据目录分裂规则，在创建pool的时候就创建分裂的子目录，避免了目录分裂对filestore性能的影响；</li>
</ol>
<p><strong>参考：</strong><br><a href="http://docs.ceph.com/docs/master/rados/configuration/filestore-config-ref/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/rados/configuration/filestore-config-ref/</a><br><a href="http://docs.ceph.com/docs/jewel/rados/operations/pools/#create-a-pool" target="_blank" rel="noopener">http://docs.ceph.com/docs/jewel/rados/operations/pools/#create-a-pool</a><br><a href="http://blog.csdn.net/for_tech/article/details/51251936" target="_blank" rel="noopener">http://blog.csdn.net/for_tech/article/details/51251936</a><br><a href="http://ivanjobs.github.io/page3/" target="_blank" rel="noopener">http://ivanjobs.github.io/page3/</a></p>
<h3 id="14，filestore-fd-cache配置参数"><a href="#14，filestore-fd-cache配置参数" class="headerlink" title="14，filestore fd cache配置参数"></a>14，filestore fd cache配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filestore_fd_cache_shards =  32     默认值 16     // FD number of shards</span><br><span class="line">filestore_fd_cache_size = 32768     默认值 128  // FD lru size</span><br></pre></td></tr></table></figure>
<p>filestore的fd cache是加速访问filestore里的file的，在非一次性写入的应用场景，增大配置可以很明显的提升filestore的性能；</p>
<h3 id="15，filestore-sync配置参数"><a href="#15，filestore-sync配置参数" class="headerlink" title="15，filestore sync配置参数"></a>15，filestore sync配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">filestore_wbthrottle_enable = <span class="literal">false</span>    默认值 <span class="literal">true</span>        SSD的时候建议关闭</span><br><span class="line">filestore_min_sync_interval = 5           默认值 0.01 s     最小同步间隔秒数，sync fs的数据到disk，FileStore::sync_entry()</span><br><span class="line">filestore_max_sync_interval = 10         默认值 5 s       最大同步间隔秒数，sync fs的数据到disk，FileStore::sync_entry()</span><br><span class="line">filestore_commit_timeout = 3000         默认值 600 s       FileStore::sync_entry() 里 new SyncEntryTimeout(m_filestore_commit_timeout)</span><br></pre></td></tr></table></figure>
<p><code>filestore_wbthrottle_enable</code>的配置是关于filestore writeback throttle的，即我们说的filestore处理workqueue <code>op_wq</code>的数据量阈值；默认值是true，开启后XFS相关的配置参数有：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OPTION(filestore_wbthrottle_xfs_bytes_start_flusher, OPT_U64, <span class="number">41943040</span>)</span><br><span class="line">OPTION(filestore_wbthrottle_xfs_bytes_hard_limit, OPT_U64, <span class="number">419430400</span>)</span><br><span class="line">OPTION(filestore_wbthrottle_xfs_ios_start_flusher, OPT_U64, <span class="number">500</span>)</span><br><span class="line">OPTION(filestore_wbthrottle_xfs_ios_hard_limit, OPT_U64, <span class="number">5000</span>)</span><br><span class="line">OPTION(filestore_wbthrottle_xfs_inodes_start_flusher, OPT_U64, <span class="number">500</span>)</span><br><span class="line">OPTION(filestore_wbthrottle_xfs_inodes_hard_limit, OPT_U64, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>若使用普通HDD，可以保持其为true；针对SSD，建议将其关闭，不开启writeback throttle；</p>
<p><code>filestore_min_sync_interval</code>和<code>filestore_max_sync_interval</code>是配置filestore flush outstanding IO到disk的时间间隔的；增大配置可以让系统做尽可能多的IO merge，减少filestore写磁盘的压力，但也会增大page cache占用内存的开销，增大数据丢失的可能性；</p>
<p><code>filestore_commit_timeout</code>是配置filestore sync entry到disk的超时时间，在filestore压力很大时，调大这个值能尽量避免IO超时导致OSD crush；</p>
<h3 id="16，filestore-throttle配置参数"><a href="#16，filestore-throttle配置参数" class="headerlink" title="16，filestore throttle配置参数"></a>16，filestore throttle配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">filestore_expected_throughput_bytes =  536870912       默认值 200MB    /// Expected filestore throughput <span class="keyword">in</span> B/s</span><br><span class="line">filestore_expected_throughput_ops = 2500                默认值 200      /// Expected filestore throughput <span class="keyword">in</span> ops/s</span><br><span class="line">filestore_queue_max_bytes= 1048576000                   默认值 100MB</span><br><span class="line">filestore_queue_max_ops = 5000                          默认值 50</span><br><span class="line"> </span><br><span class="line">/// Use above to inject delays intended to keep the op queue between low and high</span><br><span class="line">filestore_queue_low_threshhold = 0.6                    默认值 0.3</span><br><span class="line">filestore_queue_high_threshhold = 0.9                   默认值 0.9</span><br><span class="line"> </span><br><span class="line">filestore_queue_high_delay_multiple = 2                    默认值 0    /// Filestore high delay multiple.  Defaults to 0 (disabled)</span><br><span class="line">filestore_queue_max_delay_multiple = 10                 默认值 0    /// Filestore max delay multiple.  Defaults to 0 (disabled)</span><br></pre></td></tr></table></figure>
<p>在jewel版本里，引入了dynamic throttle，来平滑普通throttle带来的长尾效应问题；</p>
<p>一般在使用普通磁盘时，之前的throttle机制即可很好的工作，所以这里默认<code>filestore_queue_high_delay_multiple</code>和<code>filestore_queue_max_delay_multiple</code>都为0；</p>
<p>针对高速磁盘，需要在部署之前，通过小工具<code>ceph_smalliobenchfs</code>来测试下，获取合适的配置参数；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">BackoffThrottle的介绍如下：</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* BackoffThrottle</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* Creates a throttle which gradually induces delays when get() is called</span></span><br><span class="line"><span class="comment">* based on params low_threshhold, high_threshhold, expected_throughput,</span></span><br><span class="line"><span class="comment">* high_multiple, and max_multiple.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* In [0, low_threshhold), we want no delay.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* In [low_threshhold, high_threshhold), delays should be injected based</span></span><br><span class="line"><span class="comment">* on a line from 0 at low_threshhold to</span></span><br><span class="line"><span class="comment">* high_multiple * (1/expected_throughput) at high_threshhold.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* In [high_threshhold, 1), we want delays injected based on a line from</span></span><br><span class="line"><span class="comment">* (high_multiple * (1/expected_throughput)) at high_threshhold to</span></span><br><span class="line"><span class="comment">* (high_multiple * (1/expected_throughput)) +</span></span><br><span class="line"><span class="comment">* (max_multiple * (1/expected_throughput)) at 1.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* Let the current throttle ratio (current/max) be r, low_threshhold be l,</span></span><br><span class="line"><span class="comment">* high_threshhold be h, high_delay (high_multiple / expected_throughput) be e,</span></span><br><span class="line"><span class="comment">* and max_delay (max_muliple / expected_throughput) be m.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* delay = 0, r \in [0, l)</span></span><br><span class="line"><span class="comment">* delay = (r - l) * (e / (h - l)), r \in [l, h)</span></span><br><span class="line"><span class="comment">* delay = h + (r - h)((m - e)/(1 - h))</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p><strong>参考：</strong><br><a href="http://docs.ceph.com/docs/jewel/dev/osd_internals/osd_throttles/" target="_blank" rel="noopener">http://docs.ceph.com/docs/jewel/dev/osd_internals/osd_throttles/</a><br><a href="http://blog.wjin.org/posts/ceph-dynamic-throttle.html" target="_blank" rel="noopener">http://blog.wjin.org/posts/ceph-dynamic-throttle.html</a><br><a href="https://github.com/ceph/ceph/blob/master/src/doc/dynamic-throttle.txt" target="_blank" rel="noopener">https://github.com/ceph/ceph/blob/master/src/doc/dynamic-throttle.txt</a><br><a href="Ceph-BackoffThrottle.md">Ceph BackoffThrottle分析</a></p>
<h3 id="17，filestore-finisher-threads配置参数"><a href="#17，filestore-finisher-threads配置参数" class="headerlink" title="17，filestore finisher threads配置参数"></a>17，filestore finisher threads配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filestore_ondisk_finisher_threads = 2   默认值 1</span><br><span class="line">filestore_apply_finisher_threads = 2   默认值 1</span><br></pre></td></tr></table></figure>
<p>这两个参数定义filestore commit/apply的finisher处理线程数，默认都为1，任何IO commit/apply完成后，都需要经过对应的ondisk/apply finisher thread处理；</p>
<p>在使用普通HDD时，磁盘性能是瓶颈，单个finisher thread就能处理好；<br>但在使用高速磁盘的时候，IO完成比较快，单个finisher thread不能处理这么多的IO commit/apply reply，它会成为瓶颈；所以在jewel版本里引入了finisher thread pool的配置，这里一般配置为2即可；</p>
<h3 id="18，journal配置参数"><a href="#18，journal配置参数" class="headerlink" title="18，journal配置参数"></a>18，journal配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">journal_max_write_bytes=1048576000          默认值 10M    </span><br><span class="line">journal_max_write_entries=5000                默认值 100</span><br><span class="line"> </span><br><span class="line">journal_throttle_high_multiple = 2          默认值 0    /// Multiple over expected at high_threshhold. Defaults to 0 (disabled).</span><br><span class="line">journal_throttle_max_multiple = 10          默认值 0    /// Multiple over expected at max.  Defaults to 0 (disabled).</span><br><span class="line"></span><br><span class="line">/// Target range <span class="keyword">for</span> journal fullness</span><br><span class="line">OPTION(journal_throttle_low_threshhold, OPT_DOUBLE, 0.6)</span><br><span class="line">OPTION(journal_throttle_high_threshhold, OPT_DOUBLE, 0.9)</span><br></pre></td></tr></table></figure>
<p><code>journal_max_write_bytes</code>和<code>journal_max_write_entries</code>是journal一次write的数据量和entries限制；<br>针对SSD分区做journal的情况，这两个值要增大，这样能增大journal的吞吐量；</p>
<p><code>journal_throttle_high_multiple</code>和<code>journal_throttle_max_multiple</code>是<code>JournalThrottle</code>的配置参数，<code>JournalThrottle</code>是<code>BackoffThrottle</code>的封装类，所以<code>JournalThrottle</code>与我们在filestore throttle介绍的dynamic throttle工作原理一样；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> FileJournal::set_throttle_params()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">stringstream</span> ss;</span><br><span class="line">    <span class="keyword">bool</span> valid = throttle.set_params(</span><br><span class="line">                     g_conf-&gt;journal_throttle_low_threshhold,</span><br><span class="line">                     g_conf-&gt;journal_throttle_high_threshhold,</span><br><span class="line">                     g_conf-&gt;filestore_expected_throughput_bytes,</span><br><span class="line">                     g_conf-&gt;journal_throttle_high_multiple,</span><br><span class="line">                     g_conf-&gt;journal_throttle_max_multiple,</span><br><span class="line">                     header.max_size - get_top(),</span><br><span class="line">                     &amp;ss);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上述代码中看出相关的配置参数有：</p>
<ul>
<li><code>journal_throttle_low_threshhold</code></li>
<li><code>journal_throttle_high_threshhold</code></li>
<li><code>filestore_expected_throughput_bytes</code></li>
</ul>
<h3 id="19，rbd-cache配置参数"><a href="#19，rbd-cache配置参数" class="headerlink" title="19，rbd cache配置参数"></a>19，rbd cache配置参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">rbd_cache_size = 134217728                  默认值 32M // cache size <span class="keyword">in</span> bytes</span><br><span class="line">rbd_cache_max_dirty = 100663296             默认值 24M // dirty <span class="built_in">limit</span> <span class="keyword">in</span> bytes - <span class="built_in">set</span> to 0 <span class="keyword">for</span> write-through caching</span><br><span class="line">rbd_cache_target_dirty = 67108864           默认值 16M // target dirty <span class="built_in">limit</span> <span class="keyword">in</span> bytes</span><br><span class="line">rbd_cache_writethrough_until_flush = <span class="literal">true</span>   默认值 <span class="literal">true</span>    // whether to make writeback caching writethrough until flush is called, to be sure the user of librbd will send flushs so that writeback is safe</span><br><span class="line">rbd_cache_max_dirty_age = 5                 默认值 1.0     // seconds <span class="keyword">in</span> cache before writeback starts</span><br></pre></td></tr></table></figure>
<p><code>rbd_cache_size</code>：client端每个rbd image的cache size，不需要太大，可以调整为64M，不然会比较占client端内存；<br>参照默认值，根据<code>rbd_cache_size</code>的大小调整<code>rbd_cache_max_dirty</code>和<code>rbd_cache_target_dirty</code>；</p>
<ul>
<li><code>rbd_cache_max_dirty</code>：在writeback模式下cache的最大bytes数，默认是24MB；当该值为0时，表示使用writethrough模式；</li>
<li><code>rbd_cache_target_dirty</code>：在writeback模式下cache向ceph集群写入的bytes阀值，默认16MB；注意该值一定要小于<code>rbd_cache_max_dirty</code>值</li>
</ul>
<p><code>rbd_cache_writethrough_until_flush</code>：在内核触发flush cache到ceph集群前rbd cache一直是writethrough模式，直到flush后rbd cache变成writeback模式；<br><code>rbd_cache_max_dirty_age</code>：标记OSDC端ObjectCacher中entry在cache中的最长时间；</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://my.oschina.net/linuxhunter/blog/541997" target="_blank" rel="noopener">https://my.oschina.net/linuxhunter/blog/541997</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ictfox.cn/2017/05/09/rgw-multi-region/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ictfox">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ictfox.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ictfox blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/09/rgw-multi-region/" itemprop="url">对象存储跨机房容灾调研</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-09T15:31:37+08:00">
                2017-05-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ceph/" itemprop="url" rel="index">
                    <span itemprop="name">ceph</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/09/rgw-multi-region/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/09/rgw-multi-region/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>随着机房的增加和客户对可靠性的要求提高，我们需要提供数据的跨机房容灾，本文档结合Ceph Radosgw的实现描述对象存储的跨机房容灾。</p>
<h2 id="当前状况"><a href="#当前状况" class="headerlink" title="当前状况"></a>当前状况</h2><p>当前应用中，每个机房的Ceph都是独立的cluster，彼此之间没有任何关系。</p>
<p>多个机房都独立的提供对象存储功能，每个Ceph Radosgw都有自己独立的命名空间和存储空间。</p>
<h3 id="这样带来两个问题："><a href="#这样带来两个问题：" class="headerlink" title="这样带来两个问题："></a>这样带来两个问题：</h3><p>1，针对Radosgw来说，我们的业务没法提供统一的命名空间；</p>
<p>2，没有机房级别的容灾，若一个机房Radosgw无法访问，则机房提供的对象存储瘫痪；</p>
<h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>针对上述中的情况和需求，Ceph的Radosgw原生支持的联合架构，支持Region，Zone级别的备份同步，能很好的解决这个问题。</p>
<h3 id="Ceph要求"><a href="#Ceph要求" class="headerlink" title="Ceph要求"></a>Ceph要求</h3><ul>
<li>版本Ceph version 0.67以后即可，我们当前使用的0.94.5支持该feature</li>
<li>每个Ceph cluster必须配置启动RADOSGW</li>
</ul>
<h3 id="概念解释"><a href="#概念解释" class="headerlink" title="概念解释"></a>概念解释</h3><ul>
<li>Region: A region represents a logical geographic area and contains one or more zones. A cluster with multiple regions must specify a master region.</li>
<li>Zone: A zone is a logical grouping of one or more Ceph Object Gateway instance(s). A region has a master zone that processes client requests.<br>注：Only write objects to the master zone in a region. You may read objects from secondary zones. Currently, the Gateway does not prevent you from writing to a secondary zone, but DON’T DO IT.</li>
</ul>
<h3 id="应用模式1"><a href="#应用模式1" class="headerlink" title="应用模式1"></a>应用模式1</h3><p>同一Region内的不同Zones之间数据同步，如下图所示：</p>
<p><img src="/images/rgw-multi-region1.jpg" alt="rgw-multi-region1"></p>
<p><strong>特点：</strong></p>
<ul>
<li>主zone支持读写操作</li>
<li>从zone支持读操作</li>
<li>主从zone之间同步数据</li>
</ul>
<p><strong>用途：</strong></p>
<ul>
<li>主从zone之间数据备份，提供跨机房容灾</li>
<li>从zone分担主zone的读数据压力，提高集群扩展性</li>
</ul>
<h3 id="应用模式2"><a href="#应用模式2" class="headerlink" title="应用模式2"></a>应用模式2</h3><p>不同Regions之间的数据同步，如下图所示：</p>
<p><img src="/images/rgw-multi-region2.jpg" alt="rgw-multi-region2"></p>
<p><strong>特点：</strong></p>
<ul>
<li>主从Region都支持读写操作</li>
<li>主从Region之间只同步元数据信息</li>
<li>主从Region之间数据是独立的</li>
</ul>
<p><strong>用途：</strong></p>
<ul>
<li>多个Regions一起来提供统一命名空间</li>
<li>不同Region服务不同地区的客户，提高集群扩展性</li>
</ul>
<h3 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h3><p>在10.2 jewel版本中，radosgw增加了一个新特性，也就是多中心同步。 </p>
<p>所谓多中心同步，也就是不同radosgw实例之间可以自动进行同步的特性。</p>
<p>为了便于管理，又进行了逻辑上的组织，也即realm、zonegroup、zone和radosgw。这是个从上至下的组织结构，也就是realm包括若干个zonegroup，其中一个是master，其它是secondary。每个zonegroup下包括一个master zone，其它都是secondary zone。</p>
<p>zone可以认为是一个实际上的集群，由至少一个radosgw实例提供服务，但是对外服务地址是一致的。 </p>
<p>同步分两种，也就是元数据同步和数据同步。zonegroup之间只会同步元数据，而同一个zonegroup下的zone之间是同步元数据和数据。这里的元数据是指用户和桶，数据是用户的对象数据。</p>
<h4 id="概念："><a href="#概念：" class="headerlink" title="概念："></a>概念：</h4><ul>
<li>Zone: A zone is logical grouping of one or more Ceph Object Gateway instances. There will be one Zone that should be designated as the master zone in a zonegroup, which will handle all bucket and user creation.</li>
<li>Zonegroup: A zonegroup consists of multiple zones, this approximately corresponds to what used to be called as a region in pre Jewel releases for federated deployments. There should be a master zonegroup that will handle changes to the system configuration.</li>
<li>Zonegroup map: A zonegroup map is a configuration structure that holds the map of the entire system, ie. which zonegroup is the master, relationships between different zonegroups and certain configurables like storage policies.</li>
<li>Realm: A realm is a container for zonegroups, this allows for separation of zonegroups themselves between clusters. It is possible to create multiple realms, making it easier to run completely different configurations in the same cluster.</li>
<li>Period: A period holds the configuration structure for the current state of the realm. Every period contains a unique id and an epoch. A period’s epoch is incremented on every commit operation. Every realm has an associated current period, holding the current state of configuration of the zonegroups and storage policies. Any configuration change for a non master zone will increment the period’s epoch. Changing the master zone to a different zone will trigger the following changes: - A new period is generated with a new period id and epoch of 1 - Realm’s current period is updated to point to the newly generated period id - Realm’s epoch is incremented</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://docs.ceph.com/docs/master/radosgw/federated-config/" target="_blank" rel="noopener">http://docs.ceph.com/docs/master/radosgw/federated-config/</a></p>
<p><a href="http://qinghua.github.io/ceph-radosgw-replication/" target="_blank" rel="noopener">http://qinghua.github.io/ceph-radosgw-replication/</a></p>
<p><a href="http://www.cnphp6.com/archives/79981" target="_blank" rel="noopener">http://www.cnphp6.com/archives/79981</a></p>
<p><a href="http://lyang.top/2016/01/18/Radosgw-%E5%A4%9A-zone-%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A-radosgw_agent-%E5%90%8C%E6%AD%A5/" target="_blank" rel="noopener">http://lyang.top/2016/01/18/Radosgw-%E5%A4%9A-zone-%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A-radosgw_agent-%E5%90%8C%E6%AD%A5/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/ictfox.jpg"
                alt="ictfox" />
            
              <p class="site-author-name" itemprop="name">ictfox</p>
              <p class="site-description motion-element" itemprop="description">学无止境</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">75</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">50</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ictfox" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/smart_bruins" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://weibo.com/ictfox" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.askceph.com" title="Ceph问答社区" target="_blank">Ceph问答社区</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.csdn.net/for_tech" title="CSDN博客" target="_blank">CSDN博客</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ictfox</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://ictfox.disqus.com/count.js" async></script>
    

    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
